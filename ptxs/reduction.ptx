
Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_80
code version = [7,5]
producer = <unknown>
host = linux
compile_size = 64bit
compressed








.version 7.5
.target sm_80
.address_size 64















.extern .shared .align 16 .b8 __smem_d[];
.extern .shared .align 16 .b8 __smem[];

.visible .entry _Z7reduce0IiEvPT_S1_j(
.param .u64 _Z7reduce0IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IiEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce0IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r11;
mov.u32 %r22, 0;
@%p1 bra $L__BB0_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r22, [%rd5];

$L__BB0_2:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.u32 [%r7], %r22;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB0_7;

mov.u32 %r23, 1;

$L__BB0_4:
shl.b32 %r9, %r23, 1;
rem.u32 %r15, %r3, %r9;
setp.ne.s32 %p3, %r15, 0;
@%p3 bra $L__BB0_6;

shl.b32 %r16, %r23, 2;
add.s32 %r17, %r7, %r16;
ld.shared.u32 %r18, [%r7];
ld.shared.u32 %r19, [%r17];
add.s32 %r20, %r18, %r19;
st.shared.u32 [%r7], %r20;

$L__BB0_6:
barrier.sync 0;
setp.lt.u32 %p4, %r9, %r1;
mov.u32 %r23, %r9;
@%p4 bra $L__BB0_4;

$L__BB0_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB0_9;

ld.shared.u32 %r21, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r21;

$L__BB0_9:
ret;

}

.visible .entry _Z7reduce1IiEvPT_S1_j(
.param .u64 _Z7reduce1IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<28>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IiEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce1IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r11;
mov.u32 %r26, 0;
@%p1 bra $L__BB1_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r26, [%rd5];

$L__BB1_2:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.u32 [%r14], %r26;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB1_7;

mov.u32 %r27, 1;

$L__BB1_4:
shl.b32 %r8, %r27, 1;
mul.lo.s32 %r9, %r8, %r3;
setp.ge.u32 %p3, %r9, %r1;
@%p3 bra $L__BB1_6;

add.s32 %r16, %r9, %r27;
shl.b32 %r17, %r16, 2;
add.s32 %r19, %r13, %r17;
shl.b32 %r20, %r9, 2;
add.s32 %r21, %r13, %r20;
ld.shared.u32 %r22, [%r21];
ld.shared.u32 %r23, [%r19];
add.s32 %r24, %r22, %r23;
st.shared.u32 [%r21], %r24;

$L__BB1_6:
barrier.sync 0;
setp.lt.u32 %p4, %r8, %r1;
mov.u32 %r27, %r8;
@%p4 bra $L__BB1_4;

$L__BB1_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB1_9;

ld.shared.u32 %r25, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r25;

$L__BB1_9:
ret;

}

.visible .entry _Z7reduce2IiEvPT_S1_j(
.param .u64 _Z7reduce2IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce2IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce2IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce2IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce2IiEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce2IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r12;
mov.u32 %r21, 0;
@%p1 bra $L__BB2_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r21, [%rd5];

$L__BB2_2:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.u32 [%r7], %r21;
barrier.sync 0;
shr.u32 %r22, %r1, 1;
setp.eq.s32 %p2, %r22, 0;
@%p2 bra $L__BB2_7;

$L__BB2_4:
setp.ge.u32 %p3, %r3, %r22;
@%p3 bra $L__BB2_6;

shl.b32 %r15, %r22, 2;
add.s32 %r16, %r7, %r15;
ld.shared.u32 %r17, [%r7];
ld.shared.u32 %r18, [%r16];
add.s32 %r19, %r17, %r18;
st.shared.u32 [%r7], %r19;

$L__BB2_6:
barrier.sync 0;
shr.u32 %r22, %r22, 1;
setp.ne.s32 %p4, %r22, 0;
@%p4 bra $L__BB2_4;

$L__BB2_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB2_9;

ld.shared.u32 %r20, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r20;

$L__BB2_9:
ret;

}

.visible .entry _Z7reduce3IiEvPT_S1_j(
.param .u64 _Z7reduce3IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IiEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .b32 %r<33>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IiEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce3IiEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r20, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r20, %r2, %r3;
setp.ge.u32 %p1, %r4, %r18;
mov.u32 %r31, 0;
@%p1 bra $L__BB3_2;

mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r31, [%rd5];

$L__BB3_2:
add.s32 %r7, %r4, %r1;
setp.ge.u32 %p2, %r7, %r18;
@%p2 bra $L__BB3_4;

mul.wide.u32 %rd6, %r7, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r21, [%rd7];
add.s32 %r31, %r21, %r31;

$L__BB3_4:
shl.b32 %r22, %r3, 2;
mov.u32 %r23, __smem;
add.s32 %r10, %r23, %r22;
st.shared.u32 [%r10], %r31;
barrier.sync 0;
shr.u32 %r29, %r1, 1;
setp.eq.s32 %p3, %r29, 0;
@%p3 bra $L__BB3_9;

$L__BB3_6:
setp.ge.u32 %p4, %r3, %r29;
@%p4 bra $L__BB3_8;

shl.b32 %r24, %r29, 2;
add.s32 %r25, %r10, %r24;
ld.shared.u32 %r26, [%r25];
add.s32 %r31, %r26, %r31;
st.shared.u32 [%r10], %r31;

$L__BB3_8:
barrier.sync 0;
shr.u32 %r29, %r29, 1;
setp.ne.s32 %p5, %r29, 0;
@%p5 bra $L__BB3_6;

$L__BB3_9:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra $L__BB3_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r31;

$L__BB3_11:
ret;

}

.visible .entry _Z7reduce4IiLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj512EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB4_2;

ld.global.u32 %r55, [%rd1];

$L__BB4_2:
add.s32 %r22, %r4, 512;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB4_4;

ld.global.u32 %r23, [%rd1+2048];
add.s32 %r55, %r23, %r55;

$L__BB4_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB4_9;

mov.u32 %r53, %r1;

$L__BB4_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB4_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB4_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB4_6;

$L__BB4_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB4_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB4_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB4_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB4_13:
ret;

}

.visible .entry _Z7reduce4IiLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj256EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB5_2;

ld.global.u32 %r55, [%rd1];

$L__BB5_2:
add.s32 %r22, %r4, 256;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB5_4;

ld.global.u32 %r23, [%rd1+1024];
add.s32 %r55, %r23, %r55;

$L__BB5_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB5_9;

mov.u32 %r53, %r1;

$L__BB5_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB5_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB5_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB5_6;

$L__BB5_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB5_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB5_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB5_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB5_13:
ret;

}

.visible .entry _Z7reduce4IiLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj128EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB6_2;

ld.global.u32 %r55, [%rd1];

$L__BB6_2:
add.s32 %r22, %r4, 128;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB6_4;

ld.global.u32 %r23, [%rd1+512];
add.s32 %r55, %r23, %r55;

$L__BB6_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB6_9;

mov.u32 %r53, %r1;

$L__BB6_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB6_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB6_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB6_6;

$L__BB6_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB6_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB6_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB6_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB6_13:
ret;

}

.visible .entry _Z7reduce4IiLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj64EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB7_2;

ld.global.u32 %r55, [%rd1];

$L__BB7_2:
add.s32 %r22, %r4, 64;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB7_4;

ld.global.u32 %r23, [%rd1+256];
add.s32 %r55, %r23, %r55;

$L__BB7_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB7_9;

mov.u32 %r53, %r1;

$L__BB7_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB7_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB7_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB7_6;

$L__BB7_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB7_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB7_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB7_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB7_13:
ret;

}

.visible .entry _Z7reduce4IiLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj32EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB8_2;

ld.global.u32 %r53, [%rd1];

$L__BB8_2:
add.s32 %r22, %r4, 32;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB8_4;

ld.global.u32 %r23, [%rd1+128];
add.s32 %r53, %r23, %r53;

$L__BB8_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB8_9;

mov.u32 %r51, %r1;

$L__BB8_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB8_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB8_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB8_6;

$L__BB8_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB8_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB8_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB8_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB8_13:
ret;

}

.visible .entry _Z7reduce4IiLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj16EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB9_2;

ld.global.u32 %r53, [%rd1];

$L__BB9_2:
add.s32 %r22, %r4, 16;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB9_4;

ld.global.u32 %r23, [%rd1+64];
add.s32 %r53, %r23, %r53;

$L__BB9_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB9_9;

mov.u32 %r51, %r1;

$L__BB9_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB9_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB9_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB9_6;

$L__BB9_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB9_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB9_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB9_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB9_13:
ret;

}

.visible .entry _Z7reduce4IiLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj8EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB10_2;

ld.global.u32 %r53, [%rd1];

$L__BB10_2:
add.s32 %r22, %r4, 8;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB10_4;

ld.global.u32 %r23, [%rd1+32];
add.s32 %r53, %r23, %r53;

$L__BB10_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB10_9;

mov.u32 %r51, %r1;

$L__BB10_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB10_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB10_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB10_6;

$L__BB10_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB10_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB10_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB10_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB10_13:
ret;

}

.visible .entry _Z7reduce4IiLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj4EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB11_2;

ld.global.u32 %r53, [%rd1];

$L__BB11_2:
add.s32 %r22, %r4, 4;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB11_4;

ld.global.u32 %r23, [%rd1+16];
add.s32 %r53, %r23, %r53;

$L__BB11_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB11_9;

mov.u32 %r51, %r1;

$L__BB11_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB11_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB11_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB11_6;

$L__BB11_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB11_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB11_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB11_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB11_13:
ret;

}

.visible .entry _Z7reduce4IiLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj2EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB12_2;

ld.global.u32 %r53, [%rd1];

$L__BB12_2:
add.s32 %r22, %r4, 2;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB12_4;

ld.global.u32 %r23, [%rd1+8];
add.s32 %r53, %r23, %r53;

$L__BB12_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB12_9;

mov.u32 %r51, %r1;

$L__BB12_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB12_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB12_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB12_6;

$L__BB12_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB12_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB12_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB12_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB12_13:
ret;

}

.visible .entry _Z7reduce4IiLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj1EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB13_2;

ld.global.u32 %r53, [%rd1];

$L__BB13_2:
add.s32 %r22, %r4, 1;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB13_4;

ld.global.u32 %r23, [%rd1+4];
add.s32 %r53, %r23, %r53;

$L__BB13_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB13_9;

mov.u32 %r51, %r1;

$L__BB13_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB13_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB13_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB13_6;

$L__BB13_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB13_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB13_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB13_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB13_13:
ret;

}

.visible .entry _Z7reduce5IiLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<57>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj512EEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce5IiLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r20, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r20, %r2;
setp.ge.u32 %p1, %r3, %r18;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r52, 0;
@%p1 bra $L__BB14_2;

ld.global.u32 %r52, [%rd1];

$L__BB14_2:
add.s32 %r21, %r3, 512;
setp.ge.u32 %p2, %r21, %r18;
@%p2 bra $L__BB14_4;

ld.global.u32 %r22, [%rd1+2048];
add.s32 %r52, %r22, %r52;

$L__BB14_4:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r8, %r24, %r23;
st.shared.u32 [%r8], %r52;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB14_6;

ld.shared.u32 %r25, [%r8+1024];
add.s32 %r52, %r25, %r52;
st.shared.u32 [%r8], %r52;

$L__BB14_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB14_8;

ld.shared.u32 %r26, [%r8+512];
add.s32 %r52, %r26, %r52;
st.shared.u32 [%r8], %r52;

$L__BB14_8:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB14_10;

ld.shared.u32 %r27, [%r8+256];
add.s32 %r52, %r27, %r52;
st.shared.u32 [%r8], %r52;

$L__BB14_10:
barrier.sync 0;
mov.u32 %r28, %ntid.y;
mov.u32 %r29, %tid.z;
mov.u32 %r30, %tid.y;
mad.lo.s32 %r31, %r28, %r29, %r30;
mov.u32 %r32, %ntid.x;
mad.lo.s32 %r15, %r31, %r32, %r2;
setp.gt.u32 %p6, %r15, 31;
@%p6 bra $L__BB14_12;

ld.shared.u32 %r33, [%r8+128];
add.s32 %r34, %r33, %r52;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r52, %r50, %r48;

$L__BB14_12:
setp.ne.s32 %p12, %r15, 0;
@%p12 bra $L__BB14_14;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r52;

$L__BB14_14:
ret;

}

.visible .entry _Z7reduce5IiLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<53>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj256EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce5IiLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r18, %r2;
setp.ge.u32 %p1, %r3, %r16;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r49, 0;
@%p1 bra $L__BB15_2;

ld.global.u32 %r49, [%rd1];

$L__BB15_2:
add.s32 %r19, %r3, 256;
setp.ge.u32 %p2, %r19, %r16;
@%p2 bra $L__BB15_4;

ld.global.u32 %r20, [%rd1+1024];
add.s32 %r49, %r20, %r49;

$L__BB15_4:
shl.b32 %r21, %r2, 2;
mov.u32 %r22, __smem;
add.s32 %r8, %r22, %r21;
st.shared.u32 [%r8], %r49;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB15_6;

ld.shared.u32 %r23, [%r8+512];
add.s32 %r49, %r23, %r49;
st.shared.u32 [%r8], %r49;

$L__BB15_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB15_8;

ld.shared.u32 %r24, [%r8+256];
add.s32 %r49, %r24, %r49;
st.shared.u32 [%r8], %r49;

$L__BB15_8:
barrier.sync 0;
mov.u32 %r25, %ntid.y;
mov.u32 %r26, %tid.z;
mov.u32 %r27, %tid.y;
mad.lo.s32 %r28, %r25, %r26, %r27;
mov.u32 %r29, %ntid.x;
mad.lo.s32 %r13, %r28, %r29, %r2;
setp.gt.u32 %p5, %r13, 31;
@%p5 bra $L__BB15_10;

ld.shared.u32 %r30, [%r8+128];
add.s32 %r31, %r30, %r49;
mov.u32 %r32, 2;
mov.u32 %r33, 31;
mov.u32 %r34, 16;
mov.u32 %r35, -1;
shfl.sync.down.b32 %r36|%p6, %r31, %r34, %r33, %r35;
add.s32 %r37, %r36, %r31;
mov.u32 %r38, 8;
shfl.sync.down.b32 %r39|%p7, %r37, %r38, %r33, %r35;
add.s32 %r40, %r39, %r37;
mov.u32 %r41, 4;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r33, %r35;
add.s32 %r43, %r42, %r40;
shfl.sync.down.b32 %r44|%p9, %r43, %r32, %r33, %r35;
add.s32 %r45, %r44, %r43;
mov.u32 %r46, 1;
shfl.sync.down.b32 %r47|%p10, %r45, %r46, %r33, %r35;
add.s32 %r49, %r47, %r45;

$L__BB15_10:
setp.ne.s32 %p11, %r13, 0;
@%p11 bra $L__BB15_12;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r49;

$L__BB15_12:
ret;

}

.visible .entry _Z7reduce5IiLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<49>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj128EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce5IiLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r16, %r2;
setp.ge.u32 %p1, %r3, %r14;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r46, 0;
@%p1 bra $L__BB16_2;

ld.global.u32 %r46, [%rd1];

$L__BB16_2:
add.s32 %r17, %r3, 128;
setp.ge.u32 %p2, %r17, %r14;
@%p2 bra $L__BB16_4;

ld.global.u32 %r18, [%rd1+512];
add.s32 %r46, %r18, %r46;

$L__BB16_4:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r8, %r20, %r19;
st.shared.u32 [%r8], %r46;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB16_6;

ld.shared.u32 %r21, [%r8+256];
add.s32 %r46, %r21, %r46;
st.shared.u32 [%r8], %r46;

$L__BB16_6:
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r11, %r25, %r26, %r2;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra $L__BB16_8;

ld.shared.u32 %r27, [%r8+128];
add.s32 %r28, %r27, %r46;
mov.u32 %r29, 2;
mov.u32 %r30, 31;
mov.u32 %r31, 16;
mov.u32 %r32, -1;
shfl.sync.down.b32 %r33|%p5, %r28, %r31, %r30, %r32;
add.s32 %r34, %r33, %r28;
mov.u32 %r35, 8;
shfl.sync.down.b32 %r36|%p6, %r34, %r35, %r30, %r32;
add.s32 %r37, %r36, %r34;
mov.u32 %r38, 4;
shfl.sync.down.b32 %r39|%p7, %r37, %r38, %r30, %r32;
add.s32 %r40, %r39, %r37;
shfl.sync.down.b32 %r41|%p8, %r40, %r29, %r30, %r32;
add.s32 %r42, %r41, %r40;
mov.u32 %r43, 1;
shfl.sync.down.b32 %r44|%p9, %r42, %r43, %r30, %r32;
add.s32 %r46, %r44, %r42;

$L__BB16_8:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra $L__BB16_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

$L__BB16_10:
ret;

}

.visible .entry _Z7reduce5IiLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj64EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce5IiLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r14, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r14, %r2;
setp.ge.u32 %p1, %r3, %r12;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r43, 0;
@%p1 bra $L__BB17_2;

ld.global.u32 %r43, [%rd1];

$L__BB17_2:
add.s32 %r15, %r3, 64;
setp.ge.u32 %p2, %r15, %r12;
@%p2 bra $L__BB17_4;

ld.global.u32 %r16, [%rd1+256];
add.s32 %r43, %r16, %r43;

$L__BB17_4:
shl.b32 %r17, %r2, 2;
mov.u32 %r18, __smem;
add.s32 %r8, %r18, %r17;
st.shared.u32 [%r8], %r43;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r9, %r22, %r23, %r2;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra $L__BB17_6;

ld.shared.u32 %r24, [%r8+128];
add.s32 %r25, %r24, %r43;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p4, %r25, %r28, %r27, %r29;
add.s32 %r31, %r30, %r25;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p5, %r31, %r32, %r27, %r29;
add.s32 %r34, %r33, %r31;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p6, %r34, %r35, %r27, %r29;
add.s32 %r37, %r36, %r34;
shfl.sync.down.b32 %r38|%p7, %r37, %r26, %r27, %r29;
add.s32 %r39, %r38, %r37;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p8, %r39, %r40, %r27, %r29;
add.s32 %r43, %r41, %r39;

$L__BB17_6:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra $L__BB17_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r43;

$L__BB17_8:
ret;

}

.visible .entry _Z7reduce5IiLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj32EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB18_2;

ld.global.u32 %r41, [%rd1];

$L__BB18_2:
add.s32 %r14, %r3, 32;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB18_4;

ld.global.u32 %r15, [%rd1+128];
add.s32 %r41, %r15, %r41;

$L__BB18_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB18_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB18_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB18_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB18_8:
ret;

}

.visible .entry _Z7reduce5IiLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj16EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB19_2;

ld.global.u32 %r41, [%rd1];

$L__BB19_2:
add.s32 %r14, %r3, 16;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB19_4;

ld.global.u32 %r15, [%rd1+64];
add.s32 %r41, %r15, %r41;

$L__BB19_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB19_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB19_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB19_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB19_8:
ret;

}

.visible .entry _Z7reduce5IiLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj8EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB20_2;

ld.global.u32 %r41, [%rd1];

$L__BB20_2:
add.s32 %r14, %r3, 8;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB20_4;

ld.global.u32 %r15, [%rd1+32];
add.s32 %r41, %r15, %r41;

$L__BB20_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB20_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB20_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB20_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB20_8:
ret;

}

.visible .entry _Z7reduce5IiLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj4EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB21_2;

ld.global.u32 %r41, [%rd1];

$L__BB21_2:
add.s32 %r14, %r3, 4;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB21_4;

ld.global.u32 %r15, [%rd1+16];
add.s32 %r41, %r15, %r41;

$L__BB21_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB21_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB21_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB21_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB21_8:
ret;

}

.visible .entry _Z7reduce5IiLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj2EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB22_2;

ld.global.u32 %r41, [%rd1];

$L__BB22_2:
add.s32 %r14, %r3, 2;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB22_4;

ld.global.u32 %r15, [%rd1+8];
add.s32 %r41, %r15, %r41;

$L__BB22_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB22_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB22_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB22_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB22_8:
ret;

}

.visible .entry _Z7reduce5IiLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj1EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB23_2;

ld.global.u32 %r41, [%rd1];

$L__BB23_2:
add.s32 %r14, %r3, 1;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB23_4;

ld.global.u32 %r15, [%rd1+4];
add.s32 %r41, %r15, %r41;

$L__BB23_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB23_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB23_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB23_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB23_8:
ret;

}

.visible .entry _Z7reduce6IiLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<14>;
.reg .b32 %r<67>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r22, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r24, %ctaid.x;
shl.b32 %r25, %r24, 10;
mov.u32 %r1, %tid.x;
add.s32 %r59, %r25, %r1;
setp.ge.u32 %p1, %r59, %r22;
mov.u32 %r60, 0;
@%p1 bra $L__BB24_5;

mov.u32 %r27, %nctaid.x;
shl.b32 %r3, %r27, 10;

$L__BB24_2:
mul.wide.u32 %rd4, %r59, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r28, [%rd5];
add.s32 %r60, %r28, %r60;
add.s32 %r7, %r59, 512;
setp.ge.u32 %p2, %r7, %r22;
@%p2 bra $L__BB24_4;

mul.wide.u32 %rd6, %r7, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r29, [%rd7];
add.s32 %r60, %r29, %r60;

$L__BB24_4:
add.s32 %r59, %r59, %r3;
setp.lt.u32 %p3, %r59, %r22;
@%p3 bra $L__BB24_2;

$L__BB24_5:
shl.b32 %r30, %r1, 2;
mov.u32 %r31, __smem;
add.s32 %r12, %r31, %r30;
st.shared.u32 [%r12], %r60;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 255;
@%p4 bra $L__BB24_7;

ld.shared.u32 %r32, [%r12+1024];
add.s32 %r60, %r32, %r60;
st.shared.u32 [%r12], %r60;

$L__BB24_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 127;
@%p5 bra $L__BB24_9;

ld.shared.u32 %r33, [%r12+512];
add.s32 %r60, %r33, %r60;
st.shared.u32 [%r12], %r60;

$L__BB24_9:
barrier.sync 0;
setp.gt.u32 %p6, %r1, 63;
@%p6 bra $L__BB24_11;

ld.shared.u32 %r34, [%r12+256];
add.s32 %r60, %r34, %r60;
st.shared.u32 [%r12], %r60;

$L__BB24_11:
barrier.sync 0;
mov.u32 %r35, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r35, %r36, %r37;
mov.u32 %r39, %ntid.x;
mad.lo.s32 %r19, %r38, %r39, %r1;
setp.gt.u32 %p7, %r19, 31;
@%p7 bra $L__BB24_13;

ld.shared.u32 %r40, [%r12+128];
add.s32 %r41, %r40, %r60;
mov.u32 %r42, 2;
mov.u32 %r43, 31;
mov.u32 %r44, 16;
mov.u32 %r45, -1;
shfl.sync.down.b32 %r46|%p8, %r41, %r44, %r43, %r45;
add.s32 %r47, %r46, %r41;
mov.u32 %r48, 8;
shfl.sync.down.b32 %r49|%p9, %r47, %r48, %r43, %r45;
add.s32 %r50, %r49, %r47;
mov.u32 %r51, 4;
shfl.sync.down.b32 %r52|%p10, %r50, %r51, %r43, %r45;
add.s32 %r53, %r52, %r50;
shfl.sync.down.b32 %r54|%p11, %r53, %r42, %r43, %r45;
add.s32 %r55, %r54, %r53;
mov.u32 %r56, 1;
shfl.sync.down.b32 %r57|%p12, %r55, %r56, %r43, %r45;
add.s32 %r60, %r57, %r55;

$L__BB24_13:
setp.ne.s32 %p13, %r19, 0;
@%p13 bra $L__BB24_15;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r24, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r60;

$L__BB24_15:
ret;

}

.visible .entry _Z7reduce6IiLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<63>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r20, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r22, %ctaid.x;
shl.b32 %r23, %r22, 9;
mov.u32 %r1, %tid.x;
add.s32 %r56, %r23, %r1;
setp.ge.u32 %p1, %r56, %r20;
mov.u32 %r57, 0;
@%p1 bra $L__BB25_5;

mov.u32 %r25, %nctaid.x;
shl.b32 %r3, %r25, 9;

$L__BB25_2:
mul.wide.u32 %rd4, %r56, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r26, [%rd5];
add.s32 %r57, %r26, %r57;
add.s32 %r7, %r56, 256;
setp.ge.u32 %p2, %r7, %r20;
@%p2 bra $L__BB25_4;

mul.wide.u32 %rd6, %r7, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r27, [%rd7];
add.s32 %r57, %r27, %r57;

$L__BB25_4:
add.s32 %r56, %r56, %r3;
setp.lt.u32 %p3, %r56, %r20;
@%p3 bra $L__BB25_2;

$L__BB25_5:
shl.b32 %r28, %r1, 2;
mov.u32 %r29, __smem;
add.s32 %r12, %r29, %r28;
st.shared.u32 [%r12], %r57;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 127;
@%p4 bra $L__BB25_7;

ld.shared.u32 %r30, [%r12+512];
add.s32 %r57, %r30, %r57;
st.shared.u32 [%r12], %r57;

$L__BB25_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 63;
@%p5 bra $L__BB25_9;

ld.shared.u32 %r31, [%r12+256];
add.s32 %r57, %r31, %r57;
st.shared.u32 [%r12], %r57;

$L__BB25_9:
barrier.sync 0;
mov.u32 %r32, %ntid.y;
mov.u32 %r33, %tid.z;
mov.u32 %r34, %tid.y;
mad.lo.s32 %r35, %r32, %r33, %r34;
mov.u32 %r36, %ntid.x;
mad.lo.s32 %r17, %r35, %r36, %r1;
setp.gt.u32 %p6, %r17, 31;
@%p6 bra $L__BB25_11;

ld.shared.u32 %r37, [%r12+128];
add.s32 %r38, %r37, %r57;
mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r43|%p7, %r38, %r41, %r40, %r42;
add.s32 %r44, %r43, %r38;
mov.u32 %r45, 8;
shfl.sync.down.b32 %r46|%p8, %r44, %r45, %r40, %r42;
add.s32 %r47, %r46, %r44;
mov.u32 %r48, 4;
shfl.sync.down.b32 %r49|%p9, %r47, %r48, %r40, %r42;
add.s32 %r50, %r49, %r47;
shfl.sync.down.b32 %r51|%p10, %r50, %r39, %r40, %r42;
add.s32 %r52, %r51, %r50;
mov.u32 %r53, 1;
shfl.sync.down.b32 %r54|%p11, %r52, %r53, %r40, %r42;
add.s32 %r57, %r54, %r52;

$L__BB25_11:
setp.ne.s32 %p12, %r17, 0;
@%p12 bra $L__BB25_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r22, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r57;

$L__BB25_13:
ret;

}

.visible .entry _Z7reduce6IiLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<58>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r21, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r52, %r21, %r2;
setp.ge.u32 %p1, %r52, %r19;
mov.u32 %r53, 0;
@%p1 bra $L__BB26_5;

mov.u32 %r23, %nctaid.x;
shl.b32 %r4, %r23, 8;

$L__BB26_2:
mul.wide.u32 %rd4, %r52, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r24, [%rd5];
add.s32 %r53, %r24, %r53;
add.s32 %r8, %r52, 128;
setp.ge.u32 %p2, %r8, %r19;
@%p2 bra $L__BB26_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r25, [%rd7];
add.s32 %r53, %r25, %r53;

$L__BB26_4:
add.s32 %r52, %r52, %r4;
setp.lt.u32 %p3, %r52, %r19;
@%p3 bra $L__BB26_2;

$L__BB26_5:
shl.b32 %r26, %r2, 2;
mov.u32 %r27, __smem;
add.s32 %r13, %r27, %r26;
st.shared.u32 [%r13], %r53;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB26_7;

ld.shared.u32 %r28, [%r13+256];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r13], %r53;

$L__BB26_7:
barrier.sync 0;
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mov.u32 %r33, %ntid.x;
mad.lo.s32 %r16, %r32, %r33, %r2;
setp.gt.u32 %p5, %r16, 31;
@%p5 bra $L__BB26_9;

ld.shared.u32 %r34, [%r13+128];
add.s32 %r35, %r34, %r53;
mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p6, %r35, %r38, %r37, %r39;
add.s32 %r41, %r40, %r35;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p7, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p8, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p9, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p10, %r49, %r50, %r37, %r39;
add.s32 %r53, %r51, %r49;

$L__BB26_9:
setp.ne.s32 %p11, %r16, 0;
@%p11 bra $L__BB26_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r53;

$L__BB26_11:
ret;

}

.visible .entry _Z7reduce6IiLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<54>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r17, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r49, %r19, %r2;
setp.ge.u32 %p1, %r49, %r17;
mov.u32 %r50, 0;
@%p1 bra $L__BB27_5;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 7;

$L__BB27_2:
mul.wide.u32 %rd4, %r49, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r22, [%rd5];
add.s32 %r50, %r22, %r50;
add.s32 %r8, %r49, 64;
setp.ge.u32 %p2, %r8, %r17;
@%p2 bra $L__BB27_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r23, [%rd7];
add.s32 %r50, %r23, %r50;

$L__BB27_4:
add.s32 %r49, %r49, %r4;
setp.lt.u32 %p3, %r49, %r17;
@%p3 bra $L__BB27_2;

$L__BB27_5:
shl.b32 %r24, %r2, 2;
mov.u32 %r25, __smem;
add.s32 %r13, %r25, %r24;
st.shared.u32 [%r13], %r50;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r14, %r29, %r30, %r2;
setp.gt.u32 %p4, %r14, 31;
@%p4 bra $L__BB27_7;

ld.shared.u32 %r31, [%r13+128];
add.s32 %r32, %r31, %r50;
mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p5, %r32, %r35, %r34, %r36;
add.s32 %r38, %r37, %r32;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p6, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p7, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p8, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p9, %r46, %r47, %r34, %r36;
add.s32 %r50, %r48, %r46;

$L__BB27_7:
setp.ne.s32 %p10, %r14, 0;
@%p10 bra $L__BB27_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r50;

$L__BB27_9:
ret;

}

.visible .entry _Z7reduce6IiLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB28_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 6;

$L__BB28_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 32;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB28_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB28_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB28_2;

$L__BB28_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB28_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB28_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB28_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB28_9:
ret;

}

.visible .entry _Z7reduce6IiLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB29_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 5;

$L__BB29_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 16;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB29_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB29_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB29_2;

$L__BB29_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB29_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB29_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB29_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB29_9:
ret;

}

.visible .entry _Z7reduce6IiLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB30_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 4;

$L__BB30_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 8;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB30_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB30_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB30_2;

$L__BB30_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB30_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB30_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB30_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB30_9:
ret;

}

.visible .entry _Z7reduce6IiLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB31_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 3;

$L__BB31_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 4;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB31_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB31_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB31_2;

$L__BB31_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB31_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB31_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB31_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB31_9:
ret;

}

.visible .entry _Z7reduce6IiLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB32_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 2;

$L__BB32_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 2;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB32_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB32_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB32_2;

$L__BB32_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB32_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB32_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB32_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB32_9:
ret;

}

.visible .entry _Z7reduce6IiLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB33_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 1;

$L__BB33_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 1;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB33_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB33_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB33_2;

$L__BB33_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB33_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB33_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB33_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB33_9:
ret;

}

.visible .entry _Z7reduce6IiLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<61>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r20, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r54, %r22, %r2;
setp.ge.u32 %p1, %r54, %r20;
mov.u32 %r56, 0;
@%p1 bra $L__BB34_3;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB34_2:
mul.wide.u32 %rd4, %r54, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r56, %r25, %r56;
add.s32 %r54, %r54, %r4;
setp.lt.u32 %p2, %r54, %r20;
@%p2 bra $L__BB34_2;

$L__BB34_3:
shl.b32 %r26, %r2, 2;
mov.u32 %r27, __smem;
add.s32 %r10, %r27, %r26;
st.shared.u32 [%r10], %r56;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB34_5;

ld.shared.u32 %r28, [%r10+1024];
add.s32 %r56, %r28, %r56;
st.shared.u32 [%r10], %r56;

$L__BB34_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB34_7;

ld.shared.u32 %r29, [%r10+512];
add.s32 %r56, %r29, %r56;
st.shared.u32 [%r10], %r56;

$L__BB34_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB34_9;

ld.shared.u32 %r30, [%r10+256];
add.s32 %r56, %r30, %r56;
st.shared.u32 [%r10], %r56;

$L__BB34_9:
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r17, %r34, %r35, %r2;
setp.gt.u32 %p6, %r17, 31;
@%p6 bra $L__BB34_11;

ld.shared.u32 %r36, [%r10+128];
add.s32 %r37, %r36, %r56;
mov.u32 %r38, 2;
mov.u32 %r39, 31;
mov.u32 %r40, 16;
mov.u32 %r41, -1;
shfl.sync.down.b32 %r42|%p7, %r37, %r40, %r39, %r41;
add.s32 %r43, %r42, %r37;
mov.u32 %r44, 8;
shfl.sync.down.b32 %r45|%p8, %r43, %r44, %r39, %r41;
add.s32 %r46, %r45, %r43;
mov.u32 %r47, 4;
shfl.sync.down.b32 %r48|%p9, %r46, %r47, %r39, %r41;
add.s32 %r49, %r48, %r46;
shfl.sync.down.b32 %r50|%p10, %r49, %r38, %r39, %r41;
add.s32 %r51, %r50, %r49;
mov.u32 %r52, 1;
shfl.sync.down.b32 %r53|%p11, %r51, %r52, %r39, %r41;
add.s32 %r56, %r53, %r51;

$L__BB34_11:
setp.ne.s32 %p12, %r17, 0;
@%p12 bra $L__BB34_13;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r56;

$L__BB34_13:
ret;

}

.visible .entry _Z7reduce6IiLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<57>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r20, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r51, %r20, %r2;
setp.ge.u32 %p1, %r51, %r18;
mov.u32 %r53, 0;
@%p1 bra $L__BB35_3;

mov.u32 %r22, %nctaid.x;
shl.b32 %r4, %r22, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB35_2:
mul.wide.u32 %rd4, %r51, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r23, [%rd5];
add.s32 %r53, %r23, %r53;
add.s32 %r51, %r51, %r4;
setp.lt.u32 %p2, %r51, %r18;
@%p2 bra $L__BB35_2;

$L__BB35_3:
shl.b32 %r24, %r2, 2;
mov.u32 %r25, __smem;
add.s32 %r10, %r25, %r24;
st.shared.u32 [%r10], %r53;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB35_5;

ld.shared.u32 %r26, [%r10+512];
add.s32 %r53, %r26, %r53;
st.shared.u32 [%r10], %r53;

$L__BB35_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB35_7;

ld.shared.u32 %r27, [%r10+256];
add.s32 %r53, %r27, %r53;
st.shared.u32 [%r10], %r53;

$L__BB35_7:
barrier.sync 0;
mov.u32 %r28, %ntid.y;
mov.u32 %r29, %tid.z;
mov.u32 %r30, %tid.y;
mad.lo.s32 %r31, %r28, %r29, %r30;
mov.u32 %r32, %ntid.x;
mad.lo.s32 %r15, %r31, %r32, %r2;
setp.gt.u32 %p5, %r15, 31;
@%p5 bra $L__BB35_9;

ld.shared.u32 %r33, [%r10+128];
add.s32 %r34, %r33, %r53;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p6, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p7, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p8, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p9, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p10, %r48, %r49, %r36, %r38;
add.s32 %r53, %r50, %r48;

$L__BB35_9:
setp.ne.s32 %p11, %r15, 0;
@%p11 bra $L__BB35_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB35_11:
ret;

}

.visible .entry _Z7reduce6IiLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<53>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r48, %r18, %r2;
setp.ge.u32 %p1, %r48, %r16;
mov.u32 %r50, 0;
@%p1 bra $L__BB36_3;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB36_2:
mul.wide.u32 %rd4, %r48, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r50, %r21, %r50;
add.s32 %r48, %r48, %r4;
setp.lt.u32 %p2, %r48, %r16;
@%p2 bra $L__BB36_2;

$L__BB36_3:
shl.b32 %r22, %r2, 2;
mov.u32 %r23, __smem;
add.s32 %r10, %r23, %r22;
st.shared.u32 [%r10], %r50;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB36_5;

ld.shared.u32 %r24, [%r10+256];
add.s32 %r50, %r24, %r50;
st.shared.u32 [%r10], %r50;

$L__BB36_5:
barrier.sync 0;
mov.u32 %r25, %ntid.y;
mov.u32 %r26, %tid.z;
mov.u32 %r27, %tid.y;
mad.lo.s32 %r28, %r25, %r26, %r27;
mov.u32 %r29, %ntid.x;
mad.lo.s32 %r13, %r28, %r29, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB36_7;

ld.shared.u32 %r30, [%r10+128];
add.s32 %r31, %r30, %r50;
mov.u32 %r32, 2;
mov.u32 %r33, 31;
mov.u32 %r34, 16;
mov.u32 %r35, -1;
shfl.sync.down.b32 %r36|%p5, %r31, %r34, %r33, %r35;
add.s32 %r37, %r36, %r31;
mov.u32 %r38, 8;
shfl.sync.down.b32 %r39|%p6, %r37, %r38, %r33, %r35;
add.s32 %r40, %r39, %r37;
mov.u32 %r41, 4;
shfl.sync.down.b32 %r42|%p7, %r40, %r41, %r33, %r35;
add.s32 %r43, %r42, %r40;
shfl.sync.down.b32 %r44|%p8, %r43, %r32, %r33, %r35;
add.s32 %r45, %r44, %r43;
mov.u32 %r46, 1;
shfl.sync.down.b32 %r47|%p9, %r45, %r46, %r33, %r35;
add.s32 %r50, %r47, %r45;

$L__BB36_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB36_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r50;

$L__BB36_9:
ret;

}

.visible .entry _Z7reduce6IiLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<49>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r16, %r2;
setp.ge.u32 %p1, %r45, %r14;
mov.u32 %r47, 0;
@%p1 bra $L__BB37_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB37_2:
mul.wide.u32 %rd4, %r45, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r19, [%rd5];
add.s32 %r47, %r19, %r47;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p2, %r45, %r14;
@%p2 bra $L__BB37_2;

$L__BB37_3:
shl.b32 %r20, %r2, 2;
mov.u32 %r21, __smem;
add.s32 %r10, %r21, %r20;
st.shared.u32 [%r10], %r47;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r11, %r25, %r26, %r2;
setp.gt.u32 %p3, %r11, 31;
@%p3 bra $L__BB37_5;

ld.shared.u32 %r27, [%r10+128];
add.s32 %r28, %r27, %r47;
mov.u32 %r29, 2;
mov.u32 %r30, 31;
mov.u32 %r31, 16;
mov.u32 %r32, -1;
shfl.sync.down.b32 %r33|%p4, %r28, %r31, %r30, %r32;
add.s32 %r34, %r33, %r28;
mov.u32 %r35, 8;
shfl.sync.down.b32 %r36|%p5, %r34, %r35, %r30, %r32;
add.s32 %r37, %r36, %r34;
mov.u32 %r38, 4;
shfl.sync.down.b32 %r39|%p6, %r37, %r38, %r30, %r32;
add.s32 %r40, %r39, %r37;
shfl.sync.down.b32 %r41|%p7, %r40, %r29, %r30, %r32;
add.s32 %r42, %r41, %r40;
mov.u32 %r43, 1;
shfl.sync.down.b32 %r44|%p8, %r42, %r43, %r30, %r32;
add.s32 %r47, %r44, %r42;

$L__BB37_5:
setp.ne.s32 %p9, %r11, 0;
@%p9 bra $L__BB37_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r47;

$L__BB37_7:
ret;

}

.visible .entry _Z7reduce6IiLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB38_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB38_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB38_2;

$L__BB38_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB38_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB38_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB38_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB38_7:
ret;

}

.visible .entry _Z7reduce6IiLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB39_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB39_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB39_2;

$L__BB39_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB39_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB39_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB39_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB39_7:
ret;

}

.visible .entry _Z7reduce6IiLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB40_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB40_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB40_2;

$L__BB40_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB40_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB40_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB40_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB40_7:
ret;

}

.visible .entry _Z7reduce6IiLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB41_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB41_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB41_2;

$L__BB41_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB41_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB41_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB41_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB41_7:
ret;

}

.visible .entry _Z7reduce6IiLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB42_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB42_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB42_2;

$L__BB42_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB42_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB42_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB42_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB42_7:
ret;

}

.visible .entry _Z7reduce6IiLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r1, %r2;
setp.ge.u32 %p1, %r41, %r13;
mov.u32 %r43, 0;
@%p1 bra $L__BB43_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB43_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r16, [%rd5];
add.s32 %r43, %r16, %r43;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p2, %r41, %r13;
@%p2 bra $L__BB43_2;

$L__BB43_3:
shl.b32 %r17, %r2, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.u32 [%r19], %r43;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r10, %r23, %r24, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB43_5;

mov.u32 %r25, 2;
mov.u32 %r26, 31;
mov.u32 %r27, 16;
mov.u32 %r28, -1;
shfl.sync.down.b32 %r29|%p4, %r43, %r27, %r26, %r28;
add.s32 %r30, %r29, %r43;
mov.u32 %r31, 8;
shfl.sync.down.b32 %r32|%p5, %r30, %r31, %r26, %r28;
add.s32 %r33, %r32, %r30;
mov.u32 %r34, 4;
shfl.sync.down.b32 %r35|%p6, %r33, %r34, %r26, %r28;
add.s32 %r36, %r35, %r33;
shfl.sync.down.b32 %r37|%p7, %r36, %r25, %r26, %r28;
add.s32 %r38, %r37, %r36;
mov.u32 %r39, 1;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r26, %r28;
add.s32 %r43, %r40, %r38;

$L__BB43_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB43_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r43;

$L__BB43_7:
ret;

}

.visible .entry _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB44_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 11;

$L__BB44_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 1024;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB44_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB44_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB44_2;

$L__BB44_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB44_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB44_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 1024;
mov.u32 %r44, 1;
@%p6 bra $L__BB44_9;

mov.u32 %r34, 1024;
div.u32 %r44, %r34, %r14;

$L__BB44_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB44_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB44_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB44_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB44_13:
ret;

}

.visible .entry _Z7reduce7IiLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB45_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 10;

$L__BB45_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 512;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB45_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB45_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB45_2;

$L__BB45_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB45_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB45_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 512;
mov.u32 %r44, 1;
@%p6 bra $L__BB45_9;

mov.u32 %r34, 512;
div.u32 %r44, %r34, %r14;

$L__BB45_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB45_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB45_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB45_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB45_13:
ret;

}

.visible .entry _Z7reduce7IiLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB46_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 9;

$L__BB46_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 256;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB46_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB46_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB46_2;

$L__BB46_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB46_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB46_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 256;
mov.u32 %r44, 1;
@%p6 bra $L__BB46_9;

mov.u32 %r34, 256;
div.u32 %r44, %r34, %r14;

$L__BB46_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB46_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB46_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB46_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB46_13:
ret;

}

.visible .entry _Z7reduce7IiLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB47_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 8;

$L__BB47_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 128;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB47_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB47_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB47_2;

$L__BB47_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB47_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB47_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 128;
mov.u32 %r44, 1;
@%p6 bra $L__BB47_9;

mov.u32 %r34, 128;
div.u32 %r44, %r34, %r14;

$L__BB47_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB47_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB47_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB47_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB47_13:
ret;

}

.visible .entry _Z7reduce7IiLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB48_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 7;

$L__BB48_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 64;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB48_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB48_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB48_2;

$L__BB48_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB48_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB48_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 64;
mov.u32 %r44, 1;
@%p6 bra $L__BB48_9;

mov.u32 %r34, 64;
div.u32 %r44, %r34, %r14;

$L__BB48_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB48_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB48_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB48_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB48_13:
ret;

}

.visible .entry _Z7reduce7IiLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB49_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 6;

$L__BB49_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 32;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB49_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB49_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB49_2;

$L__BB49_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB49_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB49_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 32;
mov.u32 %r44, 1;
@%p6 bra $L__BB49_9;

mov.u32 %r34, 32;
div.u32 %r44, %r34, %r14;

$L__BB49_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB49_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB49_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB49_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB49_13:
ret;

}

.visible .entry _Z7reduce7IiLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB50_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 5;

$L__BB50_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 16;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB50_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB50_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB50_2;

$L__BB50_5:
mov.u32 %r27, 65535;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB50_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB50_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 16;
mov.u32 %r44, 1;
@%p6 bra $L__BB50_9;

mov.u32 %r34, 16;
div.u32 %r44, %r34, %r14;

$L__BB50_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB50_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB50_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB50_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB50_13:
ret;

}

.visible .entry _Z7reduce7IiLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB51_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 4;

$L__BB51_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 8;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB51_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB51_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB51_2;

$L__BB51_5:
mov.u32 %r27, 255;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB51_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB51_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 8;
mov.u32 %r44, 1;
@%p6 bra $L__BB51_9;

mov.u32 %r34, 8;
div.u32 %r44, %r34, %r14;

$L__BB51_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB51_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB51_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB51_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB51_13:
ret;

}

.visible .entry _Z7reduce7IiLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB52_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 3;

$L__BB52_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 4;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB52_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB52_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB52_2;

$L__BB52_5:
mov.u32 %r27, 15;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB52_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB52_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 4;
mov.u32 %r44, 1;
@%p6 bra $L__BB52_9;

mov.u32 %r34, 4;
div.u32 %r44, %r34, %r14;

$L__BB52_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB52_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB52_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB52_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB52_13:
ret;

}

.visible .entry _Z7reduce7IiLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB53_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 2;

$L__BB53_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 2;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB53_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB53_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB53_2;

$L__BB53_5:
mov.u32 %r27, 3;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB53_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB53_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 2;
mov.u32 %r44, 1;
@%p6 bra $L__BB53_9;

mov.u32 %r34, 2;
div.u32 %r44, %r34, %r14;

$L__BB53_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB53_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB53_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB53_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB53_13:
ret;

}

.visible .entry _Z7reduce7IiLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r18, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r20, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r33, %r20, %r2;
setp.ge.u32 %p2, %r33, %r18;
mov.u32 %r34, 0;
@%p2 bra $L__BB54_5;

mov.u32 %r22, %nctaid.x;
shl.b32 %r4, %r22, 1;

$L__BB54_2:
mul.wide.u32 %rd4, %r33, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r23, [%rd5];
add.s32 %r34, %r23, %r34;
add.s32 %r8, %r33, 1;
setp.ge.u32 %p3, %r8, %r18;
@%p3 bra $L__BB54_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r24, [%rd7];
add.s32 %r34, %r24, %r34;

$L__BB54_4:
add.s32 %r33, %r33, %r4;
setp.lt.u32 %p4, %r33, %r18;
@%p4 bra $L__BB54_2;

$L__BB54_5:
mov.u32 %r25, 1;
redux.sync.add.s32 %r37, %r34, %r25;
mov.u32 %r14, WARP_SZ;
rem.u32 %r26, %r2, %r14;
setp.ne.s32 %p5, %r26, 0;
@%p5 bra $L__BB54_7;

div.u32 %r27, %r2, %r14;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r37;

$L__BB54_7:
bar.sync 0;
setp.ne.s32 %p6, %r2, 0;
setp.eq.s32 %p7, %r2, 0;
vote.sync.ballot.b32 %r15, %p7, %r25;
@%p6 bra $L__BB54_9;

ld.shared.u32 %r32, [__smem];
redux.sync.add.s32 %r37, %r32, %r15;

$L__BB54_9:
@%p6 bra $L__BB54_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r37;

$L__BB54_11:
ret;

}

.visible .entry _Z7reduce7IiLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB55_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB55_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB55_2;

$L__BB55_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB55_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB55_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 512;
mov.u32 %r39, 1;
@%p5 bra $L__BB55_7;

mov.u32 %r30, 512;
div.u32 %r39, %r30, %r11;

$L__BB55_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB55_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB55_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB55_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB55_11:
ret;

}

.visible .entry _Z7reduce7IiLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB56_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB56_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB56_2;

$L__BB56_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB56_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB56_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 256;
mov.u32 %r39, 1;
@%p5 bra $L__BB56_7;

mov.u32 %r30, 256;
div.u32 %r39, %r30, %r11;

$L__BB56_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB56_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB56_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB56_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB56_11:
ret;

}

.visible .entry _Z7reduce7IiLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB57_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB57_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB57_2;

$L__BB57_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB57_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB57_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 128;
mov.u32 %r39, 1;
@%p5 bra $L__BB57_7;

mov.u32 %r30, 128;
div.u32 %r39, %r30, %r11;

$L__BB57_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB57_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB57_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB57_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB57_11:
ret;

}

.visible .entry _Z7reduce7IiLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB58_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB58_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB58_2;

$L__BB58_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB58_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB58_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 64;
mov.u32 %r39, 1;
@%p5 bra $L__BB58_7;

mov.u32 %r30, 64;
div.u32 %r39, %r30, %r11;

$L__BB58_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB58_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB58_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB58_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB58_11:
ret;

}

.visible .entry _Z7reduce7IiLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB59_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB59_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB59_2;

$L__BB59_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB59_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB59_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 32;
mov.u32 %r39, 1;
@%p5 bra $L__BB59_7;

mov.u32 %r30, 32;
div.u32 %r39, %r30, %r11;

$L__BB59_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB59_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB59_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB59_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB59_11:
ret;

}

.visible .entry _Z7reduce7IiLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB60_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB60_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB60_2;

$L__BB60_3:
mov.u32 %r23, 65535;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB60_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB60_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 16;
mov.u32 %r39, 1;
@%p5 bra $L__BB60_7;

mov.u32 %r30, 16;
div.u32 %r39, %r30, %r11;

$L__BB60_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB60_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB60_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB60_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB60_11:
ret;

}

.visible .entry _Z7reduce7IiLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB61_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB61_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB61_2;

$L__BB61_3:
mov.u32 %r23, 255;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB61_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB61_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 8;
mov.u32 %r39, 1;
@%p5 bra $L__BB61_7;

mov.u32 %r30, 8;
div.u32 %r39, %r30, %r11;

$L__BB61_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB61_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB61_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB61_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB61_11:
ret;

}

.visible .entry _Z7reduce7IiLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB62_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB62_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB62_2;

$L__BB62_3:
mov.u32 %r23, 15;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB62_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB62_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 4;
mov.u32 %r39, 1;
@%p5 bra $L__BB62_7;

mov.u32 %r30, 4;
div.u32 %r39, %r30, %r11;

$L__BB62_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB62_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB62_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB62_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB62_11:
ret;

}

.visible .entry _Z7reduce7IiLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB63_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB63_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB63_2;

$L__BB63_3:
mov.u32 %r23, 3;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB63_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB63_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 2;
mov.u32 %r39, 1;
@%p5 bra $L__BB63_7;

mov.u32 %r30, 2;
div.u32 %r39, %r30, %r11;

$L__BB63_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB63_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB63_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB63_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB63_11:
ret;

}

.visible .entry _Z7reduce7IiLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<8>;
.reg .b32 %r<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r27, %r1, %r2;
setp.ge.u32 %p2, %r27, %r15;
mov.u32 %r29, 0;
@%p2 bra $L__BB64_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB64_2:
mul.wide.u32 %rd4, %r27, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r18, [%rd5];
add.s32 %r29, %r18, %r29;
add.s32 %r27, %r27, %r4;
setp.lt.u32 %p3, %r27, %r15;
@%p3 bra $L__BB64_2;

$L__BB64_3:
mov.u32 %r19, 1;
redux.sync.add.s32 %r30, %r29, %r19;
mov.u32 %r11, WARP_SZ;
rem.u32 %r20, %r2, %r11;
setp.ne.s32 %p4, %r20, 0;
@%p4 bra $L__BB64_5;

div.u32 %r21, %r2, %r11;
shl.b32 %r22, %r21, 2;
mov.u32 %r23, __smem;
add.s32 %r24, %r23, %r22;
st.shared.u32 [%r24], %r30;

$L__BB64_5:
bar.sync 0;
setp.ne.s32 %p5, %r2, 0;
setp.eq.s32 %p6, %r2, 0;
vote.sync.ballot.b32 %r12, %p6, %r19;
@%p5 bra $L__BB64_7;

ld.shared.u32 %r26, [__smem];
redux.sync.add.s32 %r30, %r26, %r12;

$L__BB64_7:
@%p5 bra $L__BB64_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r30;

$L__BB64_9:
ret;

}

.visible .entry _Z9cg_reduceIiEvPT_S1_j(
.param .u64 _Z9cg_reduceIiEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIiEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIiEvPT_S1_j_param_2
)
{
.reg .pred %p<8>;
.reg .b32 %r<49>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIiEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIiEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z9cg_reduceIiEvPT_S1_j_param_2];
mov.u32 %r21, %ntid.y;
mov.u32 %r22, %tid.z;
mov.u32 %r23, %tid.y;
mad.lo.s32 %r24, %r21, %r22, %r23;
mov.u32 %r25, %ntid.x;
mov.u32 %r26, %tid.x;
mad.lo.s32 %r1, %r24, %r25, %r26;
mul.lo.s32 %r27, %r25, %r21;
mov.u32 %r28, %ntid.z;
mul.lo.s32 %r44, %r27, %r28;
mov.u32 %r29, %ctaid.x;
mad.lo.s32 %r41, %r44, %r29, %r1;
setp.ge.u32 %p1, %r41, %r19;
mov.u32 %r46, 0;
@%p1 bra $L__BB65_3;

mov.u32 %r31, %nctaid.x;
mul.lo.s32 %r4, %r44, %r31;
cvta.to.global.u64 %rd1, %rd2;

$L__BB65_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r32, [%rd5];
add.s32 %r46, %r32, %r46;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p2, %r41, %r19;
@%p2 bra $L__BB65_2;

$L__BB65_3:
shl.b32 %r33, %r1, 2;
mov.u32 %r34, __smem;
add.s32 %r10, %r34, %r33;
st.shared.u32 [%r10], %r46;
setp.lt.u32 %p3, %r44, 64;
@%p3 bra $L__BB65_8;

$L__BB65_5:
barrier.sync 0;
shr.u32 %r13, %r44, 1;
setp.ge.u32 %p4, %r1, %r13;
@%p4 bra $L__BB65_7;

shl.b32 %r35, %r13, 2;
add.s32 %r36, %r10, %r35;
ld.shared.u32 %r37, [%r36];
add.s32 %r46, %r37, %r46;
st.shared.u32 [%r10], %r46;

$L__BB65_7:
setp.gt.u32 %p5, %r44, 127;
mov.u32 %r44, %r13;
@%p5 bra $L__BB65_5;

$L__BB65_8:
barrier.sync 0;
and.b32 %r38, %r1, 2097120;
setp.ne.s32 %p6, %r38, 0;
@%p6 bra $L__BB65_10;

mov.u32 %r39, -1;
redux.sync.add.s32 %r46, %r46, %r39;

$L__BB65_10:
setp.ne.s32 %p7, %r1, 0;
@%p7 bra $L__BB65_12;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r29, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

$L__BB65_12:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<21>;
.reg .b32 %r<156>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch[160];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB66_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB66_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB66_6;

shl.b32 %r63, %r6, 10;
add.s32 %r138, %r63, %r3;
setp.ge.u32 %p3, %r138, %r52;
mov.u32 %r143, 0;
@%p3 bra $L__BB66_11;

shl.b32 %r8, %r5, 10;

$L__BB66_5:
mul.wide.u32 %rd5, %r138, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r143, %r65, %r143;
add.s32 %r138, %r138, %r8;
setp.lt.u32 %p4, %r138, %r52;
@%p4 bra $L__BB66_5;
bra.uni $L__BB66_11;

$L__BB66_6:
shl.b32 %r67, %r6, 11;
add.s32 %r140, %r67, %r3;
setp.ge.u32 %p5, %r140, %r52;
mov.u32 %r143, 0;
@%p5 bra $L__BB66_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 11;

$L__BB66_8:
cvt.u64.u32 %rd7, %r140;
mul.wide.u32 %rd8, %r140, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r143, %r69, %r143;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB66_10;

add.s32 %r70, %r140, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r143, %r71, %r143;

$L__BB66_10:
add.s32 %r140, %r140, %r14;
setp.lt.u32 %p7, %r140, %r52;
@%p7 bra $L__BB66_8;

$L__BB66_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r143, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 9;
shl.b32 %r79, %r25, 4;
mov.u32 %r80, 65535;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r144, %r72;
@%p8 bra $L__BB66_13;

add.s32 %r82, %r75, 12;
atom.shared.or.b32 %r144, [%r82], %r24;

$L__BB66_13:
mov.u32 %r83, 31;
shfl.sync.idx.b32 %r86|%p9, %r144, %r72, %r83, %r77;
or.b32 %r87, %r86, %r24;
and.b32 %r88, %r87, %r26;
setp.eq.s32 %p10, %r88, %r26;
@%p10 bra $L__BB66_15;
bra.uni $L__BB66_14;

$L__BB66_15:
and.b32 %r91, %r4, 16;
setp.ne.s32 %p12, %r91, 0;
@%p12 bra $L__BB66_17;

and.b32 %r93, %r4, 15;
and.b32 %r94, %r4, -512;
shr.u32 %r95, %r94, 5;
or.b32 %r96, %r95, %r93;
shl.b32 %r97, %r96, 2;
add.s32 %r99, %r75, %r97;

	mov.u32 %r92, %laneid;

	and.b32 %r100, %r92, -16;
shl.b32 %r102, %r80, %r100;
ld.shared.u32 %r103, [%r99+32];
redux.sync.add.s32 %r104, %r103, %r102;
st.shared.u32 [%r99+32], %r104;

$L__BB66_17:
bar.warp.sync -1;
@%p8 bra $L__BB66_19;

not.b32 %r105, %r26;
add.s32 %r107, %r75, 12;
atom.shared.and.b32 %r108, [%r107], %r105;
bra.uni $L__BB66_19;

$L__BB66_14:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch+12];
and.b32 %r90, %r89, %r24;
setp.eq.s32 %p11, %r90, 0;
@%p11 bra $L__BB66_19;
bra.uni $L__BB66_14;

$L__BB66_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r109, %r4, 511;
setp.ne.s32 %p14, %r109, 0;
@%p14 bra $L__BB66_21;

shl.b32 %r110, %r25, 2;
mov.u32 %r111, __smem;
add.s32 %r112, %r111, %r110;
st.shared.u32 [%r112], %r29;

$L__BB66_21:
barrier.sync 0;
setp.ne.s32 %p15, %r3, 0;
@%p15 bra $L__BB66_30;

mul.lo.s32 %r114, %r2, %r1;
mov.u32 %r115, %ntid.z;
mad.lo.s32 %r116, %r114, %r115, 511;
shr.u32 %r30, %r116, 9;
setp.eq.s32 %p16, %r30, 0;
mov.u32 %r155, 0;
@%p16 bra $L__BB66_29;

add.s32 %r120, %r30, -1;
and.b32 %r154, %r30, 3;
setp.lt.u32 %p17, %r120, 3;
mov.u32 %r150, 0;
mov.u32 %r155, %r150;
@%p17 bra $L__BB66_26;

sub.s32 %r148, %r30, %r154;
mov.u32 %r145, __smem;

$L__BB66_25:
ld.shared.v4.u32 {%r124, %r125, %r126, %r127}, [%r145];
add.s32 %r132, %r124, %r155;
add.s32 %r133, %r125, %r132;
add.s32 %r134, %r126, %r133;
add.s32 %r155, %r127, %r134;
add.s32 %r150, %r150, 4;
add.s32 %r145, %r145, 16;
add.s32 %r148, %r148, -4;
setp.ne.s32 %p18, %r148, 0;
@%p18 bra $L__BB66_25;

$L__BB66_26:
setp.eq.s32 %p19, %r154, 0;
@%p19 bra $L__BB66_29;

shl.b32 %r135, %r150, 2;
mov.u32 %r136, __smem;
add.s32 %r152, %r136, %r135;

$L__BB66_28:
.pragma "nounroll";
ld.shared.u32 %r137, [%r152];
add.s32 %r155, %r137, %r155;
add.s32 %r152, %r152, 4;
add.s32 %r154, %r154, -1;
setp.ne.s32 %p20, %r154, 0;
@%p20 bra $L__BB66_28;

$L__BB66_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r155;

$L__BB66_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<24>;
.reg .b32 %r<172>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch[96];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB67_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB67_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB67_6;

shl.b32 %r63, %r6, 9;
add.s32 %r154, %r63, %r3;
setp.ge.u32 %p3, %r154, %r52;
mov.u32 %r159, 0;
@%p3 bra $L__BB67_11;

shl.b32 %r8, %r5, 9;

$L__BB67_5:
mul.wide.u32 %rd5, %r154, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r159, %r65, %r159;
add.s32 %r154, %r154, %r8;
setp.lt.u32 %p4, %r154, %r52;
@%p4 bra $L__BB67_5;
bra.uni $L__BB67_11;

$L__BB67_6:
shl.b32 %r67, %r6, 10;
add.s32 %r156, %r67, %r3;
setp.ge.u32 %p5, %r156, %r52;
mov.u32 %r159, 0;
@%p5 bra $L__BB67_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 10;

$L__BB67_8:
cvt.u64.u32 %rd7, %r156;
mul.wide.u32 %rd8, %r156, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r159, %r69, %r159;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB67_10;

add.s32 %r70, %r156, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r159, %r71, %r159;

$L__BB67_10:
add.s32 %r156, %r156, %r14;
setp.lt.u32 %p7, %r156, %r52;
@%p7 bra $L__BB67_8;

$L__BB67_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r159, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 8;
shl.b32 %r79, %r25, 3;
mov.u32 %r80, 255;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r160, %r72;
@%p8 bra $L__BB67_13;

add.s32 %r82, %r75, 8;
atom.shared.or.b32 %r160, [%r82], %r24;

$L__BB67_13:
mov.u32 %r83, 31;
shfl.sync.idx.b32 %r86|%p9, %r160, %r72, %r83, %r77;
or.b32 %r87, %r86, %r24;
and.b32 %r88, %r87, %r26;
setp.eq.s32 %p10, %r88, %r26;
@%p10 bra $L__BB67_15;
bra.uni $L__BB67_14;

$L__BB67_15:
and.b32 %r91, %r4, 24;
setp.ne.s32 %p12, %r91, 0;
@%p12 bra $L__BB67_17;

and.b32 %r95, %r4, 7;
and.b32 %r96, %r4, -256;
shr.u32 %r97, %r96, 5;
or.b32 %r98, %r97, %r95;
shl.b32 %r99, %r98, 2;
mov.u32 %r100, 2;
add.s32 %r102, %r75, %r99;
ld.shared.u32 %r103, [%r102+32];

	mov.u32 %r92, %laneid;

	and.b32 %r104, %r92, -8;
shl.b32 %r106, %r80, %r104;
mov.u32 %r107, 6175;
mov.u32 %r108, 4;
shfl.sync.bfly.b32 %r109|%p13, %r103, %r108, %r107, %r106;
add.s32 %r110, %r109, %r103;

	mov.u32 %r93, %laneid;

	and.b32 %r111, %r93, -8;
shl.b32 %r112, %r80, %r111;
shfl.sync.bfly.b32 %r113|%p14, %r110, %r100, %r107, %r112;
add.s32 %r114, %r113, %r110;

	mov.u32 %r94, %laneid;

	and.b32 %r115, %r94, -8;
shl.b32 %r116, %r80, %r115;
shfl.sync.bfly.b32 %r118|%p15, %r114, %r76, %r107, %r116;
add.s32 %r119, %r118, %r114;
st.shared.u32 [%r102+32], %r119;

$L__BB67_17:
bar.warp.sync -1;
@%p8 bra $L__BB67_19;

not.b32 %r120, %r26;
add.s32 %r122, %r75, 8;
atom.shared.and.b32 %r123, [%r122], %r120;
bra.uni $L__BB67_19;

$L__BB67_14:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch+8];
and.b32 %r90, %r89, %r24;
setp.eq.s32 %p11, %r90, 0;
@%p11 bra $L__BB67_19;
bra.uni $L__BB67_14;

$L__BB67_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r124, %r4, 255;
setp.ne.s32 %p17, %r124, 0;
@%p17 bra $L__BB67_21;

shl.b32 %r125, %r25, 2;
mov.u32 %r126, __smem;
add.s32 %r127, %r126, %r125;
st.shared.u32 [%r127], %r29;

$L__BB67_21:
barrier.sync 0;
setp.ne.s32 %p18, %r3, 0;
@%p18 bra $L__BB67_30;

mul.lo.s32 %r129, %r2, %r1;
mov.u32 %r130, %ntid.z;
mad.lo.s32 %r131, %r129, %r130, 255;
shr.u32 %r30, %r131, 8;
setp.eq.s32 %p19, %r30, 0;
mov.u32 %r171, 0;
@%p19 bra $L__BB67_29;

add.s32 %r135, %r30, -1;
and.b32 %r170, %r30, 3;
setp.lt.u32 %p20, %r135, 3;
mov.u32 %r166, 0;
mov.u32 %r171, %r166;
@%p20 bra $L__BB67_26;

sub.s32 %r164, %r30, %r170;
mov.u32 %r161, __smem;

$L__BB67_25:
ld.shared.v4.u32 {%r139, %r140, %r141, %r142}, [%r161];
add.s32 %r147, %r139, %r171;
add.s32 %r148, %r140, %r147;
add.s32 %r149, %r141, %r148;
add.s32 %r171, %r142, %r149;
add.s32 %r166, %r166, 4;
add.s32 %r161, %r161, 16;
add.s32 %r164, %r164, -4;
setp.ne.s32 %p21, %r164, 0;
@%p21 bra $L__BB67_25;

$L__BB67_26:
setp.eq.s32 %p22, %r170, 0;
@%p22 bra $L__BB67_29;

shl.b32 %r150, %r166, 2;
mov.u32 %r151, __smem;
add.s32 %r168, %r151, %r150;

$L__BB67_28:
.pragma "nounroll";
ld.shared.u32 %r152, [%r168];
add.s32 %r171, %r152, %r171;
add.s32 %r168, %r168, 4;
add.s32 %r170, %r170, -1;
setp.ne.s32 %p23, %r170, 0;
@%p23 bra $L__BB67_28;

$L__BB67_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r171;

$L__BB67_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<23>;
.reg .b32 %r<165>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB68_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB68_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB68_6;

shl.b32 %r63, %r6, 8;
add.s32 %r147, %r63, %r3;
setp.ge.u32 %p3, %r147, %r52;
mov.u32 %r152, 0;
@%p3 bra $L__BB68_11;

shl.b32 %r8, %r5, 8;

$L__BB68_5:
mul.wide.u32 %rd5, %r147, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r152, %r65, %r152;
add.s32 %r147, %r147, %r8;
setp.lt.u32 %p4, %r147, %r52;
@%p4 bra $L__BB68_5;
bra.uni $L__BB68_11;

$L__BB68_6:
shl.b32 %r67, %r6, 9;
add.s32 %r149, %r67, %r3;
setp.ge.u32 %p5, %r149, %r52;
mov.u32 %r152, 0;
@%p5 bra $L__BB68_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 9;

$L__BB68_8:
cvt.u64.u32 %rd7, %r149;
mul.wide.u32 %rd8, %r149, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r152, %r69, %r152;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB68_10;

add.s32 %r70, %r149, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r152, %r71, %r152;

$L__BB68_10:
add.s32 %r149, %r149, %r14;
setp.lt.u32 %p7, %r149, %r52;
@%p7 bra $L__BB68_8;

$L__BB68_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r152, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 7;
shl.b32 %r79, %r25, 2;
mov.u32 %r80, 15;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r153, %r72;
@%p8 bra $L__BB68_13;

add.s32 %r82, %r75, 4;
atom.shared.or.b32 %r153, [%r82], %r24;

$L__BB68_13:
mov.u32 %r83, 31;
shfl.sync.idx.b32 %r86|%p9, %r153, %r72, %r83, %r77;
or.b32 %r87, %r86, %r24;
and.b32 %r88, %r87, %r26;
setp.eq.s32 %p10, %r88, %r26;
@%p10 bra $L__BB68_15;
bra.uni $L__BB68_14;

$L__BB68_15:
and.b32 %r91, %r4, 28;
setp.ne.s32 %p12, %r91, 0;
@%p12 bra $L__BB68_17;

and.b32 %r94, %r4, 3;
and.b32 %r95, %r4, -128;
shr.u32 %r96, %r95, 5;
or.b32 %r97, %r96, %r94;
shl.b32 %r98, %r97, 2;
mov.u32 %r99, 2;
add.s32 %r101, %r75, %r98;
ld.shared.u32 %r102, [%r101+32];

	mov.u32 %r92, %laneid;

	and.b32 %r103, %r92, -4;
shl.b32 %r105, %r80, %r103;
mov.u32 %r106, 7199;
shfl.sync.bfly.b32 %r107|%p13, %r102, %r99, %r106, %r105;
add.s32 %r108, %r107, %r102;

	mov.u32 %r93, %laneid;

	and.b32 %r109, %r93, -4;
shl.b32 %r110, %r80, %r109;
shfl.sync.bfly.b32 %r112|%p14, %r108, %r76, %r106, %r110;
add.s32 %r113, %r112, %r108;
st.shared.u32 [%r101+32], %r113;

$L__BB68_17:
bar.warp.sync -1;
@%p8 bra $L__BB68_19;

not.b32 %r114, %r26;
add.s32 %r116, %r75, 4;
atom.shared.and.b32 %r117, [%r116], %r114;
bra.uni $L__BB68_19;

$L__BB68_14:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch+4];
and.b32 %r90, %r89, %r24;
setp.eq.s32 %p11, %r90, 0;
@%p11 bra $L__BB68_19;
bra.uni $L__BB68_14;

$L__BB68_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r118, %r4, 127;
setp.ne.s32 %p16, %r118, 0;
@%p16 bra $L__BB68_21;

mov.u32 %r120, __smem;
add.s32 %r121, %r120, %r79;
st.shared.u32 [%r121], %r29;

$L__BB68_21:
barrier.sync 0;
setp.ne.s32 %p17, %r3, 0;
@%p17 bra $L__BB68_30;

mul.lo.s32 %r123, %r2, %r1;
mov.u32 %r124, %ntid.z;
mad.lo.s32 %r125, %r123, %r124, 127;
shr.u32 %r30, %r125, 7;
setp.eq.s32 %p18, %r30, 0;
mov.u32 %r164, 0;
@%p18 bra $L__BB68_29;

add.s32 %r129, %r30, -1;
and.b32 %r163, %r30, 3;
setp.lt.u32 %p19, %r129, 3;
mov.u32 %r159, 0;
mov.u32 %r164, %r159;
@%p19 bra $L__BB68_26;

sub.s32 %r157, %r30, %r163;
mov.u32 %r154, __smem;

$L__BB68_25:
ld.shared.v4.u32 {%r133, %r134, %r135, %r136}, [%r154];
add.s32 %r141, %r133, %r164;
add.s32 %r142, %r134, %r141;
add.s32 %r143, %r135, %r142;
add.s32 %r164, %r136, %r143;
add.s32 %r159, %r159, 4;
add.s32 %r154, %r154, 16;
add.s32 %r157, %r157, -4;
setp.ne.s32 %p20, %r157, 0;
@%p20 bra $L__BB68_25;

$L__BB68_26:
setp.eq.s32 %p21, %r163, 0;
@%p21 bra $L__BB68_29;

shl.b32 %r144, %r159, 2;
mov.u32 %r145, __smem;
add.s32 %r161, %r145, %r144;

$L__BB68_28:
.pragma "nounroll";
ld.shared.u32 %r146, [%r161];
add.s32 %r164, %r146, %r164;
add.s32 %r161, %r161, 4;
add.s32 %r163, %r163, -1;
setp.ne.s32 %p22, %r163, 0;
@%p22 bra $L__BB68_28;

$L__BB68_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r164;

$L__BB68_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<22>;
.reg .b32 %r<157>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch[48];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB69_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB69_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB69_6;

shl.b32 %r63, %r6, 7;
add.s32 %r139, %r63, %r3;
setp.ge.u32 %p3, %r139, %r52;
mov.u32 %r144, 0;
@%p3 bra $L__BB69_11;

shl.b32 %r8, %r5, 7;

$L__BB69_5:
mul.wide.u32 %rd5, %r139, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r144, %r65, %r144;
add.s32 %r139, %r139, %r8;
setp.lt.u32 %p4, %r139, %r52;
@%p4 bra $L__BB69_5;
bra.uni $L__BB69_11;

$L__BB69_6:
shl.b32 %r67, %r6, 8;
add.s32 %r141, %r67, %r3;
setp.ge.u32 %p5, %r141, %r52;
mov.u32 %r144, 0;
@%p5 bra $L__BB69_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 8;

$L__BB69_8:
cvt.u64.u32 %rd7, %r141;
mul.wide.u32 %rd8, %r141, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r144, %r69, %r144;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB69_10;

add.s32 %r70, %r141, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r144, %r71, %r144;

$L__BB69_10:
add.s32 %r141, %r141, %r14;
setp.lt.u32 %p7, %r141, %r52;
@%p7 bra $L__BB69_8;

$L__BB69_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r144, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 6;
shl.b32 %r79, %r25, 1;
mov.u32 %r80, 3;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r145, %r72;
@%p8 bra $L__BB69_13;

atom.shared.or.b32 %r145, [%r75], %r24;

$L__BB69_13:
mov.u32 %r82, 31;
shfl.sync.idx.b32 %r85|%p9, %r145, %r72, %r82, %r77;
or.b32 %r86, %r85, %r24;
and.b32 %r87, %r86, %r26;
setp.eq.s32 %p10, %r87, %r26;
@%p10 bra $L__BB69_15;
bra.uni $L__BB69_14;

$L__BB69_15:
and.b32 %r90, %r4, 30;
setp.ne.s32 %p12, %r90, 0;
@%p12 bra $L__BB69_17;

and.b32 %r92, %r4, 1;
and.b32 %r94, %r4, -64;
shr.u32 %r95, %r94, 5;
or.b32 %r96, %r95, %r92;
shl.b32 %r97, %r96, 2;
add.s32 %r99, %r75, %r97;
ld.shared.u32 %r100, [%r99+32];

	mov.u32 %r91, %laneid;

	and.b32 %r101, %r91, -2;
shl.b32 %r103, %r80, %r101;
mov.u32 %r104, 7711;
shfl.sync.bfly.b32 %r105|%p13, %r100, %r76, %r104, %r103;
add.s32 %r106, %r105, %r100;
st.shared.u32 [%r99+32], %r106;

$L__BB69_17:
bar.warp.sync -1;
@%p8 bra $L__BB69_19;

not.b32 %r107, %r26;
atom.shared.and.b32 %r109, [%r75], %r107;
bra.uni $L__BB69_19;

$L__BB69_14:
ld.volatile.shared.u32 %r88, [_ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch];
and.b32 %r89, %r88, %r24;
setp.eq.s32 %p11, %r89, 0;
@%p11 bra $L__BB69_19;
bra.uni $L__BB69_14;

$L__BB69_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r110, %r4, 63;
setp.ne.s32 %p15, %r110, 0;
@%p15 bra $L__BB69_21;

shl.b32 %r111, %r25, 2;
mov.u32 %r112, __smem;
add.s32 %r113, %r112, %r111;
st.shared.u32 [%r113], %r29;

$L__BB69_21:
barrier.sync 0;
setp.ne.s32 %p16, %r3, 0;
@%p16 bra $L__BB69_30;

mul.lo.s32 %r115, %r2, %r1;
mov.u32 %r116, %ntid.z;
mad.lo.s32 %r117, %r115, %r116, 63;
shr.u32 %r30, %r117, 6;
setp.eq.s32 %p17, %r30, 0;
mov.u32 %r156, 0;
@%p17 bra $L__BB69_29;

add.s32 %r121, %r30, -1;
and.b32 %r155, %r30, 3;
setp.lt.u32 %p18, %r121, 3;
mov.u32 %r151, 0;
mov.u32 %r156, %r151;
@%p18 bra $L__BB69_26;

sub.s32 %r149, %r30, %r155;
mov.u32 %r146, __smem;

$L__BB69_25:
ld.shared.v4.u32 {%r125, %r126, %r127, %r128}, [%r146];
add.s32 %r133, %r125, %r156;
add.s32 %r134, %r126, %r133;
add.s32 %r135, %r127, %r134;
add.s32 %r156, %r128, %r135;
add.s32 %r151, %r151, 4;
add.s32 %r146, %r146, 16;
add.s32 %r149, %r149, -4;
setp.ne.s32 %p19, %r149, 0;
@%p19 bra $L__BB69_25;

$L__BB69_26:
setp.eq.s32 %p20, %r155, 0;
@%p20 bra $L__BB69_29;

shl.b32 %r136, %r151, 2;
mov.u32 %r137, __smem;
add.s32 %r153, %r137, %r136;

$L__BB69_28:
.pragma "nounroll";
ld.shared.u32 %r138, [%r153];
add.s32 %r156, %r138, %r156;
add.s32 %r153, %r153, 4;
add.s32 %r155, %r155, -1;
setp.ne.s32 %p21, %r155, 0;
@%p21 bra $L__BB69_28;

$L__BB69_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r156;

$L__BB69_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<113>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_jE7scratch[40];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r45, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r46, %tid.z;
mov.u32 %r47, %tid.y;
mad.lo.s32 %r48, %r1, %r46, %r47;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r48, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB70_2;

shl.b32 %r49, %r4, 2;
mov.u32 %r50, _ZZ20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_jE7scratch;
add.s32 %r51, %r50, %r49;
mov.u32 %r52, 0;
st.shared.u32 [%r51], %r52;

$L__BB70_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r53, %r45, -1;
and.b32 %r54, %r53, %r45;
setp.eq.s32 %p2, %r54, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB70_6;

shl.b32 %r56, %r6, 6;
add.s32 %r96, %r56, %r3;
setp.ge.u32 %p3, %r96, %r45;
mov.u32 %r101, 0;
@%p3 bra $L__BB70_11;

shl.b32 %r8, %r5, 6;

$L__BB70_5:
mul.wide.u32 %rd5, %r96, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r58, [%rd6];
add.s32 %r101, %r58, %r101;
add.s32 %r96, %r96, %r8;
setp.lt.u32 %p4, %r96, %r45;
@%p4 bra $L__BB70_5;
bra.uni $L__BB70_11;

$L__BB70_6:
shl.b32 %r60, %r6, 7;
add.s32 %r98, %r60, %r3;
setp.ge.u32 %p5, %r98, %r45;
mov.u32 %r101, 0;
@%p5 bra $L__BB70_11;

cvt.u64.u32 %rd2, %r45;
shl.b32 %r14, %r5, 7;

$L__BB70_8:
cvt.u64.u32 %rd7, %r98;
mul.wide.u32 %rd8, %r98, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r62, [%rd9];
add.s32 %r101, %r62, %r101;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB70_10;

add.s32 %r63, %r98, %r2;
mul.wide.u32 %rd11, %r63, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r64, [%rd12];
add.s32 %r101, %r64, %r101;

$L__BB70_10:
add.s32 %r98, %r98, %r14;
setp.lt.u32 %p7, %r98, %r45;
@%p7 bra $L__BB70_8;

$L__BB70_11:
mov.u32 %r65, -1;
redux.sync.add.s32 %r22, %r101, %r65;
and.b32 %r66, %r4, 31;
setp.ne.s32 %p8, %r66, 0;
@%p8 bra $L__BB70_13;

shr.u32 %r67, %r4, 3;
and.b32 %r68, %r67, 536870908;
mov.u32 %r69, __smem;
add.s32 %r70, %r69, %r68;
st.shared.u32 [%r70], %r22;

$L__BB70_13:
barrier.sync 0;
setp.ne.s32 %p9, %r3, 0;
@%p9 bra $L__BB70_22;

mul.lo.s32 %r72, %r2, %r1;
mov.u32 %r73, %ntid.z;
mad.lo.s32 %r74, %r72, %r73, 31;
shr.u32 %r23, %r74, 5;
setp.eq.s32 %p10, %r23, 0;
mov.u32 %r112, 0;
@%p10 bra $L__BB70_21;

add.s32 %r78, %r23, -1;
and.b32 %r111, %r23, 3;
setp.lt.u32 %p11, %r78, 3;
mov.u32 %r107, 0;
mov.u32 %r112, %r107;
@%p11 bra $L__BB70_18;

sub.s32 %r105, %r23, %r111;
mov.u32 %r102, __smem;

$L__BB70_17:
ld.shared.v4.u32 {%r82, %r83, %r84, %r85}, [%r102];
add.s32 %r90, %r82, %r112;
add.s32 %r91, %r83, %r90;
add.s32 %r92, %r84, %r91;
add.s32 %r112, %r85, %r92;
add.s32 %r107, %r107, 4;
add.s32 %r102, %r102, 16;
add.s32 %r105, %r105, -4;
setp.ne.s32 %p12, %r105, 0;
@%p12 bra $L__BB70_17;

$L__BB70_18:
setp.eq.s32 %p13, %r111, 0;
@%p13 bra $L__BB70_21;

shl.b32 %r93, %r107, 2;
mov.u32 %r94, __smem;
add.s32 %r109, %r94, %r93;

$L__BB70_20:
.pragma "nounroll";
ld.shared.u32 %r95, [%r109];
add.s32 %r112, %r95, %r112;
add.s32 %r109, %r109, 4;
add.s32 %r111, %r111, -1;
setp.ne.s32 %p14, %r111, 0;
@%p14 bra $L__BB70_20;

$L__BB70_21:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r112;

$L__BB70_22:
ret;

}

.visible .entry _Z7reduce0IfEvPT_S1_j(
.param .u64 _Z7reduce0IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<16>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IfEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce0IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f32 %f8, 0f00000000;
@%p1 bra $L__BB71_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

$L__BB71_2:
shl.b32 %r9, %r3, 2;
mov.u32 %r10, __smem;
add.s32 %r5, %r10, %r9;
st.shared.f32 [%r5], %f8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB71_7;

mov.u32 %r15, 1;

$L__BB71_4:
shl.b32 %r7, %r15, 1;
rem.u32 %r12, %r3, %r7;
setp.ne.s32 %p3, %r12, 0;
@%p3 bra $L__BB71_6;

shl.b32 %r13, %r15, 2;
add.s32 %r14, %r5, %r13;
ld.shared.f32 %f4, [%r5];
ld.shared.f32 %f5, [%r14];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r5], %f6;

$L__BB71_6:
barrier.sync 0;
setp.lt.u32 %p4, %r7, %r1;
mov.u32 %r15, %r7;
@%p4 bra $L__BB71_4;

$L__BB71_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB71_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

$L__BB71_9:
ret;

}

.visible .entry _Z7reduce1IfEvPT_S1_j(
.param .u64 _Z7reduce1IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<20>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IfEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce1IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f32 %f8, 0f00000000;
@%p1 bra $L__BB72_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

$L__BB72_2:
shl.b32 %r9, %r3, 2;
mov.u32 %r10, __smem;
add.s32 %r11, %r10, %r9;
st.shared.f32 [%r11], %f8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB72_7;

mov.u32 %r19, 1;

$L__BB72_4:
shl.b32 %r6, %r19, 1;
mul.lo.s32 %r7, %r6, %r3;
setp.ge.u32 %p3, %r7, %r1;
@%p3 bra $L__BB72_6;

add.s32 %r13, %r7, %r19;
shl.b32 %r14, %r13, 2;
add.s32 %r16, %r10, %r14;
shl.b32 %r17, %r7, 2;
add.s32 %r18, %r10, %r17;
ld.shared.f32 %f4, [%r18];
ld.shared.f32 %f5, [%r16];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r18], %f6;

$L__BB72_6:
barrier.sync 0;
setp.lt.u32 %p4, %r6, %r1;
mov.u32 %r19, %r6;
@%p4 bra $L__BB72_4;

$L__BB72_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB72_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

$L__BB72_9:
ret;

}

.visible .entry _Z7reduce2IfEvPT_S1_j(
.param .u64 _Z7reduce2IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce2IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce2IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<15>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce2IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce2IfEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce2IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r9;
mov.f32 %f8, 0f00000000;
@%p1 bra $L__BB73_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

$L__BB73_2:
shl.b32 %r10, %r3, 2;
mov.u32 %r11, __smem;
add.s32 %r5, %r11, %r10;
st.shared.f32 [%r5], %f8;
barrier.sync 0;
shr.u32 %r14, %r1, 1;
setp.eq.s32 %p2, %r14, 0;
@%p2 bra $L__BB73_7;

$L__BB73_4:
setp.ge.u32 %p3, %r3, %r14;
@%p3 bra $L__BB73_6;

shl.b32 %r12, %r14, 2;
add.s32 %r13, %r5, %r12;
ld.shared.f32 %f4, [%r5];
ld.shared.f32 %f5, [%r13];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r5], %f6;

$L__BB73_6:
barrier.sync 0;
shr.u32 %r14, %r14, 1;
setp.ne.s32 %p4, %r14, 0;
@%p4 bra $L__BB73_4;

$L__BB73_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB73_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

$L__BB73_9:
ret;

}

.visible .entry _Z7reduce3IfEvPT_S1_j(
.param .u64 _Z7reduce3IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IfEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .f32 %f<17>;
.reg .b32 %r<17>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IfEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce3IfEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
mov.f32 %f15, 0f00000000;
@%p1 bra $L__BB74_2;

mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f15, [%rd5];

$L__BB74_2:
add.s32 %r5, %r4, %r1;
setp.ge.u32 %p2, %r5, %r10;
@%p2 bra $L__BB74_4;

mul.wide.u32 %rd6, %r5, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f10, [%rd7];
add.f32 %f15, %f15, %f10;

$L__BB74_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r6, %r13, %r12;
st.shared.f32 [%r6], %f15;
barrier.sync 0;
shr.u32 %r16, %r1, 1;
setp.eq.s32 %p3, %r16, 0;
@%p3 bra $L__BB74_9;

$L__BB74_6:
setp.ge.u32 %p4, %r3, %r16;
@%p4 bra $L__BB74_8;

shl.b32 %r14, %r16, 2;
add.s32 %r15, %r6, %r14;
ld.shared.f32 %f11, [%r15];
add.f32 %f15, %f15, %f11;
st.shared.f32 [%r6], %f15;

$L__BB74_8:
barrier.sync 0;
shr.u32 %r16, %r16, 1;
setp.ne.s32 %p5, %r16, 0;
@%p5 bra $L__BB74_6;

$L__BB74_9:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra $L__BB74_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f15;

$L__BB74_11:
ret;

}

.visible .entry _Z7reduce4IfLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj512EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB75_2;

ld.global.f32 %f28, [%rd1];

$L__BB75_2:
add.s32 %r11, %r4, 512;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB75_4;

ld.global.f32 %f12, [%rd1+2048];
add.f32 %f28, %f28, %f12;

$L__BB75_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB75_9;

mov.u32 %r37, %r1;

$L__BB75_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB75_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB75_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB75_6;

$L__BB75_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB75_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB75_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB75_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB75_13:
ret;

}

.visible .entry _Z7reduce4IfLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj256EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB76_2;

ld.global.f32 %f28, [%rd1];

$L__BB76_2:
add.s32 %r11, %r4, 256;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB76_4;

ld.global.f32 %f12, [%rd1+1024];
add.f32 %f28, %f28, %f12;

$L__BB76_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB76_9;

mov.u32 %r37, %r1;

$L__BB76_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB76_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB76_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB76_6;

$L__BB76_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB76_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB76_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB76_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB76_13:
ret;

}

.visible .entry _Z7reduce4IfLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj128EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB77_2;

ld.global.f32 %f28, [%rd1];

$L__BB77_2:
add.s32 %r11, %r4, 128;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB77_4;

ld.global.f32 %f12, [%rd1+512];
add.f32 %f28, %f28, %f12;

$L__BB77_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB77_9;

mov.u32 %r37, %r1;

$L__BB77_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB77_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB77_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB77_6;

$L__BB77_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB77_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB77_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB77_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB77_13:
ret;

}

.visible .entry _Z7reduce4IfLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj64EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB78_2;

ld.global.f32 %f28, [%rd1];

$L__BB78_2:
add.s32 %r11, %r4, 64;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB78_4;

ld.global.f32 %f12, [%rd1+256];
add.f32 %f28, %f28, %f12;

$L__BB78_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB78_9;

mov.u32 %r37, %r1;

$L__BB78_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB78_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB78_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB78_6;

$L__BB78_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB78_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB78_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB78_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB78_13:
ret;

}

.visible .entry _Z7reduce4IfLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj32EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB79_2;

ld.global.f32 %f26, [%rd1];

$L__BB79_2:
add.s32 %r11, %r4, 32;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB79_4;

ld.global.f32 %f12, [%rd1+128];
add.f32 %f26, %f26, %f12;

$L__BB79_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB79_9;

mov.u32 %r37, %r1;

$L__BB79_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB79_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB79_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB79_6;

$L__BB79_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB79_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB79_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB79_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB79_13:
ret;

}

.visible .entry _Z7reduce4IfLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj16EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB80_2;

ld.global.f32 %f26, [%rd1];

$L__BB80_2:
add.s32 %r11, %r4, 16;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB80_4;

ld.global.f32 %f12, [%rd1+64];
add.f32 %f26, %f26, %f12;

$L__BB80_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB80_9;

mov.u32 %r37, %r1;

$L__BB80_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB80_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB80_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB80_6;

$L__BB80_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB80_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB80_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB80_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB80_13:
ret;

}

.visible .entry _Z7reduce4IfLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj8EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB81_2;

ld.global.f32 %f26, [%rd1];

$L__BB81_2:
add.s32 %r11, %r4, 8;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB81_4;

ld.global.f32 %f12, [%rd1+32];
add.f32 %f26, %f26, %f12;

$L__BB81_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB81_9;

mov.u32 %r37, %r1;

$L__BB81_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB81_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB81_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB81_6;

$L__BB81_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB81_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB81_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB81_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB81_13:
ret;

}

.visible .entry _Z7reduce4IfLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj4EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB82_2;

ld.global.f32 %f26, [%rd1];

$L__BB82_2:
add.s32 %r11, %r4, 4;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB82_4;

ld.global.f32 %f12, [%rd1+16];
add.f32 %f26, %f26, %f12;

$L__BB82_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB82_9;

mov.u32 %r37, %r1;

$L__BB82_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB82_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB82_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB82_6;

$L__BB82_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB82_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB82_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB82_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB82_13:
ret;

}

.visible .entry _Z7reduce4IfLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj2EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB83_2;

ld.global.f32 %f26, [%rd1];

$L__BB83_2:
add.s32 %r11, %r4, 2;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB83_4;

ld.global.f32 %f12, [%rd1+8];
add.f32 %f26, %f26, %f12;

$L__BB83_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB83_9;

mov.u32 %r37, %r1;

$L__BB83_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB83_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB83_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB83_6;

$L__BB83_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB83_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB83_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB83_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB83_13:
ret;

}

.visible .entry _Z7reduce4IfLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB84_2;

ld.global.f32 %f26, [%rd1];

$L__BB84_2:
add.s32 %r11, %r4, 1;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB84_4;

ld.global.f32 %f12, [%rd1+4];
add.f32 %f26, %f26, %f12;

$L__BB84_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB84_9;

mov.u32 %r37, %r1;

$L__BB84_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB84_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB84_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB84_6;

$L__BB84_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB84_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB84_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB84_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB84_13:
ret;

}

.visible .entry _Z7reduce5IfLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj512EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f30, 0f00000000;
@%p1 bra $L__BB85_2;

ld.global.f32 %f30, [%rd1];

$L__BB85_2:
add.s32 %r8, %r3, 512;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB85_4;

ld.global.f32 %f14, [%rd1+2048];
add.f32 %f30, %f30, %f14;

$L__BB85_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB85_6;

ld.shared.f32 %f15, [%r4+1024];
add.f32 %f30, %f30, %f15;
st.shared.f32 [%r4], %f30;

$L__BB85_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB85_8;

ld.shared.f32 %f16, [%r4+512];
add.f32 %f30, %f30, %f16;
st.shared.f32 [%r4], %f30;

$L__BB85_8:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB85_10;

ld.shared.f32 %f17, [%r4+256];
add.f32 %f30, %f30, %f17;
st.shared.f32 [%r4], %f30;

$L__BB85_10:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p6, %r5, 31;
@%p6 bra $L__BB85_12;

ld.shared.f32 %f18, [%r4+128];
add.f32 %f19, %f30, %f18;
mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p7, %r16, %r19, %r18, %r20;
mov.b32 %f20, %r21;
add.f32 %f21, %f19, %f20;
mov.b32 %r22, %f21;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p8, %r22, %r23, %r18, %r20;
mov.b32 %f22, %r24;
add.f32 %f23, %f21, %f22;
mov.b32 %r25, %f23;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p9, %r25, %r26, %r18, %r20;
mov.b32 %f24, %r27;
add.f32 %f25, %f23, %f24;
mov.b32 %r28, %f25;
shfl.sync.down.b32 %r29|%p10, %r28, %r17, %r18, %r20;
mov.b32 %f26, %r29;
add.f32 %f27, %f25, %f26;
mov.b32 %r30, %f27;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p11, %r30, %r31, %r18, %r20;
mov.b32 %f28, %r32;
add.f32 %f30, %f27, %f28;

$L__BB85_12:
setp.ne.s32 %p12, %r5, 0;
@%p12 bra $L__BB85_14;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f30;

$L__BB85_14:
ret;

}

.visible .entry _Z7reduce5IfLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj256EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f27, 0f00000000;
@%p1 bra $L__BB86_2;

ld.global.f32 %f27, [%rd1];

$L__BB86_2:
add.s32 %r8, %r3, 256;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB86_4;

ld.global.f32 %f12, [%rd1+1024];
add.f32 %f27, %f27, %f12;

$L__BB86_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB86_6;

ld.shared.f32 %f13, [%r4+512];
add.f32 %f27, %f27, %f13;
st.shared.f32 [%r4], %f27;

$L__BB86_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB86_8;

ld.shared.f32 %f14, [%r4+256];
add.f32 %f27, %f27, %f14;
st.shared.f32 [%r4], %f27;

$L__BB86_8:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p5, %r5, 31;
@%p5 bra $L__BB86_10;

ld.shared.f32 %f15, [%r4+128];
add.f32 %f16, %f27, %f15;
mov.b32 %r16, %f16;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p6, %r16, %r19, %r18, %r20;
mov.b32 %f17, %r21;
add.f32 %f18, %f16, %f17;
mov.b32 %r22, %f18;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p7, %r22, %r23, %r18, %r20;
mov.b32 %f19, %r24;
add.f32 %f20, %f18, %f19;
mov.b32 %r25, %f20;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r26, %r18, %r20;
mov.b32 %f21, %r27;
add.f32 %f22, %f20, %f21;
mov.b32 %r28, %f22;
shfl.sync.down.b32 %r29|%p9, %r28, %r17, %r18, %r20;
mov.b32 %f23, %r29;
add.f32 %f24, %f22, %f23;
mov.b32 %r30, %f24;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p10, %r30, %r31, %r18, %r20;
mov.b32 %f25, %r32;
add.f32 %f27, %f24, %f25;

$L__BB86_10:
setp.ne.s32 %p11, %r5, 0;
@%p11 bra $L__BB86_12;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f27;

$L__BB86_12:
ret;

}

.visible .entry _Z7reduce5IfLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj128EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f24, 0f00000000;
@%p1 bra $L__BB87_2;

ld.global.f32 %f24, [%rd1];

$L__BB87_2:
add.s32 %r8, %r3, 128;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB87_4;

ld.global.f32 %f10, [%rd1+512];
add.f32 %f24, %f24, %f10;

$L__BB87_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB87_6;

ld.shared.f32 %f11, [%r4+256];
add.f32 %f24, %f24, %f11;
st.shared.f32 [%r4], %f24;

$L__BB87_6:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p4, %r5, 31;
@%p4 bra $L__BB87_8;

ld.shared.f32 %f12, [%r4+128];
add.f32 %f13, %f24, %f12;
mov.b32 %r16, %f13;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p5, %r16, %r19, %r18, %r20;
mov.b32 %f14, %r21;
add.f32 %f15, %f13, %f14;
mov.b32 %r22, %f15;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p6, %r22, %r23, %r18, %r20;
mov.b32 %f16, %r24;
add.f32 %f17, %f15, %f16;
mov.b32 %r25, %f17;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p7, %r25, %r26, %r18, %r20;
mov.b32 %f18, %r27;
add.f32 %f19, %f17, %f18;
mov.b32 %r28, %f19;
shfl.sync.down.b32 %r29|%p8, %r28, %r17, %r18, %r20;
mov.b32 %f20, %r29;
add.f32 %f21, %f19, %f20;
mov.b32 %r30, %f21;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r18, %r20;
mov.b32 %f22, %r32;
add.f32 %f24, %f21, %f22;

$L__BB87_8:
setp.ne.s32 %p10, %r5, 0;
@%p10 bra $L__BB87_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f24;

$L__BB87_10:
ret;

}

.visible .entry _Z7reduce5IfLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<23>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj64EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB88_2;

ld.global.f32 %f21, [%rd1];

$L__BB88_2:
add.s32 %r8, %r3, 64;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB88_4;

ld.global.f32 %f8, [%rd1+256];
add.f32 %f21, %f21, %f8;

$L__BB88_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p3, %r5, 31;
@%p3 bra $L__BB88_6;

ld.shared.f32 %f9, [%r4+128];
add.f32 %f10, %f21, %f9;
mov.b32 %r16, %f10;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f11, %r21;
add.f32 %f12, %f10, %f11;
mov.b32 %r22, %f12;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f13, %r24;
add.f32 %f14, %f12, %f13;
mov.b32 %r25, %f14;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f15, %r27;
add.f32 %f16, %f14, %f15;
mov.b32 %r28, %f16;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f17, %r29;
add.f32 %f18, %f16, %f17;
mov.b32 %r30, %f18;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f19, %r32;
add.f32 %f21, %f18, %f19;

$L__BB88_6:
setp.ne.s32 %p9, %r5, 0;
@%p9 bra $L__BB88_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f21;

$L__BB88_8:
ret;

}

.visible .entry _Z7reduce5IfLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj32EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB89_2;

ld.global.f32 %f19, [%rd1];

$L__BB89_2:
add.s32 %r7, %r3, 32;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB89_4;

ld.global.f32 %f8, [%rd1+128];
add.f32 %f19, %f19, %f8;

$L__BB89_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB89_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB89_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB89_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB89_8:
ret;

}

.visible .entry _Z7reduce5IfLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj16EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB90_2;

ld.global.f32 %f19, [%rd1];

$L__BB90_2:
add.s32 %r7, %r3, 16;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB90_4;

ld.global.f32 %f8, [%rd1+64];
add.f32 %f19, %f19, %f8;

$L__BB90_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB90_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB90_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB90_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB90_8:
ret;

}

.visible .entry _Z7reduce5IfLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj8EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB91_2;

ld.global.f32 %f19, [%rd1];

$L__BB91_2:
add.s32 %r7, %r3, 8;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB91_4;

ld.global.f32 %f8, [%rd1+32];
add.f32 %f19, %f19, %f8;

$L__BB91_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB91_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB91_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB91_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB91_8:
ret;

}

.visible .entry _Z7reduce5IfLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj4EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB92_2;

ld.global.f32 %f19, [%rd1];

$L__BB92_2:
add.s32 %r7, %r3, 4;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB92_4;

ld.global.f32 %f8, [%rd1+16];
add.f32 %f19, %f19, %f8;

$L__BB92_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB92_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB92_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB92_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB92_8:
ret;

}

.visible .entry _Z7reduce5IfLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj2EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB93_2;

ld.global.f32 %f19, [%rd1];

$L__BB93_2:
add.s32 %r7, %r3, 2;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB93_4;

ld.global.f32 %f8, [%rd1+8];
add.f32 %f19, %f19, %f8;

$L__BB93_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB93_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB93_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB93_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB93_8:
ret;

}

.visible .entry _Z7reduce5IfLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj1EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB94_2;

ld.global.f32 %f19, [%rd1];

$L__BB94_2:
add.s32 %r7, %r3, 1;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB94_4;

ld.global.f32 %f8, [%rd1+4];
add.f32 %f19, %f19, %f8;

$L__BB94_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB94_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB94_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB94_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB94_8:
ret;

}

.visible .entry _Z7reduce6IfLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<14>;
.reg .f32 %f<39>;
.reg .b32 %r<39>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r10, %ctaid.x;
shl.b32 %r11, %r10, 10;
mov.u32 %r1, %tid.x;
add.s32 %r38, %r11, %r1;
setp.ge.u32 %p1, %r38, %r9;
mov.f32 %f32, 0f00000000;
@%p1 bra $L__BB95_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r3, %r12, 10;

$L__BB95_2:
mul.wide.u32 %rd4, %r38, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f16, [%rd5];
add.f32 %f32, %f32, %f16;
add.s32 %r5, %r38, 512;
setp.ge.u32 %p2, %r5, %r9;
@%p2 bra $L__BB95_4;

mul.wide.u32 %rd6, %r5, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f17, [%rd7];
add.f32 %f32, %f32, %f17;

$L__BB95_4:
add.s32 %r38, %r38, %r3;
setp.lt.u32 %p3, %r38, %r9;
@%p3 bra $L__BB95_2;

$L__BB95_5:
shl.b32 %r13, %r1, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.f32 [%r7], %f32;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 255;
@%p4 bra $L__BB95_7;

ld.shared.f32 %f18, [%r7+1024];
add.f32 %f32, %f32, %f18;
st.shared.f32 [%r7], %f32;

$L__BB95_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 127;
@%p5 bra $L__BB95_9;

ld.shared.f32 %f19, [%r7+512];
add.f32 %f32, %f32, %f19;
st.shared.f32 [%r7], %f32;

$L__BB95_9:
barrier.sync 0;
setp.gt.u32 %p6, %r1, 63;
@%p6 bra $L__BB95_11;

ld.shared.f32 %f20, [%r7+256];
add.f32 %f32, %f32, %f20;
st.shared.f32 [%r7], %f32;

$L__BB95_11:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r1;
setp.gt.u32 %p7, %r8, 31;
@%p7 bra $L__BB95_13;

ld.shared.f32 %f21, [%r7+128];
add.f32 %f22, %f32, %f21;
mov.b32 %r20, %f22;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p8, %r20, %r23, %r22, %r24;
mov.b32 %f23, %r25;
add.f32 %f24, %f22, %f23;
mov.b32 %r26, %f24;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p9, %r26, %r27, %r22, %r24;
mov.b32 %f25, %r28;
add.f32 %f26, %f24, %f25;
mov.b32 %r29, %f26;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p10, %r29, %r30, %r22, %r24;
mov.b32 %f27, %r31;
add.f32 %f28, %f26, %f27;
mov.b32 %r32, %f28;
shfl.sync.down.b32 %r33|%p11, %r32, %r21, %r22, %r24;
mov.b32 %f29, %r33;
add.f32 %f30, %f28, %f29;
mov.b32 %r34, %f30;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p12, %r34, %r35, %r22, %r24;
mov.b32 %f31, %r36;
add.f32 %f32, %f30, %f31;

$L__BB95_13:
setp.ne.s32 %p13, %r8, 0;
@%p13 bra $L__BB95_15;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r10, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f32;

$L__BB95_15:
ret;

}

.visible .entry _Z7reduce6IfLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<39>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r10, %ctaid.x;
shl.b32 %r11, %r10, 9;
mov.u32 %r1, %tid.x;
add.s32 %r38, %r11, %r1;
setp.ge.u32 %p1, %r38, %r9;
mov.f32 %f29, 0f00000000;
@%p1 bra $L__BB96_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r3, %r12, 9;

$L__BB96_2:
mul.wide.u32 %rd4, %r38, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f14, [%rd5];
add.f32 %f29, %f29, %f14;
add.s32 %r5, %r38, 256;
setp.ge.u32 %p2, %r5, %r9;
@%p2 bra $L__BB96_4;

mul.wide.u32 %rd6, %r5, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f15, [%rd7];
add.f32 %f29, %f29, %f15;

$L__BB96_4:
add.s32 %r38, %r38, %r3;
setp.lt.u32 %p3, %r38, %r9;
@%p3 bra $L__BB96_2;

$L__BB96_5:
shl.b32 %r13, %r1, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.f32 [%r7], %f29;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 127;
@%p4 bra $L__BB96_7;

ld.shared.f32 %f16, [%r7+512];
add.f32 %f29, %f29, %f16;
st.shared.f32 [%r7], %f29;

$L__BB96_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 63;
@%p5 bra $L__BB96_9;

ld.shared.f32 %f17, [%r7+256];
add.f32 %f29, %f29, %f17;
st.shared.f32 [%r7], %f29;

$L__BB96_9:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r1;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB96_11;

ld.shared.f32 %f18, [%r7+128];
add.f32 %f19, %f29, %f18;
mov.b32 %r20, %f19;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f20, %r25;
add.f32 %f21, %f19, %f20;
mov.b32 %r26, %f21;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f22, %r28;
add.f32 %f23, %f21, %f22;
mov.b32 %r29, %f23;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f24, %r31;
add.f32 %f25, %f23, %f24;
mov.b32 %r32, %f25;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f26, %r33;
add.f32 %f27, %f25, %f26;
mov.b32 %r34, %f27;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f28, %r36;
add.f32 %f29, %f27, %f28;

$L__BB96_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB96_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r10, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f29;

$L__BB96_13:
ret;

}

.visible .entry _Z7reduce6IfLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r11, %r2;
setp.ge.u32 %p1, %r37, %r10;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB97_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 8;

$L__BB97_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f26, %f26, %f12;
add.s32 %r6, %r37, 128;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB97_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f13, [%rd7];
add.f32 %f26, %f26, %f13;

$L__BB97_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r10;
@%p3 bra $L__BB97_2;

$L__BB97_5:
shl.b32 %r13, %r2, 2;
mov.u32 %r14, __smem;
add.s32 %r8, %r14, %r13;
st.shared.f32 [%r8], %f26;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB97_7;

ld.shared.f32 %f14, [%r8+256];
add.f32 %f26, %f26, %f14;
st.shared.f32 [%r8], %f26;

$L__BB97_7:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p5, %r9, 31;
@%p5 bra $L__BB97_9;

ld.shared.f32 %f15, [%r8+128];
add.f32 %f16, %f26, %f15;
mov.b32 %r20, %f16;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p6, %r20, %r23, %r22, %r24;
mov.b32 %f17, %r25;
add.f32 %f18, %f16, %f17;
mov.b32 %r26, %f18;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p7, %r26, %r27, %r22, %r24;
mov.b32 %f19, %r28;
add.f32 %f20, %f18, %f19;
mov.b32 %r29, %f20;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p8, %r29, %r30, %r22, %r24;
mov.b32 %f21, %r31;
add.f32 %f22, %f20, %f21;
mov.b32 %r32, %f22;
shfl.sync.down.b32 %r33|%p9, %r32, %r21, %r22, %r24;
mov.b32 %f23, %r33;
add.f32 %f24, %f22, %f23;
mov.b32 %r34, %f24;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p10, %r34, %r35, %r22, %r24;
mov.b32 %f25, %r36;
add.f32 %f26, %f24, %f25;

$L__BB97_9:
setp.ne.s32 %p11, %r9, 0;
@%p11 bra $L__BB97_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f26;

$L__BB97_11:
ret;

}

.visible .entry _Z7reduce6IfLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r11, %r2;
setp.ge.u32 %p1, %r37, %r10;
mov.f32 %f23, 0f00000000;
@%p1 bra $L__BB98_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 7;

$L__BB98_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f23, %f23, %f10;
add.s32 %r6, %r37, 64;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB98_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f23, %f23, %f11;

$L__BB98_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r10;
@%p3 bra $L__BB98_2;

$L__BB98_5:
shl.b32 %r13, %r2, 2;
mov.u32 %r14, __smem;
add.s32 %r8, %r14, %r13;
st.shared.f32 [%r8], %f23;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p4, %r9, 31;
@%p4 bra $L__BB98_7;

ld.shared.f32 %f12, [%r8+128];
add.f32 %f13, %f23, %f12;
mov.b32 %r20, %f13;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f13, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f23, %f21, %f22;

$L__BB98_7:
setp.ne.s32 %p10, %r9, 0;
@%p10 bra $L__BB98_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f23;

$L__BB98_9:
ret;

}

.visible .entry _Z7reduce6IfLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB99_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;

$L__BB99_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 32;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB99_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB99_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB99_2;

$L__BB99_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB99_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB99_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB99_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB99_9:
ret;

}

.visible .entry _Z7reduce6IfLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB100_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 5;

$L__BB100_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 16;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB100_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB100_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB100_2;

$L__BB100_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB100_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB100_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB100_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB100_9:
ret;

}

.visible .entry _Z7reduce6IfLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB101_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 4;

$L__BB101_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 8;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB101_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB101_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB101_2;

$L__BB101_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB101_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB101_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB101_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB101_9:
ret;

}

.visible .entry _Z7reduce6IfLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB102_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 3;

$L__BB102_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 4;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB102_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB102_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB102_2;

$L__BB102_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB102_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB102_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB102_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB102_9:
ret;

}

.visible .entry _Z7reduce6IfLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB103_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 2;

$L__BB103_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 2;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB103_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB103_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB103_2;

$L__BB103_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB103_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB103_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB103_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB103_9:
ret;

}

.visible .entry _Z7reduce6IfLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB104_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 1;

$L__BB104_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 1;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB104_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB104_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB104_2;

$L__BB104_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB104_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB104_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB104_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB104_9:
ret;

}

.visible .entry _Z7reduce6IfLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f30, 0f00000000;
@%p1 bra $L__BB105_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB105_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f14, [%rd5];
add.f32 %f30, %f30, %f14;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB105_2;

$L__BB105_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB105_5;

ld.shared.f32 %f15, [%r7+1024];
add.f32 %f30, %f30, %f15;
st.shared.f32 [%r7], %f30;

$L__BB105_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB105_7;

ld.shared.f32 %f16, [%r7+512];
add.f32 %f30, %f30, %f16;
st.shared.f32 [%r7], %f30;

$L__BB105_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB105_9;

ld.shared.f32 %f17, [%r7+256];
add.f32 %f30, %f30, %f17;
st.shared.f32 [%r7], %f30;

$L__BB105_9:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB105_11;

ld.shared.f32 %f18, [%r7+128];
add.f32 %f19, %f30, %f18;
mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p7, %r19, %r22, %r21, %r23;
mov.b32 %f20, %r24;
add.f32 %f21, %f19, %f20;
mov.b32 %r25, %f21;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p8, %r25, %r26, %r21, %r23;
mov.b32 %f22, %r27;
add.f32 %f23, %f21, %f22;
mov.b32 %r28, %f23;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p9, %r28, %r29, %r21, %r23;
mov.b32 %f24, %r30;
add.f32 %f25, %f23, %f24;
mov.b32 %r31, %f25;
shfl.sync.down.b32 %r32|%p10, %r31, %r20, %r21, %r23;
mov.b32 %f26, %r32;
add.f32 %f27, %f25, %f26;
mov.b32 %r33, %f27;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p11, %r33, %r34, %r21, %r23;
mov.b32 %f28, %r35;
add.f32 %f30, %f27, %f28;

$L__BB105_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB105_13;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f30;

$L__BB105_13:
ret;

}

.visible .entry _Z7reduce6IfLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f27, 0f00000000;
@%p1 bra $L__BB106_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB106_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f27, %f27, %f12;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB106_2;

$L__BB106_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB106_5;

ld.shared.f32 %f13, [%r7+512];
add.f32 %f27, %f27, %f13;
st.shared.f32 [%r7], %f27;

$L__BB106_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB106_7;

ld.shared.f32 %f14, [%r7+256];
add.f32 %f27, %f27, %f14;
st.shared.f32 [%r7], %f27;

$L__BB106_7:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p5, %r8, 31;
@%p5 bra $L__BB106_9;

ld.shared.f32 %f15, [%r7+128];
add.f32 %f16, %f27, %f15;
mov.b32 %r19, %f16;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p6, %r19, %r22, %r21, %r23;
mov.b32 %f17, %r24;
add.f32 %f18, %f16, %f17;
mov.b32 %r25, %f18;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r26, %r21, %r23;
mov.b32 %f19, %r27;
add.f32 %f20, %f18, %f19;
mov.b32 %r28, %f20;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r29, %r21, %r23;
mov.b32 %f21, %r30;
add.f32 %f22, %f20, %f21;
mov.b32 %r31, %f22;
shfl.sync.down.b32 %r32|%p9, %r31, %r20, %r21, %r23;
mov.b32 %f23, %r32;
add.f32 %f24, %f22, %f23;
mov.b32 %r33, %f24;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p10, %r33, %r34, %r21, %r23;
mov.b32 %f25, %r35;
add.f32 %f27, %f24, %f25;

$L__BB106_9:
setp.ne.s32 %p11, %r8, 0;
@%p11 bra $L__BB106_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f27;

$L__BB106_11:
ret;

}

.visible .entry _Z7reduce6IfLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f24, 0f00000000;
@%p1 bra $L__BB107_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB107_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f24, %f24, %f10;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB107_2;

$L__BB107_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB107_5;

ld.shared.f32 %f11, [%r7+256];
add.f32 %f24, %f24, %f11;
st.shared.f32 [%r7], %f24;

$L__BB107_5:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB107_7;

ld.shared.f32 %f12, [%r7+128];
add.f32 %f13, %f24, %f12;
mov.b32 %r19, %f13;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p5, %r19, %r22, %r21, %r23;
mov.b32 %f14, %r24;
add.f32 %f15, %f13, %f14;
mov.b32 %r25, %f15;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r21, %r23;
mov.b32 %f16, %r27;
add.f32 %f17, %f15, %f16;
mov.b32 %r28, %f17;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p7, %r28, %r29, %r21, %r23;
mov.b32 %f18, %r30;
add.f32 %f19, %f17, %f18;
mov.b32 %r31, %f19;
shfl.sync.down.b32 %r32|%p8, %r31, %r20, %r21, %r23;
mov.b32 %f20, %r32;
add.f32 %f21, %f19, %f20;
mov.b32 %r33, %f21;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p9, %r33, %r34, %r21, %r23;
mov.b32 %f22, %r35;
add.f32 %f24, %f21, %f22;

$L__BB107_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB107_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f24;

$L__BB107_9:
ret;

}

.visible .entry _Z7reduce6IfLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<23>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB108_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB108_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f21, %f21, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB108_2;

$L__BB108_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB108_5;

ld.shared.f32 %f9, [%r7+128];
add.f32 %f10, %f21, %f9;
mov.b32 %r19, %f10;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f15, %r30;
add.f32 %f16, %f14, %f15;
mov.b32 %r31, %f16;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f17, %r32;
add.f32 %f18, %f16, %f17;
mov.b32 %r33, %f18;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f19, %r35;
add.f32 %f21, %f18, %f19;

$L__BB108_5:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB108_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f21;

$L__BB108_7:
ret;

}

.visible .entry _Z7reduce6IfLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB109_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB109_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB109_2;

$L__BB109_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB109_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB109_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB109_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB109_7:
ret;

}

.visible .entry _Z7reduce6IfLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB110_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB110_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB110_2;

$L__BB110_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB110_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB110_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB110_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB110_7:
ret;

}

.visible .entry _Z7reduce6IfLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB111_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB111_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB111_2;

$L__BB111_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB111_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB111_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB111_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB111_7:
ret;

}

.visible .entry _Z7reduce6IfLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB112_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB112_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB112_2;

$L__BB112_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB112_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB112_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB112_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB112_7:
ret;

}

.visible .entry _Z7reduce6IfLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB113_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB113_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB113_2;

$L__BB113_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB113_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB113_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB113_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB113_7:
ret;

}

.visible .entry _Z7reduce6IfLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r34, %r1, %r2;
setp.ge.u32 %p1, %r34, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB114_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB114_2:
mul.wide.u32 %rd4, %r34, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r34, %r34, %r4;
setp.lt.u32 %p2, %r34, %r8;
@%p2 bra $L__BB114_2;

$L__BB114_3:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r11, %r10, %r9;
st.shared.f32 [%r11], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r7, %r15, %r16, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB114_5;

mov.b32 %r17, %f19;
mov.u32 %r18, 2;
mov.u32 %r19, 31;
mov.u32 %r20, 16;
mov.u32 %r21, -1;
shfl.sync.down.b32 %r22|%p4, %r17, %r20, %r19, %r21;
mov.b32 %f9, %r22;
add.f32 %f10, %f19, %f9;
mov.b32 %r23, %f10;
mov.u32 %r24, 8;
shfl.sync.down.b32 %r25|%p5, %r23, %r24, %r19, %r21;
mov.b32 %f11, %r25;
add.f32 %f12, %f10, %f11;
mov.b32 %r26, %f12;
mov.u32 %r27, 4;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r19, %r21;
mov.b32 %f13, %r28;
add.f32 %f14, %f12, %f13;
mov.b32 %r29, %f14;
shfl.sync.down.b32 %r30|%p7, %r29, %r18, %r19, %r21;
mov.b32 %f15, %r30;
add.f32 %f16, %f14, %f15;
mov.b32 %r31, %f16;
mov.u32 %r32, 1;
shfl.sync.down.b32 %r33|%p8, %r31, %r32, %r19, %r21;
mov.b32 %f17, %r33;
add.f32 %f19, %f16, %f17;

$L__BB114_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB114_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB114_7:
ret;

}

.visible .entry _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB115_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 11;

$L__BB115_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 1024;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB115_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB115_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB115_2;

$L__BB115_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB115_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB115_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB115_7;

$L__BB115_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB115_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB115_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 1024;
mov.u32 %r43, 1;
@%p8 bra $L__BB115_12;

mov.u32 %r31, 1024;
div.u32 %r43, %r31, %r44;

$L__BB115_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB115_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB115_16;

mov.u32 %r39, 31;

$L__BB115_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB115_15;

$L__BB115_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB115_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB115_18:
ret;

}

.visible .entry _Z7reduce7IfLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB116_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 10;

$L__BB116_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 512;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB116_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB116_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB116_2;

$L__BB116_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB116_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB116_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB116_7;

$L__BB116_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB116_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB116_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 512;
mov.u32 %r43, 1;
@%p8 bra $L__BB116_12;

mov.u32 %r31, 512;
div.u32 %r43, %r31, %r44;

$L__BB116_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB116_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB116_16;

mov.u32 %r39, 31;

$L__BB116_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB116_15;

$L__BB116_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB116_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB116_18:
ret;

}

.visible .entry _Z7reduce7IfLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB117_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 9;

$L__BB117_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 256;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB117_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB117_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB117_2;

$L__BB117_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB117_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB117_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB117_7;

$L__BB117_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB117_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB117_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 256;
mov.u32 %r43, 1;
@%p8 bra $L__BB117_12;

mov.u32 %r31, 256;
div.u32 %r43, %r31, %r44;

$L__BB117_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB117_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB117_16;

mov.u32 %r39, 31;

$L__BB117_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB117_15;

$L__BB117_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB117_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB117_18:
ret;

}

.visible .entry _Z7reduce7IfLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB118_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 8;

$L__BB118_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 128;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB118_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB118_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB118_2;

$L__BB118_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB118_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB118_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB118_7;

$L__BB118_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB118_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB118_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 128;
mov.u32 %r43, 1;
@%p8 bra $L__BB118_12;

mov.u32 %r31, 128;
div.u32 %r43, %r31, %r44;

$L__BB118_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB118_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB118_16;

mov.u32 %r39, 31;

$L__BB118_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB118_15;

$L__BB118_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB118_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB118_18:
ret;

}

.visible .entry _Z7reduce7IfLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB119_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 7;

$L__BB119_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 64;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB119_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB119_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB119_2;

$L__BB119_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB119_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB119_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB119_7;

$L__BB119_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB119_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB119_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 64;
mov.u32 %r43, 1;
@%p8 bra $L__BB119_12;

mov.u32 %r31, 64;
div.u32 %r43, %r31, %r44;

$L__BB119_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB119_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB119_16;

mov.u32 %r39, 31;

$L__BB119_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB119_15;

$L__BB119_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB119_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB119_18:
ret;

}

.visible .entry _Z7reduce7IfLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB120_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;

$L__BB120_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 32;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB120_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB120_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB120_2;

$L__BB120_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB120_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB120_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB120_7;

$L__BB120_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB120_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB120_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 32;
mov.u32 %r43, 1;
@%p8 bra $L__BB120_12;

mov.u32 %r31, 32;
div.u32 %r43, %r31, %r44;

$L__BB120_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB120_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB120_16;

mov.u32 %r39, 31;

$L__BB120_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB120_15;

$L__BB120_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB120_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB120_18:
ret;

}

.visible .entry _Z7reduce7IfLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB121_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 5;

$L__BB121_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 16;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB121_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB121_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB121_2;

$L__BB121_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB121_8;

mov.u32 %r22, 31;
mov.u32 %r23, 65535;
mov.u32 %r42, %r44;

$L__BB121_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB121_7;

$L__BB121_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB121_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB121_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 16;
mov.u32 %r43, 1;
@%p8 bra $L__BB121_12;

mov.u32 %r31, 16;
div.u32 %r43, %r31, %r44;

$L__BB121_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 65535;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB121_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB121_16;

mov.u32 %r39, 31;

$L__BB121_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB121_15;

$L__BB121_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB121_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB121_18:
ret;

}

.visible .entry _Z7reduce7IfLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB122_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 4;

$L__BB122_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 8;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB122_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB122_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB122_2;

$L__BB122_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB122_8;

mov.u32 %r22, 31;
mov.u32 %r23, 255;
mov.u32 %r42, %r44;

$L__BB122_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB122_7;

$L__BB122_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB122_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB122_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 8;
mov.u32 %r43, 1;
@%p8 bra $L__BB122_12;

mov.u32 %r31, 8;
div.u32 %r43, %r31, %r44;

$L__BB122_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 255;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB122_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB122_16;

mov.u32 %r39, 31;

$L__BB122_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB122_15;

$L__BB122_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB122_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB122_18:
ret;

}

.visible .entry _Z7reduce7IfLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB123_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 3;

$L__BB123_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 4;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB123_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB123_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB123_2;

$L__BB123_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB123_8;

mov.u32 %r22, 31;
mov.u32 %r23, 15;
mov.u32 %r42, %r44;

$L__BB123_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB123_7;

$L__BB123_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB123_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB123_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 4;
mov.u32 %r43, 1;
@%p8 bra $L__BB123_12;

mov.u32 %r31, 4;
div.u32 %r43, %r31, %r44;

$L__BB123_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 15;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB123_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB123_16;

mov.u32 %r39, 31;

$L__BB123_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB123_15;

$L__BB123_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB123_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB123_18:
ret;

}

.visible .entry _Z7reduce7IfLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB124_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 2;

$L__BB124_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 2;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB124_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB124_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB124_2;

$L__BB124_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB124_8;

mov.u32 %r22, 31;
mov.u32 %r23, 3;
mov.u32 %r42, %r44;

$L__BB124_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB124_7;

$L__BB124_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB124_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB124_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 2;
mov.u32 %r43, 1;
@%p8 bra $L__BB124_12;

mov.u32 %r31, 2;
div.u32 %r43, %r31, %r44;

$L__BB124_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 3;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB124_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB124_16;

mov.u32 %r39, 31;

$L__BB124_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB124_15;

$L__BB124_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB124_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB124_18:
ret;

}

.visible .entry _Z7reduce7IfLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<26>;
.reg .b32 %r<37>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r14, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r34, %r15, %r2;
setp.ge.u32 %p1, %r34, %r14;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB125_5;

mov.u32 %r16, %nctaid.x;
shl.b32 %r4, %r16, 1;

$L__BB125_2:
mul.wide.u32 %rd4, %r34, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r34, 1;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra $L__BB125_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB125_4:
add.s32 %r34, %r34, %r4;
setp.lt.u32 %p3, %r34, %r14;
@%p3 bra $L__BB125_2;

$L__BB125_5:
mov.u32 %r36, WARP_SZ;
setp.lt.s32 %p4, %r36, 2;
@%p4 bra $L__BB125_8;

mov.u32 %r20, 31;
mov.u32 %r21, 1;
mov.u32 %r35, %r36;

$L__BB125_7:
mov.b32 %r17, %f19;
shr.u32 %r18, %r35, 31;
add.s32 %r19, %r35, %r18;
shr.s32 %r10, %r19, 1;
shfl.sync.down.b32 %r22|%p5, %r17, %r10, %r20, %r21;
mov.b32 %f17, %r22;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r35, 3;
mov.u32 %r35, %r10;
@%p6 bra $L__BB125_7;

$L__BB125_8:
rem.u32 %r23, %r2, %r36;
setp.ne.s32 %p7, %r23, 0;
@%p7 bra $L__BB125_10;

div.u32 %r24, %r2, %r36;
shl.b32 %r25, %r24, 2;
mov.u32 %r26, __smem;
add.s32 %r27, %r26, %r25;
st.shared.f32 [%r27], %f19;

$L__BB125_10:
bar.sync 0;
setp.ne.s32 %p8, %r2, 0;
setp.eq.s32 %p9, %r2, 0;
mov.u32 %r28, 1;
vote.sync.ballot.b32 %r11, %p9, %r28;
@%p8 bra $L__BB125_14;

ld.shared.f32 %f19, [__smem];
@%p4 bra $L__BB125_14;

mov.u32 %r32, 31;

$L__BB125_13:
mov.b32 %r29, %f19;
shr.u32 %r30, %r36, 31;
add.s32 %r31, %r36, %r30;
shr.s32 %r13, %r31, 1;
shfl.sync.down.b32 %r33|%p12, %r29, %r13, %r32, %r11;
mov.b32 %f18, %r33;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p13, %r36, 3;
mov.u32 %r36, %r13;
@%p13 bra $L__BB125_13;

$L__BB125_14:
@%p8 bra $L__BB125_16;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB125_16:
ret;

}

.visible .entry _Z7reduce7IfLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB126_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB126_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB126_2;

$L__BB126_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB126_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB126_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB126_5;

$L__BB126_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB126_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB126_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 512;
mov.u32 %r42, 1;
@%p7 bra $L__BB126_10;

mov.u32 %r30, 512;
div.u32 %r42, %r30, %r43;

$L__BB126_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB126_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB126_14;

mov.u32 %r38, 31;

$L__BB126_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB126_13;

$L__BB126_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB126_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB126_16:
ret;

}

.visible .entry _Z7reduce7IfLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB127_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB127_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB127_2;

$L__BB127_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB127_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB127_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB127_5;

$L__BB127_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB127_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB127_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 256;
mov.u32 %r42, 1;
@%p7 bra $L__BB127_10;

mov.u32 %r30, 256;
div.u32 %r42, %r30, %r43;

$L__BB127_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB127_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB127_14;

mov.u32 %r38, 31;

$L__BB127_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB127_13;

$L__BB127_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB127_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB127_16:
ret;

}

.visible .entry _Z7reduce7IfLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB128_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB128_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB128_2;

$L__BB128_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB128_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB128_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB128_5;

$L__BB128_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB128_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB128_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 128;
mov.u32 %r42, 1;
@%p7 bra $L__BB128_10;

mov.u32 %r30, 128;
div.u32 %r42, %r30, %r43;

$L__BB128_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB128_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB128_14;

mov.u32 %r38, 31;

$L__BB128_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB128_13;

$L__BB128_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB128_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB128_16:
ret;

}

.visible .entry _Z7reduce7IfLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB129_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB129_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB129_2;

$L__BB129_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB129_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB129_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB129_5;

$L__BB129_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB129_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB129_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 64;
mov.u32 %r42, 1;
@%p7 bra $L__BB129_10;

mov.u32 %r30, 64;
div.u32 %r42, %r30, %r43;

$L__BB129_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB129_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB129_14;

mov.u32 %r38, 31;

$L__BB129_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB129_13;

$L__BB129_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB129_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB129_16:
ret;

}

.visible .entry _Z7reduce7IfLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB130_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB130_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB130_2;

$L__BB130_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB130_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB130_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB130_5;

$L__BB130_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB130_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB130_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 32;
mov.u32 %r42, 1;
@%p7 bra $L__BB130_10;

mov.u32 %r30, 32;
div.u32 %r42, %r30, %r43;

$L__BB130_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB130_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB130_14;

mov.u32 %r38, 31;

$L__BB130_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB130_13;

$L__BB130_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB130_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB130_16:
ret;

}

.visible .entry _Z7reduce7IfLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB131_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB131_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB131_2;

$L__BB131_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB131_6;

mov.u32 %r21, 31;
mov.u32 %r22, 65535;
mov.u32 %r41, %r43;

$L__BB131_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB131_5;

$L__BB131_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB131_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB131_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 16;
mov.u32 %r42, 1;
@%p7 bra $L__BB131_10;

mov.u32 %r30, 16;
div.u32 %r42, %r30, %r43;

$L__BB131_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 65535;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB131_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB131_14;

mov.u32 %r38, 31;

$L__BB131_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB131_13;

$L__BB131_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB131_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB131_16:
ret;

}

.visible .entry _Z7reduce7IfLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB132_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB132_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB132_2;

$L__BB132_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB132_6;

mov.u32 %r21, 31;
mov.u32 %r22, 255;
mov.u32 %r41, %r43;

$L__BB132_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB132_5;

$L__BB132_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB132_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB132_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 8;
mov.u32 %r42, 1;
@%p7 bra $L__BB132_10;

mov.u32 %r30, 8;
div.u32 %r42, %r30, %r43;

$L__BB132_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 255;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB132_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB132_14;

mov.u32 %r38, 31;

$L__BB132_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB132_13;

$L__BB132_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB132_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB132_16:
ret;

}

.visible .entry _Z7reduce7IfLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB133_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB133_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB133_2;

$L__BB133_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB133_6;

mov.u32 %r21, 31;
mov.u32 %r22, 15;
mov.u32 %r41, %r43;

$L__BB133_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB133_5;

$L__BB133_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB133_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB133_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 4;
mov.u32 %r42, 1;
@%p7 bra $L__BB133_10;

mov.u32 %r30, 4;
div.u32 %r42, %r30, %r43;

$L__BB133_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 15;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB133_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB133_14;

mov.u32 %r38, 31;

$L__BB133_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB133_13;

$L__BB133_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB133_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB133_16:
ret;

}

.visible .entry _Z7reduce7IfLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB134_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB134_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB134_2;

$L__BB134_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB134_6;

mov.u32 %r21, 31;
mov.u32 %r22, 3;
mov.u32 %r41, %r43;

$L__BB134_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB134_5;

$L__BB134_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB134_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB134_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 2;
mov.u32 %r42, 1;
@%p7 bra $L__BB134_10;

mov.u32 %r30, 2;
div.u32 %r42, %r30, %r43;

$L__BB134_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 3;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB134_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB134_14;

mov.u32 %r38, 31;

$L__BB134_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB134_13;

$L__BB134_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB134_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB134_16:
ret;

}

.visible .entry _Z7reduce7IfLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<14>;
.reg .f32 %f<22>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r13, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r31, %r1, %r2;
setp.ge.u32 %p1, %r31, %r13;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB135_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB135_2:
mul.wide.u32 %rd4, %r31, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r31, %r31, %r4;
setp.lt.u32 %p2, %r31, %r13;
@%p2 bra $L__BB135_2;

$L__BB135_3:
mov.u32 %r33, WARP_SZ;
setp.lt.s32 %p3, %r33, 2;
@%p3 bra $L__BB135_6;

mov.u32 %r17, 31;
mov.u32 %r18, 1;
mov.u32 %r32, %r33;

$L__BB135_5:
mov.b32 %r14, %f19;
shr.u32 %r15, %r32, 31;
add.s32 %r16, %r32, %r15;
shr.s32 %r9, %r16, 1;
shfl.sync.down.b32 %r19|%p4, %r14, %r9, %r17, %r18;
mov.b32 %f14, %r19;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r32, 3;
mov.u32 %r32, %r9;
@%p5 bra $L__BB135_5;

$L__BB135_6:
rem.u32 %r20, %r2, %r33;
setp.ne.s32 %p6, %r20, 0;
@%p6 bra $L__BB135_8;

div.u32 %r21, %r2, %r33;
shl.b32 %r22, %r21, 2;
mov.u32 %r23, __smem;
add.s32 %r24, %r23, %r22;
st.shared.f32 [%r24], %f19;

$L__BB135_8:
bar.sync 0;
setp.ne.s32 %p7, %r2, 0;
setp.eq.s32 %p8, %r2, 0;
mov.u32 %r25, 1;
vote.sync.ballot.b32 %r10, %p8, %r25;
@%p7 bra $L__BB135_12;

ld.shared.f32 %f19, [__smem];
@%p3 bra $L__BB135_12;

mov.u32 %r29, 31;

$L__BB135_11:
mov.b32 %r26, %f19;
shr.u32 %r27, %r33, 31;
add.s32 %r28, %r33, %r27;
shr.s32 %r12, %r28, 1;
shfl.sync.down.b32 %r30|%p11, %r26, %r12, %r29, %r10;
mov.b32 %f15, %r30;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p12, %r33, 3;
mov.u32 %r33, %r12;
@%p12 bra $L__BB135_11;

$L__BB135_12:
@%p7 bra $L__BB135_14;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB135_14:
ret;

}

.visible .entry _Z9cg_reduceIfEvPT_S1_j(
.param .u64 _Z9cg_reduceIfEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIfEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIfEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<46>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIfEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIfEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z9cg_reduceIfEvPT_S1_j_param_2];
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r1, %r14, %r15, %r16;
mul.lo.s32 %r17, %r15, %r11;
mov.u32 %r18, %ntid.z;
mul.lo.s32 %r45, %r17, %r18;
mov.u32 %r19, %ctaid.x;
mad.lo.s32 %r44, %r45, %r19, %r1;
setp.ge.u32 %p1, %r44, %r10;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB136_3;

mov.u32 %r20, %nctaid.x;
mul.lo.s32 %r4, %r45, %r20;
cvta.to.global.u64 %rd1, %rd2;

$L__BB136_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f26, %f26, %f12;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r10;
@%p2 bra $L__BB136_2;

$L__BB136_3:
shl.b32 %r21, %r1, 2;
mov.u32 %r22, __smem;
add.s32 %r7, %r22, %r21;
st.shared.f32 [%r7], %f26;
setp.lt.u32 %p3, %r45, 64;
@%p3 bra $L__BB136_8;

$L__BB136_5:
barrier.sync 0;
shr.u32 %r9, %r45, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra $L__BB136_7;

shl.b32 %r23, %r9, 2;
add.s32 %r24, %r7, %r23;
ld.shared.f32 %f13, [%r24];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r7], %f26;

$L__BB136_7:
setp.gt.u32 %p5, %r45, 127;
mov.u32 %r45, %r9;
@%p5 bra $L__BB136_5;

$L__BB136_8:
barrier.sync 0;
and.b32 %r25, %r1, 2097120;
setp.ne.s32 %p6, %r25, 0;
@%p6 bra $L__BB136_10;

mov.b32 %r26, %f26;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.bfly.b32 %r30|%p7, %r26, %r28, %r27, %r29;
mov.b32 %f14, %r30;
add.f32 %f15, %f26, %f14;
mov.b32 %r31, %f15;
mov.u32 %r32, 8;
shfl.sync.bfly.b32 %r33|%p8, %r31, %r32, %r27, %r29;
mov.b32 %f16, %r33;
add.f32 %f17, %f15, %f16;
mov.b32 %r34, %f17;
mov.u32 %r35, 4;
shfl.sync.bfly.b32 %r36|%p9, %r34, %r35, %r27, %r29;
mov.b32 %f18, %r36;
add.f32 %f19, %f17, %f18;
mov.b32 %r37, %f19;
mov.u32 %r38, 2;
shfl.sync.bfly.b32 %r39|%p10, %r37, %r38, %r27, %r29;
mov.b32 %f20, %r39;
add.f32 %f21, %f19, %f20;
mov.b32 %r40, %f21;
mov.u32 %r41, 1;
shfl.sync.bfly.b32 %r42|%p11, %r40, %r41, %r27, %r29;
mov.b32 %f22, %r42;
add.f32 %f26, %f21, %f22;

$L__BB136_10:
setp.ne.s32 %p12, %r1, 0;
@%p12 bra $L__BB136_12;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r19, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB136_12:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<30>;
.reg .f32 %f<68>;
.reg .b32 %r<143>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch[160];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB137_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB137_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f62, 0f00000000;
@%p2 bra $L__BB137_6;

shl.b32 %r47, %r6, 10;
add.s32 %r134, %r47, %r3;
setp.ge.u32 %p3, %r134, %r37;
@%p3 bra $L__BB137_11;

shl.b32 %r8, %r5, 10;

$L__BB137_5:
mul.wide.u32 %rd5, %r134, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f62, %f62, %f18;
add.s32 %r134, %r134, %r8;
setp.lt.u32 %p4, %r134, %r37;
@%p4 bra $L__BB137_5;
bra.uni $L__BB137_11;

$L__BB137_6:
shl.b32 %r48, %r6, 11;
add.s32 %r135, %r48, %r3;
setp.ge.u32 %p5, %r135, %r37;
@%p5 bra $L__BB137_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 11;

$L__BB137_8:
cvt.u64.u32 %rd7, %r135;
mul.wide.u32 %rd8, %r135, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f62, %f62, %f21;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB137_10;

add.s32 %r49, %r135, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f62, %f62, %f22;

$L__BB137_10:
add.s32 %r135, %r135, %r12;
setp.lt.u32 %p7, %r135, %r37;
@%p7 bra $L__BB137_8;

$L__BB137_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f62;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f62, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r69, %r51;
shr.u32 %r18, %r4, 9;
shl.b32 %r71, %r18, 4;
mov.u32 %r72, 65535;
shl.b32 %r19, %r72, %r71;
bar.warp.sync -1;
mov.u32 %r136, %r50;
@%p13 bra $L__BB137_13;

add.s32 %r74, %r54, 12;
atom.shared.or.b32 %r136, [%r74], %r17;

$L__BB137_13:
shfl.sync.idx.b32 %r78|%p14, %r136, %r50, %r56, %r58;
or.b32 %r79, %r78, %r17;
and.b32 %r80, %r79, %r19;
setp.eq.s32 %p15, %r80, %r19;
@%p15 bra $L__BB137_16;
bra.uni $L__BB137_15;

$L__BB137_16:
and.b32 %r83, %r4, 16;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra $L__BB137_18;

and.b32 %r88, %r4, 15;
and.b32 %r89, %r4, -512;
shr.u32 %r90, %r89, 5;
or.b32 %r91, %r90, %r88;
shl.b32 %r92, %r91, 2;
add.s32 %r95, %r54, %r92;
ld.shared.f32 %f33, [%r95+32];

	mov.u32 %r84, %laneid;

	and.b32 %r96, %r84, -16;
shl.b32 %r98, %r72, %r96;
mov.b32 %r99, %f33;
mov.u32 %r100, 4127;
shfl.sync.bfly.b32 %r102|%p18, %r99, %r61, %r100, %r98;
mov.b32 %f34, %r102;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r103, %r85, -16;
shl.b32 %r104, %r72, %r103;
mov.b32 %r105, %f35;
shfl.sync.bfly.b32 %r107|%p19, %r105, %r64, %r100, %r104;
mov.b32 %f36, %r107;
add.f32 %f37, %f35, %f36;

	mov.u32 %r86, %laneid;

	and.b32 %r108, %r86, -16;
shl.b32 %r109, %r72, %r108;
mov.b32 %r110, %f37;
shfl.sync.bfly.b32 %r111|%p20, %r110, %r53, %r100, %r109;
mov.b32 %f38, %r111;
add.f32 %f39, %f37, %f38;

	mov.u32 %r87, %laneid;

	and.b32 %r112, %r87, -16;
shl.b32 %r113, %r72, %r112;
mov.b32 %r114, %f39;
shfl.sync.bfly.b32 %r116|%p21, %r114, %r69, %r100, %r113;
mov.b32 %f40, %r116;
add.f32 %f41, %f39, %f40;
st.shared.f32 [%r95+32], %f41;

$L__BB137_18:
bar.warp.sync -1;
@%p13 bra $L__BB137_20;

not.b32 %r117, %r19;
add.s32 %r119, %r54, 12;
atom.shared.and.b32 %r120, [%r119], %r117;
bra.uni $L__BB137_20;

$L__BB137_15:
ld.volatile.shared.u32 %r81, [_ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch+12];
and.b32 %r82, %r81, %r17;
setp.eq.s32 %p16, %r82, 0;
@%p16 bra $L__BB137_20;
bra.uni $L__BB137_15;

$L__BB137_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r121, %r4, 511;
setp.ne.s32 %p23, %r121, 0;
@%p23 bra $L__BB137_22;

shl.b32 %r122, %r18, 2;
mov.u32 %r123, __smem;
add.s32 %r124, %r123, %r122;
st.shared.f32 [%r124], %f8;

$L__BB137_22:
barrier.sync 0;
setp.ne.s32 %p24, %r3, 0;
@%p24 bra $L__BB137_31;

mul.lo.s32 %r125, %r2, %r1;
mov.u32 %r126, %ntid.z;
mad.lo.s32 %r127, %r125, %r126, 511;
shr.u32 %r22, %r127, 9;
setp.eq.s32 %p25, %r22, 0;
mov.f32 %f67, 0f00000000;
@%p25 bra $L__BB137_30;

add.s32 %r129, %r22, -1;
and.b32 %r142, %r22, 3;
setp.lt.u32 %p26, %r129, 3;
mov.f32 %f67, 0f00000000;
mov.u32 %r140, 0;
@%p26 bra $L__BB137_27;

sub.s32 %r139, %r22, %r142;
mov.u32 %r137, __smem;

$L__BB137_26:
ld.shared.v4.f32 {%f46, %f47, %f48, %f49}, [%r137];
add.f32 %f54, %f67, %f46;
add.f32 %f55, %f54, %f47;
add.f32 %f56, %f55, %f48;
add.f32 %f67, %f56, %f49;
add.s32 %r140, %r140, 4;
add.s32 %r137, %r137, 16;
add.s32 %r139, %r139, -4;
setp.ne.s32 %p27, %r139, 0;
@%p27 bra $L__BB137_26;

$L__BB137_27:
setp.eq.s32 %p28, %r142, 0;
@%p28 bra $L__BB137_30;

shl.b32 %r132, %r140, 2;
mov.u32 %r133, __smem;
add.s32 %r141, %r133, %r132;

$L__BB137_29:
.pragma "nounroll";
ld.shared.f32 %f57, [%r141];
add.f32 %f67, %f67, %f57;
add.s32 %r141, %r141, 4;
add.s32 %r142, %r142, -1;
setp.ne.s32 %p29, %r142, 0;
@%p29 bra $L__BB137_29;

$L__BB137_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f67;

$L__BB137_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<29>;
.reg .f32 %f<66>;
.reg .b32 %r<137>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch[96];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB138_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB138_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f60, 0f00000000;
@%p2 bra $L__BB138_6;

shl.b32 %r47, %r6, 9;
add.s32 %r128, %r47, %r3;
setp.ge.u32 %p3, %r128, %r37;
@%p3 bra $L__BB138_11;

shl.b32 %r8, %r5, 9;

$L__BB138_5:
mul.wide.u32 %rd5, %r128, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f60, %f60, %f18;
add.s32 %r128, %r128, %r8;
setp.lt.u32 %p4, %r128, %r37;
@%p4 bra $L__BB138_5;
bra.uni $L__BB138_11;

$L__BB138_6:
shl.b32 %r48, %r6, 10;
add.s32 %r129, %r48, %r3;
setp.ge.u32 %p5, %r129, %r37;
@%p5 bra $L__BB138_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 10;

$L__BB138_8:
cvt.u64.u32 %rd7, %r129;
mul.wide.u32 %rd8, %r129, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f60, %f60, %f21;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB138_10;

add.s32 %r49, %r129, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f60, %f60, %f22;

$L__BB138_10:
add.s32 %r129, %r129, %r12;
setp.lt.u32 %p7, %r129, %r37;
@%p7 bra $L__BB138_8;

$L__BB138_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f60;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f60, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r69, %r51;
shr.u32 %r18, %r4, 8;
shl.b32 %r71, %r18, 3;
mov.u32 %r72, 255;
shl.b32 %r19, %r72, %r71;
bar.warp.sync -1;
mov.u32 %r130, %r50;
@%p13 bra $L__BB138_13;

add.s32 %r74, %r54, 8;
atom.shared.or.b32 %r130, [%r74], %r17;

$L__BB138_13:
shfl.sync.idx.b32 %r78|%p14, %r130, %r50, %r56, %r58;
or.b32 %r79, %r78, %r17;
and.b32 %r80, %r79, %r19;
setp.eq.s32 %p15, %r80, %r19;
@%p15 bra $L__BB138_16;
bra.uni $L__BB138_15;

$L__BB138_16:
and.b32 %r83, %r4, 24;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra $L__BB138_18;

and.b32 %r87, %r4, 7;
and.b32 %r88, %r4, -256;
shr.u32 %r89, %r88, 5;
or.b32 %r90, %r89, %r87;
shl.b32 %r91, %r90, 2;
add.s32 %r94, %r54, %r91;
ld.shared.f32 %f33, [%r94+32];

	mov.u32 %r84, %laneid;

	and.b32 %r95, %r84, -8;
shl.b32 %r97, %r72, %r95;
mov.b32 %r98, %f33;
mov.u32 %r99, 6175;
shfl.sync.bfly.b32 %r101|%p18, %r98, %r64, %r99, %r97;
mov.b32 %f34, %r101;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r102, %r85, -8;
shl.b32 %r103, %r72, %r102;
mov.b32 %r104, %f35;
shfl.sync.bfly.b32 %r105|%p19, %r104, %r53, %r99, %r103;
mov.b32 %f36, %r105;
add.f32 %f37, %f35, %f36;

	mov.u32 %r86, %laneid;

	and.b32 %r106, %r86, -8;
shl.b32 %r107, %r72, %r106;
mov.b32 %r108, %f37;
shfl.sync.bfly.b32 %r110|%p20, %r108, %r69, %r99, %r107;
mov.b32 %f38, %r110;
add.f32 %f39, %f37, %f38;
st.shared.f32 [%r94+32], %f39;

$L__BB138_18:
bar.warp.sync -1;
@%p13 bra $L__BB138_20;

not.b32 %r111, %r19;
add.s32 %r113, %r54, 8;
atom.shared.and.b32 %r114, [%r113], %r111;
bra.uni $L__BB138_20;

$L__BB138_15:
ld.volatile.shared.u32 %r81, [_ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch+8];
and.b32 %r82, %r81, %r17;
setp.eq.s32 %p16, %r82, 0;
@%p16 bra $L__BB138_20;
bra.uni $L__BB138_15;

$L__BB138_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r115, %r4, 255;
setp.ne.s32 %p22, %r115, 0;
@%p22 bra $L__BB138_22;

shl.b32 %r116, %r18, 2;
mov.u32 %r117, __smem;
add.s32 %r118, %r117, %r116;
st.shared.f32 [%r118], %f8;

$L__BB138_22:
barrier.sync 0;
setp.ne.s32 %p23, %r3, 0;
@%p23 bra $L__BB138_31;

mul.lo.s32 %r119, %r2, %r1;
mov.u32 %r120, %ntid.z;
mad.lo.s32 %r121, %r119, %r120, 255;
shr.u32 %r22, %r121, 8;
setp.eq.s32 %p24, %r22, 0;
mov.f32 %f65, 0f00000000;
@%p24 bra $L__BB138_30;

add.s32 %r123, %r22, -1;
and.b32 %r136, %r22, 3;
setp.lt.u32 %p25, %r123, 3;
mov.f32 %f65, 0f00000000;
mov.u32 %r134, 0;
@%p25 bra $L__BB138_27;

sub.s32 %r133, %r22, %r136;
mov.u32 %r131, __smem;

$L__BB138_26:
ld.shared.v4.f32 {%f44, %f45, %f46, %f47}, [%r131];
add.f32 %f52, %f65, %f44;
add.f32 %f53, %f52, %f45;
add.f32 %f54, %f53, %f46;
add.f32 %f65, %f54, %f47;
add.s32 %r134, %r134, 4;
add.s32 %r131, %r131, 16;
add.s32 %r133, %r133, -4;
setp.ne.s32 %p26, %r133, 0;
@%p26 bra $L__BB138_26;

$L__BB138_27:
setp.eq.s32 %p27, %r136, 0;
@%p27 bra $L__BB138_30;

shl.b32 %r126, %r134, 2;
mov.u32 %r127, __smem;
add.s32 %r135, %r127, %r126;

$L__BB138_29:
.pragma "nounroll";
ld.shared.f32 %f55, [%r135];
add.f32 %f65, %f65, %f55;
add.s32 %r135, %r135, 4;
add.s32 %r136, %r136, -1;
setp.ne.s32 %p28, %r136, 0;
@%p28 bra $L__BB138_29;

$L__BB138_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f65;

$L__BB138_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<28>;
.reg .f32 %f<64>;
.reg .b32 %r<131>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB139_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB139_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f58, 0f00000000;
@%p2 bra $L__BB139_6;

shl.b32 %r47, %r6, 8;
add.s32 %r122, %r47, %r3;
setp.ge.u32 %p3, %r122, %r37;
@%p3 bra $L__BB139_11;

shl.b32 %r8, %r5, 8;

$L__BB139_5:
mul.wide.u32 %rd5, %r122, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f58, %f58, %f18;
add.s32 %r122, %r122, %r8;
setp.lt.u32 %p4, %r122, %r37;
@%p4 bra $L__BB139_5;
bra.uni $L__BB139_11;

$L__BB139_6:
shl.b32 %r48, %r6, 9;
add.s32 %r123, %r48, %r3;
setp.ge.u32 %p5, %r123, %r37;
@%p5 bra $L__BB139_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 9;

$L__BB139_8:
cvt.u64.u32 %rd7, %r123;
mul.wide.u32 %rd8, %r123, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f58, %f58, %f21;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB139_10;

add.s32 %r49, %r123, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f58, %f58, %f22;

$L__BB139_10:
add.s32 %r123, %r123, %r12;
setp.lt.u32 %p7, %r123, %r37;
@%p7 bra $L__BB139_8;

$L__BB139_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f58;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f58, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r69, %r51;
shr.u32 %r18, %r4, 7;
shl.b32 %r71, %r18, 2;
mov.u32 %r72, 15;
shl.b32 %r19, %r72, %r71;
bar.warp.sync -1;
mov.u32 %r124, %r50;
@%p13 bra $L__BB139_13;

add.s32 %r74, %r54, 4;
atom.shared.or.b32 %r124, [%r74], %r17;

$L__BB139_13:
shfl.sync.idx.b32 %r78|%p14, %r124, %r50, %r56, %r58;
or.b32 %r79, %r78, %r17;
and.b32 %r80, %r79, %r19;
setp.eq.s32 %p15, %r80, %r19;
@%p15 bra $L__BB139_16;
bra.uni $L__BB139_15;

$L__BB139_16:
and.b32 %r83, %r4, 28;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra $L__BB139_18;

and.b32 %r86, %r4, 3;
and.b32 %r87, %r4, -128;
shr.u32 %r88, %r87, 5;
or.b32 %r89, %r88, %r86;
shl.b32 %r90, %r89, 2;
add.s32 %r93, %r54, %r90;
ld.shared.f32 %f33, [%r93+32];

	mov.u32 %r84, %laneid;

	and.b32 %r94, %r84, -4;
shl.b32 %r96, %r72, %r94;
mov.b32 %r97, %f33;
mov.u32 %r98, 7199;
shfl.sync.bfly.b32 %r99|%p18, %r97, %r53, %r98, %r96;
mov.b32 %f34, %r99;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r100, %r85, -4;
shl.b32 %r101, %r72, %r100;
mov.b32 %r102, %f35;
shfl.sync.bfly.b32 %r104|%p19, %r102, %r69, %r98, %r101;
mov.b32 %f36, %r104;
add.f32 %f37, %f35, %f36;
st.shared.f32 [%r93+32], %f37;

$L__BB139_18:
bar.warp.sync -1;
@%p13 bra $L__BB139_20;

not.b32 %r105, %r19;
add.s32 %r107, %r54, 4;
atom.shared.and.b32 %r108, [%r107], %r105;
bra.uni $L__BB139_20;

$L__BB139_15:
ld.volatile.shared.u32 %r81, [_ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch+4];
and.b32 %r82, %r81, %r17;
setp.eq.s32 %p16, %r82, 0;
@%p16 bra $L__BB139_20;
bra.uni $L__BB139_15;

$L__BB139_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r109, %r4, 127;
setp.ne.s32 %p21, %r109, 0;
@%p21 bra $L__BB139_22;

mov.u32 %r111, __smem;
add.s32 %r112, %r111, %r71;
st.shared.f32 [%r112], %f8;

$L__BB139_22:
barrier.sync 0;
setp.ne.s32 %p22, %r3, 0;
@%p22 bra $L__BB139_31;

mul.lo.s32 %r113, %r2, %r1;
mov.u32 %r114, %ntid.z;
mad.lo.s32 %r115, %r113, %r114, 127;
shr.u32 %r22, %r115, 7;
setp.eq.s32 %p23, %r22, 0;
mov.f32 %f63, 0f00000000;
@%p23 bra $L__BB139_30;

add.s32 %r117, %r22, -1;
and.b32 %r130, %r22, 3;
setp.lt.u32 %p24, %r117, 3;
mov.f32 %f63, 0f00000000;
mov.u32 %r128, 0;
@%p24 bra $L__BB139_27;

sub.s32 %r127, %r22, %r130;
mov.u32 %r125, __smem;

$L__BB139_26:
ld.shared.v4.f32 {%f42, %f43, %f44, %f45}, [%r125];
add.f32 %f50, %f63, %f42;
add.f32 %f51, %f50, %f43;
add.f32 %f52, %f51, %f44;
add.f32 %f63, %f52, %f45;
add.s32 %r128, %r128, 4;
add.s32 %r125, %r125, 16;
add.s32 %r127, %r127, -4;
setp.ne.s32 %p25, %r127, 0;
@%p25 bra $L__BB139_26;

$L__BB139_27:
setp.eq.s32 %p26, %r130, 0;
@%p26 bra $L__BB139_30;

shl.b32 %r120, %r128, 2;
mov.u32 %r121, __smem;
add.s32 %r129, %r121, %r120;

$L__BB139_29:
.pragma "nounroll";
ld.shared.f32 %f53, [%r129];
add.f32 %f63, %f63, %f53;
add.s32 %r129, %r129, 4;
add.s32 %r130, %r130, -1;
setp.ne.s32 %p27, %r130, 0;
@%p27 bra $L__BB139_29;

$L__BB139_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f63;

$L__BB139_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<27>;
.reg .f32 %f<62>;
.reg .b32 %r<123>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch[48];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB140_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB140_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f56, 0f00000000;
@%p2 bra $L__BB140_6;

shl.b32 %r47, %r6, 7;
add.s32 %r114, %r47, %r3;
setp.ge.u32 %p3, %r114, %r37;
@%p3 bra $L__BB140_11;

shl.b32 %r8, %r5, 7;

$L__BB140_5:
mul.wide.u32 %rd5, %r114, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f56, %f56, %f18;
add.s32 %r114, %r114, %r8;
setp.lt.u32 %p4, %r114, %r37;
@%p4 bra $L__BB140_5;
bra.uni $L__BB140_11;

$L__BB140_6:
shl.b32 %r48, %r6, 8;
add.s32 %r115, %r48, %r3;
setp.ge.u32 %p5, %r115, %r37;
@%p5 bra $L__BB140_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 8;

$L__BB140_8:
cvt.u64.u32 %rd7, %r115;
mul.wide.u32 %rd8, %r115, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f56, %f56, %f21;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB140_10;

add.s32 %r49, %r115, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f56, %f56, %f22;

$L__BB140_10:
add.s32 %r115, %r115, %r12;
setp.lt.u32 %p7, %r115, %r37;
@%p7 bra $L__BB140_8;

$L__BB140_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f56;
mov.u32 %r56, 3;
mov.u32 %r57, 31;
mov.u32 %r58, 16;
mov.u32 %r59, -1;
shfl.sync.bfly.b32 %r60|%p8, %r55, %r58, %r57, %r59;
mov.b32 %f23, %r60;
add.f32 %f24, %f56, %f23;
mov.b32 %r61, %f24;
mov.u32 %r62, 8;
shfl.sync.bfly.b32 %r63|%p9, %r61, %r62, %r57, %r59;
mov.b32 %f25, %r63;
add.f32 %f26, %f24, %f25;
mov.b32 %r64, %f26;
mov.u32 %r65, 4;
shfl.sync.bfly.b32 %r66|%p10, %r64, %r65, %r57, %r59;
mov.b32 %f27, %r66;
add.f32 %f28, %f26, %f27;
mov.b32 %r67, %f28;
shfl.sync.bfly.b32 %r68|%p11, %r67, %r53, %r57, %r59;
mov.b32 %f29, %r68;
add.f32 %f30, %f28, %f29;
mov.b32 %r69, %f30;
mov.u32 %r70, 1;
shfl.sync.bfly.b32 %r71|%p12, %r69, %r70, %r57, %r59;
mov.b32 %f31, %r71;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r70, %r51;
shr.u32 %r18, %r4, 6;
shl.b32 %r72, %r18, 1;
shl.b32 %r19, %r56, %r72;
bar.warp.sync -1;
mov.u32 %r116, %r50;
@%p13 bra $L__BB140_13;

atom.shared.or.b32 %r116, [%r54], %r17;

$L__BB140_13:
shfl.sync.idx.b32 %r77|%p14, %r116, %r50, %r57, %r59;
or.b32 %r78, %r77, %r17;
and.b32 %r79, %r78, %r19;
setp.eq.s32 %p15, %r79, %r19;
@%p15 bra $L__BB140_16;
bra.uni $L__BB140_15;

$L__BB140_16:
and.b32 %r82, %r4, 30;
setp.ne.s32 %p17, %r82, 0;
@%p17 bra $L__BB140_18;

and.b32 %r84, %r4, 1;
and.b32 %r86, %r4, -64;
shr.u32 %r87, %r86, 5;
or.b32 %r88, %r87, %r84;
shl.b32 %r89, %r88, 2;
add.s32 %r91, %r54, %r89;
ld.shared.f32 %f33, [%r91+32];

	mov.u32 %r83, %laneid;

	and.b32 %r92, %r83, -2;
shl.b32 %r94, %r56, %r92;
mov.b32 %r95, %f33;
mov.u32 %r96, 7711;
shfl.sync.bfly.b32 %r97|%p18, %r95, %r70, %r96, %r94;
mov.b32 %f34, %r97;
add.f32 %f35, %f33, %f34;
st.shared.f32 [%r91+32], %f35;

$L__BB140_18:
bar.warp.sync -1;
@%p13 bra $L__BB140_20;

not.b32 %r98, %r19;
atom.shared.and.b32 %r100, [%r54], %r98;
bra.uni $L__BB140_20;

$L__BB140_15:
ld.volatile.shared.u32 %r80, [_ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch];
and.b32 %r81, %r80, %r17;
setp.eq.s32 %p16, %r81, 0;
@%p16 bra $L__BB140_20;
bra.uni $L__BB140_15;

$L__BB140_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r101, %r4, 63;
setp.ne.s32 %p20, %r101, 0;
@%p20 bra $L__BB140_22;

shl.b32 %r102, %r18, 2;
mov.u32 %r103, __smem;
add.s32 %r104, %r103, %r102;
st.shared.f32 [%r104], %f8;

$L__BB140_22:
barrier.sync 0;
setp.ne.s32 %p21, %r3, 0;
@%p21 bra $L__BB140_31;

mul.lo.s32 %r105, %r2, %r1;
mov.u32 %r106, %ntid.z;
mad.lo.s32 %r107, %r105, %r106, 63;
shr.u32 %r22, %r107, 6;
setp.eq.s32 %p22, %r22, 0;
mov.f32 %f61, 0f00000000;
@%p22 bra $L__BB140_30;

add.s32 %r109, %r22, -1;
and.b32 %r122, %r22, 3;
setp.lt.u32 %p23, %r109, 3;
mov.f32 %f61, 0f00000000;
mov.u32 %r120, 0;
@%p23 bra $L__BB140_27;

sub.s32 %r119, %r22, %r122;
mov.u32 %r117, __smem;

$L__BB140_26:
ld.shared.v4.f32 {%f40, %f41, %f42, %f43}, [%r117];
add.f32 %f48, %f61, %f40;
add.f32 %f49, %f48, %f41;
add.f32 %f50, %f49, %f42;
add.f32 %f61, %f50, %f43;
add.s32 %r120, %r120, 4;
add.s32 %r117, %r117, 16;
add.s32 %r119, %r119, -4;
setp.ne.s32 %p24, %r119, 0;
@%p24 bra $L__BB140_26;

$L__BB140_27:
setp.eq.s32 %p25, %r122, 0;
@%p25 bra $L__BB140_30;

shl.b32 %r112, %r120, 2;
mov.u32 %r113, __smem;
add.s32 %r121, %r113, %r112;

$L__BB140_29:
.pragma "nounroll";
ld.shared.f32 %f51, [%r121];
add.f32 %f61, %f61, %f51;
add.s32 %r121, %r121, 4;
add.s32 %r122, %r122, -1;
setp.ne.s32 %p26, %r122, 0;
@%p26 bra $L__BB140_29;

$L__BB140_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f61;

$L__BB140_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<19>;
.reg .f32 %f<58>;
.reg .b32 %r<81>;
.reg .b64 %rd<16>;


ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r29, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r30, %ntid.y;
mov.u32 %r31, %tid.z;
mov.u32 %r32, %tid.y;
mad.lo.s32 %r33, %r30, %r31, %r32;
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %tid.x;
mad.lo.s32 %r3, %r33, %r1, %r2;
barrier.sync 0;
mov.u32 %r4, %nctaid.x;
add.s32 %r34, %r29, -1;
and.b32 %r35, %r34, %r29;
setp.eq.s32 %p1, %r35, 0;
mov.u32 %r5, %ctaid.x;
mov.f32 %f52, 0f00000000;
@%p1 bra $L__BB141_4;

shl.b32 %r36, %r5, 6;
add.s32 %r73, %r36, %r2;
setp.ge.u32 %p2, %r73, %r29;
@%p2 bra $L__BB141_9;

shl.b32 %r7, %r4, 6;

$L__BB141_3:
mul.wide.u32 %rd5, %r73, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f52, %f52, %f18;
add.s32 %r73, %r73, %r7;
setp.lt.u32 %p3, %r73, %r29;
@%p3 bra $L__BB141_3;
bra.uni $L__BB141_9;

$L__BB141_4:
shl.b32 %r37, %r5, 7;
add.s32 %r74, %r37, %r2;
setp.ge.u32 %p4, %r74, %r29;
@%p4 bra $L__BB141_9;

cvt.u64.u32 %rd2, %r29;
shl.b32 %r11, %r4, 7;

$L__BB141_6:
cvt.u64.u32 %rd7, %r74;
mul.wide.u32 %rd8, %r74, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f52, %f52, %f21;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p5, %rd10, %rd2;
@%p5 bra $L__BB141_8;

add.s32 %r38, %r74, %r1;
mul.wide.u32 %rd11, %r38, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f52, %f52, %f22;

$L__BB141_8:
add.s32 %r74, %r74, %r11;
setp.lt.u32 %p6, %r74, %r29;
@%p6 bra $L__BB141_6;

$L__BB141_9:
mov.b32 %r39, %f52;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.bfly.b32 %r43|%p7, %r39, %r41, %r40, %r42;
mov.b32 %f23, %r43;
add.f32 %f24, %f52, %f23;
mov.b32 %r44, %f24;
mov.u32 %r45, 8;
shfl.sync.bfly.b32 %r46|%p8, %r44, %r45, %r40, %r42;
mov.b32 %f25, %r46;
add.f32 %f26, %f24, %f25;
mov.b32 %r47, %f26;
mov.u32 %r48, 4;
shfl.sync.bfly.b32 %r49|%p9, %r47, %r48, %r40, %r42;
mov.b32 %f27, %r49;
add.f32 %f28, %f26, %f27;
mov.b32 %r50, %f28;
mov.u32 %r51, 2;
shfl.sync.bfly.b32 %r52|%p10, %r50, %r51, %r40, %r42;
mov.b32 %f29, %r52;
add.f32 %f30, %f28, %f29;
mov.b32 %r53, %f30;
mov.u32 %r54, 1;
shfl.sync.bfly.b32 %r55|%p11, %r53, %r54, %r40, %r42;
mov.b32 %f31, %r55;
add.f32 %f8, %f30, %f31;
and.b32 %r56, %r3, 31;
setp.ne.s32 %p12, %r56, 0;
@%p12 bra $L__BB141_11;

shr.u32 %r57, %r3, 3;
and.b32 %r58, %r57, 536870908;
mov.u32 %r59, __smem;
add.s32 %r60, %r59, %r58;
st.shared.f32 [%r60], %f8;

$L__BB141_11:
barrier.sync 0;
setp.ne.s32 %p13, %r2, 0;
@%p13 bra $L__BB141_20;

mul.lo.s32 %r63, %r1, %r30;
mov.u32 %r64, %ntid.z;
mad.lo.s32 %r65, %r63, %r64, 31;
shr.u32 %r14, %r65, 5;
setp.eq.s32 %p14, %r14, 0;
mov.f32 %f57, 0f00000000;
@%p14 bra $L__BB141_19;

add.s32 %r67, %r14, -1;
and.b32 %r80, %r14, 3;
setp.lt.u32 %p15, %r67, 3;
mov.f32 %f57, 0f00000000;
mov.u32 %r78, 0;
@%p15 bra $L__BB141_16;

sub.s32 %r77, %r14, %r80;
mov.u32 %r75, __smem;

$L__BB141_15:
ld.shared.v4.f32 {%f36, %f37, %f38, %f39}, [%r75];
add.f32 %f44, %f57, %f36;
add.f32 %f45, %f44, %f37;
add.f32 %f46, %f45, %f38;
add.f32 %f57, %f46, %f39;
add.s32 %r78, %r78, 4;
add.s32 %r75, %r75, 16;
add.s32 %r77, %r77, -4;
setp.ne.s32 %p16, %r77, 0;
@%p16 bra $L__BB141_15;

$L__BB141_16:
setp.eq.s32 %p17, %r80, 0;
@%p17 bra $L__BB141_19;

shl.b32 %r70, %r78, 2;
mov.u32 %r71, __smem;
add.s32 %r79, %r71, %r70;

$L__BB141_18:
.pragma "nounroll";
ld.shared.f32 %f47, [%r79];
add.f32 %f57, %f57, %f47;
add.s32 %r79, %r79, 4;
add.s32 %r80, %r80, -1;
setp.ne.s32 %p18, %r80, 0;
@%p18 bra $L__BB141_18;

$L__BB141_19:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r5, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f57;

$L__BB141_20:
ret;

}

.visible .entry _Z7reduce0IdEvPT_S1_j(
.param .u64 _Z7reduce0IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<16>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IdEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce0IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra $L__BB142_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

$L__BB142_2:
shl.b32 %r9, %r3, 3;
mov.u32 %r10, __smem_d;
add.s32 %r5, %r10, %r9;
st.shared.f64 [%r5], %fd8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB142_7;

mov.u32 %r15, 1;

$L__BB142_4:
shl.b32 %r7, %r15, 1;
rem.u32 %r12, %r3, %r7;
setp.ne.s32 %p3, %r12, 0;
@%p3 bra $L__BB142_6;

shl.b32 %r13, %r15, 3;
add.s32 %r14, %r5, %r13;
ld.shared.f64 %fd4, [%r5];
ld.shared.f64 %fd5, [%r14];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r5], %fd6;

$L__BB142_6:
barrier.sync 0;
setp.lt.u32 %p4, %r7, %r1;
mov.u32 %r15, %r7;
@%p4 bra $L__BB142_4;

$L__BB142_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB142_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

$L__BB142_9:
ret;

}

.visible .entry _Z7reduce1IdEvPT_S1_j(
.param .u64 _Z7reduce1IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<20>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IdEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce1IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra $L__BB143_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

$L__BB143_2:
shl.b32 %r9, %r3, 3;
mov.u32 %r10, __smem_d;
add.s32 %r11, %r10, %r9;
st.shared.f64 [%r11], %fd8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB143_7;

mov.u32 %r19, 1;

$L__BB143_4:
shl.b32 %r6, %r19, 1;
mul.lo.s32 %r7, %r6, %r3;
setp.ge.u32 %p3, %r7, %r1;
@%p3 bra $L__BB143_6;

add.s32 %r13, %r7, %r19;
shl.b32 %r14, %r13, 3;
add.s32 %r16, %r10, %r14;
shl.b32 %r17, %r7, 3;
add.s32 %r18, %r10, %r17;
ld.shared.f64 %fd4, [%r18];
ld.shared.f64 %fd5, [%r16];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r18], %fd6;

$L__BB143_6:
barrier.sync 0;
setp.lt.u32 %p4, %r6, %r1;
mov.u32 %r19, %r6;
@%p4 bra $L__BB143_4;

$L__BB143_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB143_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

$L__BB143_9:
ret;

}

.visible .entry _Z7reduce2IdEvPT_S1_j(
.param .u64 _Z7reduce2IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce2IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce2IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<15>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce2IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce2IdEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce2IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r9;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra $L__BB144_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

$L__BB144_2:
shl.b32 %r10, %r3, 3;
mov.u32 %r11, __smem_d;
add.s32 %r5, %r11, %r10;
st.shared.f64 [%r5], %fd8;
barrier.sync 0;
shr.u32 %r14, %r1, 1;
setp.eq.s32 %p2, %r14, 0;
@%p2 bra $L__BB144_7;

$L__BB144_4:
setp.ge.u32 %p3, %r3, %r14;
@%p3 bra $L__BB144_6;

shl.b32 %r12, %r14, 3;
add.s32 %r13, %r5, %r12;
ld.shared.f64 %fd4, [%r5];
ld.shared.f64 %fd5, [%r13];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r5], %fd6;

$L__BB144_6:
barrier.sync 0;
shr.u32 %r14, %r14, 1;
setp.ne.s32 %p4, %r14, 0;
@%p4 bra $L__BB144_4;

$L__BB144_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB144_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

$L__BB144_9:
ret;

}

.visible .entry _Z7reduce3IdEvPT_S1_j(
.param .u64 _Z7reduce3IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IdEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .b32 %r<17>;
.reg .f64 %fd<17>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IdEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce3IdEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
mov.f64 %fd15, 0d0000000000000000;
@%p1 bra $L__BB145_2;

mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd15, [%rd5];

$L__BB145_2:
add.s32 %r5, %r4, %r1;
setp.ge.u32 %p2, %r5, %r10;
@%p2 bra $L__BB145_4;

mul.wide.u32 %rd6, %r5, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd10, [%rd7];
add.f64 %fd15, %fd15, %fd10;

$L__BB145_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r6, %r13, %r12;
st.shared.f64 [%r6], %fd15;
barrier.sync 0;
shr.u32 %r16, %r1, 1;
setp.eq.s32 %p3, %r16, 0;
@%p3 bra $L__BB145_9;

$L__BB145_6:
setp.ge.u32 %p4, %r3, %r16;
@%p4 bra $L__BB145_8;

shl.b32 %r14, %r16, 3;
add.s32 %r15, %r6, %r14;
ld.shared.f64 %fd11, [%r15];
add.f64 %fd15, %fd15, %fd11;
st.shared.f64 [%r6], %fd15;

$L__BB145_8:
barrier.sync 0;
shr.u32 %r16, %r16, 1;
setp.ne.s32 %p5, %r16, 0;
@%p5 bra $L__BB145_6;

$L__BB145_9:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra $L__BB145_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd15;

$L__BB145_11:
ret;

}

.visible .entry _Z7reduce4IdLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj512EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB146_2;

ld.global.f64 %fd28, [%rd1];

$L__BB146_2:
add.s32 %r11, %r4, 512;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB146_4;

ld.global.f64 %fd12, [%rd1+4096];
add.f64 %fd28, %fd28, %fd12;

$L__BB146_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB146_9;

mov.u32 %r47, %r1;

$L__BB146_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB146_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB146_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB146_6;

$L__BB146_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB146_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB146_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB146_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB146_13:
ret;

}

.visible .entry _Z7reduce4IdLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj256EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB147_2;

ld.global.f64 %fd28, [%rd1];

$L__BB147_2:
add.s32 %r11, %r4, 256;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB147_4;

ld.global.f64 %fd12, [%rd1+2048];
add.f64 %fd28, %fd28, %fd12;

$L__BB147_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB147_9;

mov.u32 %r47, %r1;

$L__BB147_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB147_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB147_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB147_6;

$L__BB147_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB147_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB147_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB147_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB147_13:
ret;

}

.visible .entry _Z7reduce4IdLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj128EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB148_2;

ld.global.f64 %fd28, [%rd1];

$L__BB148_2:
add.s32 %r11, %r4, 128;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB148_4;

ld.global.f64 %fd12, [%rd1+1024];
add.f64 %fd28, %fd28, %fd12;

$L__BB148_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB148_9;

mov.u32 %r47, %r1;

$L__BB148_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB148_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB148_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB148_6;

$L__BB148_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB148_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB148_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB148_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB148_13:
ret;

}

.visible .entry _Z7reduce4IdLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj64EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB149_2;

ld.global.f64 %fd28, [%rd1];

$L__BB149_2:
add.s32 %r11, %r4, 64;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB149_4;

ld.global.f64 %fd12, [%rd1+512];
add.f64 %fd28, %fd28, %fd12;

$L__BB149_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB149_9;

mov.u32 %r47, %r1;

$L__BB149_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB149_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB149_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB149_6;

$L__BB149_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB149_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB149_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB149_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB149_13:
ret;

}

.visible .entry _Z7reduce4IdLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj32EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB150_2;

ld.global.f64 %fd27, [%rd1];

$L__BB150_2:
add.s32 %r11, %r4, 32;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB150_4;

ld.global.f64 %fd12, [%rd1+256];
add.f64 %fd27, %fd27, %fd12;

$L__BB150_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB150_9;

mov.u32 %r47, %r1;

$L__BB150_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB150_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB150_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB150_6;

$L__BB150_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB150_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB150_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB150_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB150_13:
ret;

}

.visible .entry _Z7reduce4IdLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj16EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB151_2;

ld.global.f64 %fd27, [%rd1];

$L__BB151_2:
add.s32 %r11, %r4, 16;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB151_4;

ld.global.f64 %fd12, [%rd1+128];
add.f64 %fd27, %fd27, %fd12;

$L__BB151_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB151_9;

mov.u32 %r47, %r1;

$L__BB151_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB151_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB151_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB151_6;

$L__BB151_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB151_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB151_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB151_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB151_13:
ret;

}

.visible .entry _Z7reduce4IdLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj8EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB152_2;

ld.global.f64 %fd27, [%rd1];

$L__BB152_2:
add.s32 %r11, %r4, 8;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB152_4;

ld.global.f64 %fd12, [%rd1+64];
add.f64 %fd27, %fd27, %fd12;

$L__BB152_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB152_9;

mov.u32 %r47, %r1;

$L__BB152_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB152_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB152_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB152_6;

$L__BB152_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB152_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB152_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB152_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB152_13:
ret;

}

.visible .entry _Z7reduce4IdLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj4EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB153_2;

ld.global.f64 %fd27, [%rd1];

$L__BB153_2:
add.s32 %r11, %r4, 4;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB153_4;

ld.global.f64 %fd12, [%rd1+32];
add.f64 %fd27, %fd27, %fd12;

$L__BB153_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB153_9;

mov.u32 %r47, %r1;

$L__BB153_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB153_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB153_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB153_6;

$L__BB153_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB153_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB153_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB153_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB153_13:
ret;

}

.visible .entry _Z7reduce4IdLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj2EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB154_2;

ld.global.f64 %fd27, [%rd1];

$L__BB154_2:
add.s32 %r11, %r4, 2;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB154_4;

ld.global.f64 %fd12, [%rd1+16];
add.f64 %fd27, %fd27, %fd12;

$L__BB154_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB154_9;

mov.u32 %r47, %r1;

$L__BB154_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB154_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB154_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB154_6;

$L__BB154_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB154_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB154_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB154_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB154_13:
ret;

}

.visible .entry _Z7reduce4IdLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB155_2;

ld.global.f64 %fd27, [%rd1];

$L__BB155_2:
add.s32 %r11, %r4, 1;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB155_4;

ld.global.f64 %fd12, [%rd1+8];
add.f64 %fd27, %fd27, %fd12;

$L__BB155_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB155_9;

mov.u32 %r47, %r1;

$L__BB155_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB155_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB155_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB155_6;

$L__BB155_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB155_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB155_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB155_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB155_13:
ret;

}

.visible .entry _Z7reduce5IdLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<43>;
.reg .f64 %fd<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj512EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd30, 0d0000000000000000;
@%p1 bra $L__BB156_2;

ld.global.f64 %fd30, [%rd1];

$L__BB156_2:
add.s32 %r8, %r3, 512;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB156_4;

ld.global.f64 %fd14, [%rd1+4096];
add.f64 %fd30, %fd30, %fd14;

$L__BB156_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB156_6;

ld.shared.f64 %fd15, [%r4+2048];
add.f64 %fd30, %fd30, %fd15;
st.shared.f64 [%r4], %fd30;

$L__BB156_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB156_8;

ld.shared.f64 %fd16, [%r4+1024];
add.f64 %fd30, %fd30, %fd16;
st.shared.f64 [%r4], %fd30;

$L__BB156_8:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB156_10;

ld.shared.f64 %fd17, [%r4+512];
add.f64 %fd30, %fd30, %fd17;
st.shared.f64 [%r4], %fd30;

$L__BB156_10:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p6, %r5, 31;
@%p6 bra $L__BB156_12;

ld.shared.f64 %fd28, [%r4+256];
add.f64 %fd18, %fd30, %fd28;

	mov.b64 {%r16,%r17}, %fd18;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p7, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p8, %r16, %r38, %r37, %r39;

	mov.b64 %fd19, {%r18,%r19};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r20,%r21}, %fd20;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p9, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p10, %r20, %r40, %r37, %r39;

	mov.b64 %fd21, {%r22,%r23};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r24,%r25}, %fd22;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p11, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p12, %r24, %r41, %r37, %r39;

	mov.b64 %fd23, {%r26,%r27};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r28,%r29}, %fd24;

	shfl.sync.down.b32 %r31|%p13, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p14, %r28, %r36, %r37, %r39;

	mov.b64 %fd25, {%r30,%r31};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r32,%r33}, %fd26;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p15, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p16, %r32, %r42, %r37, %r39;

	mov.b64 %fd27, {%r34,%r35};

	add.f64 %fd30, %fd26, %fd27;

$L__BB156_12:
setp.ne.s32 %p17, %r5, 0;
@%p17 bra $L__BB156_14;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd30;

$L__BB156_14:
ret;

}

.visible .entry _Z7reduce5IdLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<43>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj256EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB157_2;

ld.global.f64 %fd27, [%rd1];

$L__BB157_2:
add.s32 %r8, %r3, 256;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB157_4;

ld.global.f64 %fd12, [%rd1+2048];
add.f64 %fd27, %fd27, %fd12;

$L__BB157_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB157_6;

ld.shared.f64 %fd13, [%r4+1024];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r4], %fd27;

$L__BB157_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB157_8;

ld.shared.f64 %fd14, [%r4+512];
add.f64 %fd27, %fd27, %fd14;
st.shared.f64 [%r4], %fd27;

$L__BB157_8:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p5, %r5, 31;
@%p5 bra $L__BB157_10;

ld.shared.f64 %fd25, [%r4+256];
add.f64 %fd15, %fd27, %fd25;

	mov.b64 {%r16,%r17}, %fd15;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p6, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p7, %r16, %r38, %r37, %r39;

	mov.b64 %fd16, {%r18,%r19};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r20,%r21}, %fd17;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p8, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p9, %r20, %r40, %r37, %r39;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r24,%r25}, %fd19;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p10, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p11, %r24, %r41, %r37, %r39;

	mov.b64 %fd20, {%r26,%r27};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r28,%r29}, %fd21;

	shfl.sync.down.b32 %r31|%p12, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p13, %r28, %r36, %r37, %r39;

	mov.b64 %fd22, {%r30,%r31};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r32,%r33}, %fd23;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p14, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p15, %r32, %r42, %r37, %r39;

	mov.b64 %fd24, {%r34,%r35};

	add.f64 %fd27, %fd23, %fd24;

$L__BB157_10:
setp.ne.s32 %p16, %r5, 0;
@%p16 bra $L__BB157_12;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB157_12:
ret;

}

.visible .entry _Z7reduce5IdLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<43>;
.reg .f64 %fd<27>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj128EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd24, 0d0000000000000000;
@%p1 bra $L__BB158_2;

ld.global.f64 %fd24, [%rd1];

$L__BB158_2:
add.s32 %r8, %r3, 128;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB158_4;

ld.global.f64 %fd10, [%rd1+1024];
add.f64 %fd24, %fd24, %fd10;

$L__BB158_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB158_6;

ld.shared.f64 %fd11, [%r4+512];
add.f64 %fd24, %fd24, %fd11;
st.shared.f64 [%r4], %fd24;

$L__BB158_6:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p4, %r5, 31;
@%p4 bra $L__BB158_8;

ld.shared.f64 %fd22, [%r4+256];
add.f64 %fd12, %fd24, %fd22;

	mov.b64 {%r16,%r17}, %fd12;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p5, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p6, %r16, %r38, %r37, %r39;

	mov.b64 %fd13, {%r18,%r19};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p7, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p8, %r20, %r40, %r37, %r39;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p9, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p10, %r24, %r41, %r37, %r39;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	shfl.sync.down.b32 %r31|%p11, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p12, %r28, %r36, %r37, %r39;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p13, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p14, %r32, %r42, %r37, %r39;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd24, %fd20, %fd21;

$L__BB158_8:
setp.ne.s32 %p15, %r5, 0;
@%p15 bra $L__BB158_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd24;

$L__BB158_10:
ret;

}

.visible .entry _Z7reduce5IdLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj64EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB159_2;

ld.global.f64 %fd21, [%rd1];

$L__BB159_2:
add.s32 %r8, %r3, 64;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB159_4;

ld.global.f64 %fd8, [%rd1+512];
add.f64 %fd21, %fd21, %fd8;

$L__BB159_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p3, %r5, 31;
@%p3 bra $L__BB159_6;

ld.shared.f64 %fd19, [%r4+256];
add.f64 %fd9, %fd21, %fd19;

	mov.b64 {%r16,%r17}, %fd9;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd9, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd21, %fd17, %fd18;

$L__BB159_6:
setp.ne.s32 %p14, %r5, 0;
@%p14 bra $L__BB159_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB159_8:
ret;

}

.visible .entry _Z7reduce5IdLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj32EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB160_2;

ld.global.f64 %fd20, [%rd1];

$L__BB160_2:
add.s32 %r7, %r3, 32;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB160_4;

ld.global.f64 %fd8, [%rd1+256];
add.f64 %fd20, %fd20, %fd8;

$L__BB160_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB160_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB160_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB160_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB160_8:
ret;

}

.visible .entry _Z7reduce5IdLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj16EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB161_2;

ld.global.f64 %fd20, [%rd1];

$L__BB161_2:
add.s32 %r7, %r3, 16;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB161_4;

ld.global.f64 %fd8, [%rd1+128];
add.f64 %fd20, %fd20, %fd8;

$L__BB161_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB161_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB161_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB161_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB161_8:
ret;

}

.visible .entry _Z7reduce5IdLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj8EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB162_2;

ld.global.f64 %fd20, [%rd1];

$L__BB162_2:
add.s32 %r7, %r3, 8;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB162_4;

ld.global.f64 %fd8, [%rd1+64];
add.f64 %fd20, %fd20, %fd8;

$L__BB162_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB162_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB162_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB162_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB162_8:
ret;

}

.visible .entry _Z7reduce5IdLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj4EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB163_2;

ld.global.f64 %fd20, [%rd1];

$L__BB163_2:
add.s32 %r7, %r3, 4;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB163_4;

ld.global.f64 %fd8, [%rd1+32];
add.f64 %fd20, %fd20, %fd8;

$L__BB163_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB163_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB163_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB163_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB163_8:
ret;

}

.visible .entry _Z7reduce5IdLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj2EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB164_2;

ld.global.f64 %fd20, [%rd1];

$L__BB164_2:
add.s32 %r7, %r3, 2;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB164_4;

ld.global.f64 %fd8, [%rd1+16];
add.f64 %fd20, %fd20, %fd8;

$L__BB164_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB164_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB164_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB164_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB164_8:
ret;

}

.visible .entry _Z7reduce5IdLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj1EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB165_2;

ld.global.f64 %fd20, [%rd1];

$L__BB165_2:
add.s32 %r7, %r3, 1;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB165_4;

ld.global.f64 %fd8, [%rd1+8];
add.f64 %fd20, %fd20, %fd8;

$L__BB165_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB165_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB165_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB165_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB165_8:
ret;

}

.visible .entry _Z7reduce6IdLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<19>;
.reg .b32 %r<48>;
.reg .f64 %fd<39>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd32, 0d0000000000000000;
@%p1 bra $L__BB166_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 10;

$L__BB166_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd16, [%rd5];
add.f64 %fd32, %fd32, %fd16;
add.s32 %r6, %r47, 512;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB166_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd17, [%rd7];
add.f64 %fd32, %fd32, %fd17;

$L__BB166_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB166_2;

$L__BB166_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd32;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 255;
@%p4 bra $L__BB166_7;

ld.shared.f64 %fd18, [%r8+2048];
add.f64 %fd32, %fd32, %fd18;
st.shared.f64 [%r8], %fd32;

$L__BB166_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 127;
@%p5 bra $L__BB166_9;

ld.shared.f64 %fd19, [%r8+1024];
add.f64 %fd32, %fd32, %fd19;
st.shared.f64 [%r8], %fd32;

$L__BB166_9:
barrier.sync 0;
setp.gt.u32 %p6, %r2, 63;
@%p6 bra $L__BB166_11;

ld.shared.f64 %fd20, [%r8+512];
add.f64 %fd32, %fd32, %fd20;
st.shared.f64 [%r8], %fd32;

$L__BB166_11:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p7, %r9, 31;
@%p7 bra $L__BB166_13;

ld.shared.f64 %fd31, [%r8+256];
add.f64 %fd21, %fd32, %fd31;

	mov.b64 {%r20,%r21}, %fd21;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p8, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p9, %r20, %r42, %r41, %r43;

	mov.b64 %fd22, {%r22,%r23};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r24,%r25}, %fd23;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p10, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p11, %r24, %r44, %r41, %r43;

	mov.b64 %fd24, {%r26,%r27};

	add.f64 %fd25, %fd23, %fd24;

	mov.b64 {%r28,%r29}, %fd25;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p12, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p13, %r28, %r45, %r41, %r43;

	mov.b64 %fd26, {%r30,%r31};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r32,%r33}, %fd27;

	shfl.sync.down.b32 %r35|%p14, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p15, %r32, %r40, %r41, %r43;

	mov.b64 %fd28, {%r34,%r35};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r36,%r37}, %fd29;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p16, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p17, %r36, %r46, %r41, %r43;

	mov.b64 %fd30, {%r38,%r39};

	add.f64 %fd32, %fd29, %fd30;

$L__BB166_13:
setp.ne.s32 %p18, %r9, 0;
@%p18 bra $L__BB166_15;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd32;

$L__BB166_15:
ret;

}

.visible .entry _Z7reduce6IdLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<35>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd29, 0d0000000000000000;
@%p1 bra $L__BB167_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 9;

$L__BB167_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd14, [%rd5];
add.f64 %fd29, %fd29, %fd14;
add.s32 %r6, %r47, 256;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB167_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd15, [%rd7];
add.f64 %fd29, %fd29, %fd15;

$L__BB167_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB167_2;

$L__BB167_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd29;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB167_7;

ld.shared.f64 %fd16, [%r8+1024];
add.f64 %fd29, %fd29, %fd16;
st.shared.f64 [%r8], %fd29;

$L__BB167_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB167_9;

ld.shared.f64 %fd17, [%r8+512];
add.f64 %fd29, %fd29, %fd17;
st.shared.f64 [%r8], %fd29;

$L__BB167_9:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra $L__BB167_11;

ld.shared.f64 %fd28, [%r8+256];
add.f64 %fd18, %fd29, %fd28;

	mov.b64 {%r20,%r21}, %fd18;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd19, {%r22,%r23};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r24,%r25}, %fd20;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd21, {%r26,%r27};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r28,%r29}, %fd22;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd23, {%r30,%r31};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r32,%r33}, %fd24;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd25, {%r34,%r35};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r36,%r37}, %fd26;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd27, {%r38,%r39};

	add.f64 %fd29, %fd26, %fd27;

$L__BB167_11:
setp.ne.s32 %p17, %r9, 0;
@%p17 bra $L__BB167_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd29;

$L__BB167_13:
ret;

}

.visible .entry _Z7reduce6IdLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd26, 0d0000000000000000;
@%p1 bra $L__BB168_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 8;

$L__BB168_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd26, %fd26, %fd12;
add.s32 %r6, %r47, 128;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB168_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd13, [%rd7];
add.f64 %fd26, %fd26, %fd13;

$L__BB168_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB168_2;

$L__BB168_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd26;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB168_7;

ld.shared.f64 %fd14, [%r8+512];
add.f64 %fd26, %fd26, %fd14;
st.shared.f64 [%r8], %fd26;

$L__BB168_7:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p5, %r9, 31;
@%p5 bra $L__BB168_9;

ld.shared.f64 %fd25, [%r8+256];
add.f64 %fd15, %fd26, %fd25;

	mov.b64 {%r20,%r21}, %fd15;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p6, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p7, %r20, %r42, %r41, %r43;

	mov.b64 %fd16, {%r22,%r23};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r24,%r25}, %fd17;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p8, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p9, %r24, %r44, %r41, %r43;

	mov.b64 %fd18, {%r26,%r27};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r28,%r29}, %fd19;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p10, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p11, %r28, %r45, %r41, %r43;

	mov.b64 %fd20, {%r30,%r31};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r32,%r33}, %fd21;

	shfl.sync.down.b32 %r35|%p12, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p13, %r32, %r40, %r41, %r43;

	mov.b64 %fd22, {%r34,%r35};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r36,%r37}, %fd23;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p14, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p15, %r36, %r46, %r41, %r43;

	mov.b64 %fd24, {%r38,%r39};

	add.f64 %fd26, %fd23, %fd24;

$L__BB168_9:
setp.ne.s32 %p16, %r9, 0;
@%p16 bra $L__BB168_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd26;

$L__BB168_11:
ret;

}

.visible .entry _Z7reduce6IdLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<27>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd23, 0d0000000000000000;
@%p1 bra $L__BB169_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 7;

$L__BB169_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd23, %fd23, %fd10;
add.s32 %r6, %r47, 64;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB169_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd23, %fd23, %fd11;

$L__BB169_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB169_2;

$L__BB169_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd23;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p4, %r9, 31;
@%p4 bra $L__BB169_7;

ld.shared.f64 %fd22, [%r8+256];
add.f64 %fd12, %fd23, %fd22;

	mov.b64 {%r20,%r21}, %fd12;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd23, %fd20, %fd21;

$L__BB169_7:
setp.ne.s32 %p15, %r9, 0;
@%p15 bra $L__BB169_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd23;

$L__BB169_9:
ret;

}

.visible .entry _Z7reduce6IdLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB170_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;

$L__BB170_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 32;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB170_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB170_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB170_2;

$L__BB170_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB170_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB170_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB170_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB170_9:
ret;

}

.visible .entry _Z7reduce6IdLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB171_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 5;

$L__BB171_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 16;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB171_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB171_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB171_2;

$L__BB171_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB171_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB171_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB171_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB171_9:
ret;

}

.visible .entry _Z7reduce6IdLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB172_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 4;

$L__BB172_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 8;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB172_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB172_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB172_2;

$L__BB172_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB172_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB172_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB172_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB172_9:
ret;

}

.visible .entry _Z7reduce6IdLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB173_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 3;

$L__BB173_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 4;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB173_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB173_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB173_2;

$L__BB173_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB173_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB173_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB173_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB173_9:
ret;

}

.visible .entry _Z7reduce6IdLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB174_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 2;

$L__BB174_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 2;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB174_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB174_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB174_2;

$L__BB174_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB174_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB174_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB174_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB174_9:
ret;

}

.visible .entry _Z7reduce6IdLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB175_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 1;

$L__BB175_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 1;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB175_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB175_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB175_2;

$L__BB175_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB175_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB175_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB175_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB175_9:
ret;

}

.visible .entry _Z7reduce6IdLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<47>;
.reg .f64 %fd<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd30, 0d0000000000000000;
@%p1 bra $L__BB176_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB176_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd14, [%rd5];
add.f64 %fd30, %fd30, %fd14;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB176_2;

$L__BB176_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB176_5;

ld.shared.f64 %fd15, [%r7+2048];
add.f64 %fd30, %fd30, %fd15;
st.shared.f64 [%r7], %fd30;

$L__BB176_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB176_7;

ld.shared.f64 %fd16, [%r7+1024];
add.f64 %fd30, %fd30, %fd16;
st.shared.f64 [%r7], %fd30;

$L__BB176_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB176_9;

ld.shared.f64 %fd17, [%r7+512];
add.f64 %fd30, %fd30, %fd17;
st.shared.f64 [%r7], %fd30;

$L__BB176_9:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB176_11;

ld.shared.f64 %fd28, [%r7+256];
add.f64 %fd18, %fd30, %fd28;

	mov.b64 {%r19,%r20}, %fd18;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p7, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p8, %r19, %r41, %r40, %r42;

	mov.b64 %fd19, {%r21,%r22};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r23,%r24}, %fd20;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p9, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p10, %r23, %r43, %r40, %r42;

	mov.b64 %fd21, {%r25,%r26};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r27,%r28}, %fd22;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p11, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p12, %r27, %r44, %r40, %r42;

	mov.b64 %fd23, {%r29,%r30};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r31,%r32}, %fd24;

	shfl.sync.down.b32 %r34|%p13, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p14, %r31, %r39, %r40, %r42;

	mov.b64 %fd25, {%r33,%r34};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r35,%r36}, %fd26;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p15, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p16, %r35, %r45, %r40, %r42;

	mov.b64 %fd27, {%r37,%r38};

	add.f64 %fd30, %fd26, %fd27;

$L__BB176_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB176_13;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd30;

$L__BB176_13:
ret;

}

.visible .entry _Z7reduce6IdLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<47>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB177_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB177_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd27, %fd27, %fd12;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB177_2;

$L__BB177_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB177_5;

ld.shared.f64 %fd13, [%r7+1024];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r7], %fd27;

$L__BB177_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB177_7;

ld.shared.f64 %fd14, [%r7+512];
add.f64 %fd27, %fd27, %fd14;
st.shared.f64 [%r7], %fd27;

$L__BB177_7:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p5, %r8, 31;
@%p5 bra $L__BB177_9;

ld.shared.f64 %fd25, [%r7+256];
add.f64 %fd15, %fd27, %fd25;

	mov.b64 {%r19,%r20}, %fd15;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p6, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p7, %r19, %r41, %r40, %r42;

	mov.b64 %fd16, {%r21,%r22};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r23,%r24}, %fd17;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p8, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p9, %r23, %r43, %r40, %r42;

	mov.b64 %fd18, {%r25,%r26};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r27,%r28}, %fd19;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p10, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p11, %r27, %r44, %r40, %r42;

	mov.b64 %fd20, {%r29,%r30};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r31,%r32}, %fd21;

	shfl.sync.down.b32 %r34|%p12, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p13, %r31, %r39, %r40, %r42;

	mov.b64 %fd22, {%r33,%r34};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r35,%r36}, %fd23;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p14, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p15, %r35, %r45, %r40, %r42;

	mov.b64 %fd24, {%r37,%r38};

	add.f64 %fd27, %fd23, %fd24;

$L__BB177_9:
setp.ne.s32 %p16, %r8, 0;
@%p16 bra $L__BB177_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB177_11:
ret;

}

.visible .entry _Z7reduce6IdLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<47>;
.reg .f64 %fd<27>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd24, 0d0000000000000000;
@%p1 bra $L__BB178_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB178_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd24, %fd24, %fd10;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB178_2;

$L__BB178_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB178_5;

ld.shared.f64 %fd11, [%r7+512];
add.f64 %fd24, %fd24, %fd11;
st.shared.f64 [%r7], %fd24;

$L__BB178_5:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB178_7;

ld.shared.f64 %fd22, [%r7+256];
add.f64 %fd12, %fd24, %fd22;

	mov.b64 {%r19,%r20}, %fd12;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p5, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p6, %r19, %r41, %r40, %r42;

	mov.b64 %fd13, {%r21,%r22};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r23,%r24}, %fd14;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p7, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p8, %r23, %r43, %r40, %r42;

	mov.b64 %fd15, {%r25,%r26};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r27,%r28}, %fd16;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p9, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p10, %r27, %r44, %r40, %r42;

	mov.b64 %fd17, {%r29,%r30};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r31,%r32}, %fd18;

	shfl.sync.down.b32 %r34|%p11, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p12, %r31, %r39, %r40, %r42;

	mov.b64 %fd19, {%r33,%r34};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r35,%r36}, %fd20;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p13, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p14, %r35, %r45, %r40, %r42;

	mov.b64 %fd21, {%r37,%r38};

	add.f64 %fd24, %fd20, %fd21;

$L__BB178_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB178_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd24;

$L__BB178_9:
ret;

}

.visible .entry _Z7reduce6IdLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB179_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB179_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd21, %fd21, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB179_2;

$L__BB179_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB179_5;

ld.shared.f64 %fd19, [%r7+256];
add.f64 %fd9, %fd21, %fd19;

	mov.b64 {%r19,%r20}, %fd9;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd9, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd21, %fd17, %fd18;

$L__BB179_5:
setp.ne.s32 %p14, %r8, 0;
@%p14 bra $L__BB179_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB179_7:
ret;

}

.visible .entry _Z7reduce6IdLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB180_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB180_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB180_2;

$L__BB180_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB180_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB180_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB180_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB180_7:
ret;

}

.visible .entry _Z7reduce6IdLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB181_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB181_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB181_2;

$L__BB181_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB181_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB181_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB181_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB181_7:
ret;

}

.visible .entry _Z7reduce6IdLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB182_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB182_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB182_2;

$L__BB182_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB182_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB182_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB182_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB182_7:
ret;

}

.visible .entry _Z7reduce6IdLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB183_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB183_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB183_2;

$L__BB183_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB183_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB183_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB183_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB183_7:
ret;

}

.visible .entry _Z7reduce6IdLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB184_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB184_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB184_2;

$L__BB184_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB184_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB184_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB184_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB184_7:
ret;

}

.visible .entry _Z7reduce6IdLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<45>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r1, %r2;
setp.ge.u32 %p1, %r44, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB185_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB185_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r8;
@%p2 bra $L__BB185_2;

$L__BB185_3:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r11, %r10, %r9;
st.shared.f64 [%r11], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r7, %r15, %r16, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB185_5;


	mov.b64 {%r17,%r18}, %fd20;

	mov.u32 %r37, 2;
mov.u32 %r38, 31;
mov.u32 %r39, 16;
mov.u32 %r40, -1;
shfl.sync.down.b32 %r20|%p4, %r18, %r39, %r38, %r40;
shfl.sync.down.b32 %r19|%p5, %r17, %r39, %r38, %r40;

	mov.b64 %fd10, {%r19,%r20};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r21,%r22}, %fd11;

	mov.u32 %r41, 8;
shfl.sync.down.b32 %r24|%p6, %r22, %r41, %r38, %r40;
shfl.sync.down.b32 %r23|%p7, %r21, %r41, %r38, %r40;

	mov.b64 %fd12, {%r23,%r24};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r25,%r26}, %fd13;

	mov.u32 %r42, 4;
shfl.sync.down.b32 %r28|%p8, %r26, %r42, %r38, %r40;
shfl.sync.down.b32 %r27|%p9, %r25, %r42, %r38, %r40;

	mov.b64 %fd14, {%r27,%r28};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r29,%r30}, %fd15;

	shfl.sync.down.b32 %r32|%p10, %r30, %r37, %r38, %r40;
shfl.sync.down.b32 %r31|%p11, %r29, %r37, %r38, %r40;

	mov.b64 %fd16, {%r31,%r32};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r33,%r34}, %fd17;

	mov.u32 %r43, 1;
shfl.sync.down.b32 %r36|%p12, %r34, %r43, %r38, %r40;
shfl.sync.down.b32 %r35|%p13, %r33, %r43, %r38, %r40;

	mov.b64 %fd18, {%r35,%r36};

	add.f64 %fd20, %fd17, %fd18;

$L__BB185_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB185_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB185_7:
ret;

}

.visible .entry _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB186_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 11;

$L__BB186_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 1024;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB186_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB186_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB186_2;

$L__BB186_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB186_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB186_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB186_7;

$L__BB186_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB186_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB186_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 1024;
mov.u32 %r47, 1;
@%p9 bra $L__BB186_12;

mov.u32 %r33, 1024;
div.u32 %r47, %r33, %r48;

$L__BB186_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB186_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB186_16;

mov.u32 %r44, 31;

$L__BB186_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB186_15;

$L__BB186_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB186_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB186_18:
ret;

}

.visible .entry _Z7reduce7IdLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB187_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 10;

$L__BB187_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 512;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB187_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB187_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB187_2;

$L__BB187_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB187_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB187_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB187_7;

$L__BB187_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB187_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB187_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 512;
mov.u32 %r47, 1;
@%p9 bra $L__BB187_12;

mov.u32 %r33, 512;
div.u32 %r47, %r33, %r48;

$L__BB187_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB187_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB187_16;

mov.u32 %r44, 31;

$L__BB187_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB187_15;

$L__BB187_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB187_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB187_18:
ret;

}

.visible .entry _Z7reduce7IdLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB188_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 9;

$L__BB188_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 256;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB188_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB188_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB188_2;

$L__BB188_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB188_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB188_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB188_7;

$L__BB188_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB188_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB188_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 256;
mov.u32 %r47, 1;
@%p9 bra $L__BB188_12;

mov.u32 %r33, 256;
div.u32 %r47, %r33, %r48;

$L__BB188_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB188_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB188_16;

mov.u32 %r44, 31;

$L__BB188_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB188_15;

$L__BB188_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB188_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB188_18:
ret;

}

.visible .entry _Z7reduce7IdLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB189_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 8;

$L__BB189_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 128;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB189_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB189_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB189_2;

$L__BB189_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB189_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB189_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB189_7;

$L__BB189_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB189_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB189_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 128;
mov.u32 %r47, 1;
@%p9 bra $L__BB189_12;

mov.u32 %r33, 128;
div.u32 %r47, %r33, %r48;

$L__BB189_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB189_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB189_16;

mov.u32 %r44, 31;

$L__BB189_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB189_15;

$L__BB189_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB189_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB189_18:
ret;

}

.visible .entry _Z7reduce7IdLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB190_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 7;

$L__BB190_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 64;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB190_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB190_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB190_2;

$L__BB190_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB190_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB190_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB190_7;

$L__BB190_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB190_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB190_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 64;
mov.u32 %r47, 1;
@%p9 bra $L__BB190_12;

mov.u32 %r33, 64;
div.u32 %r47, %r33, %r48;

$L__BB190_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB190_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB190_16;

mov.u32 %r44, 31;

$L__BB190_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB190_15;

$L__BB190_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB190_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB190_18:
ret;

}

.visible .entry _Z7reduce7IdLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB191_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;

$L__BB191_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 32;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB191_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB191_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB191_2;

$L__BB191_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB191_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB191_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB191_7;

$L__BB191_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB191_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB191_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 32;
mov.u32 %r47, 1;
@%p9 bra $L__BB191_12;

mov.u32 %r33, 32;
div.u32 %r47, %r33, %r48;

$L__BB191_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB191_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB191_16;

mov.u32 %r44, 31;

$L__BB191_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB191_15;

$L__BB191_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB191_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB191_18:
ret;

}

.visible .entry _Z7reduce7IdLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB192_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 5;

$L__BB192_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 16;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB192_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB192_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB192_2;

$L__BB192_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB192_8;

mov.u32 %r25, 31;
mov.u32 %r26, 65535;
mov.u32 %r46, %r48;

$L__BB192_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB192_7;

$L__BB192_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB192_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB192_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 16;
mov.u32 %r47, 1;
@%p9 bra $L__BB192_12;

mov.u32 %r33, 16;
div.u32 %r47, %r33, %r48;

$L__BB192_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 65535;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB192_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB192_16;

mov.u32 %r44, 31;

$L__BB192_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB192_15;

$L__BB192_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB192_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB192_18:
ret;

}

.visible .entry _Z7reduce7IdLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB193_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 4;

$L__BB193_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 8;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB193_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB193_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB193_2;

$L__BB193_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB193_8;

mov.u32 %r25, 31;
mov.u32 %r26, 255;
mov.u32 %r46, %r48;

$L__BB193_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB193_7;

$L__BB193_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB193_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB193_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 8;
mov.u32 %r47, 1;
@%p9 bra $L__BB193_12;

mov.u32 %r33, 8;
div.u32 %r47, %r33, %r48;

$L__BB193_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 255;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB193_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB193_16;

mov.u32 %r44, 31;

$L__BB193_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB193_15;

$L__BB193_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB193_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB193_18:
ret;

}

.visible .entry _Z7reduce7IdLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB194_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 3;

$L__BB194_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 4;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB194_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB194_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB194_2;

$L__BB194_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB194_8;

mov.u32 %r25, 31;
mov.u32 %r26, 15;
mov.u32 %r46, %r48;

$L__BB194_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB194_7;

$L__BB194_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB194_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB194_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 4;
mov.u32 %r47, 1;
@%p9 bra $L__BB194_12;

mov.u32 %r33, 4;
div.u32 %r47, %r33, %r48;

$L__BB194_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 15;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB194_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB194_16;

mov.u32 %r44, 31;

$L__BB194_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB194_15;

$L__BB194_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB194_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB194_18:
ret;

}

.visible .entry _Z7reduce7IdLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB195_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 2;

$L__BB195_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 2;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB195_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB195_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB195_2;

$L__BB195_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB195_8;

mov.u32 %r25, 31;
mov.u32 %r26, 3;
mov.u32 %r46, %r48;

$L__BB195_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB195_7;

$L__BB195_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB195_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB195_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 2;
mov.u32 %r47, 1;
@%p9 bra $L__BB195_12;

mov.u32 %r33, 2;
div.u32 %r47, %r33, %r48;

$L__BB195_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 3;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB195_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB195_16;

mov.u32 %r44, 31;

$L__BB195_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB195_15;

$L__BB195_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB195_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB195_18:
ret;

}

.visible .entry _Z7reduce7IdLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<41>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r14, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r38, %r15, %r2;
setp.ge.u32 %p1, %r38, %r14;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB196_5;

mov.u32 %r16, %nctaid.x;
shl.b32 %r4, %r16, 1;

$L__BB196_2:
mul.wide.u32 %rd4, %r38, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r38, 1;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra $L__BB196_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB196_4:
add.s32 %r38, %r38, %r4;
setp.lt.u32 %p3, %r38, %r14;
@%p3 bra $L__BB196_2;

$L__BB196_5:
mov.u32 %r40, WARP_SZ;
setp.lt.s32 %p4, %r40, 2;
@%p4 bra $L__BB196_8;

mov.u32 %r23, 31;
mov.u32 %r24, 1;
mov.u32 %r39, %r40;

$L__BB196_7:

	mov.b64 {%r17,%r18}, %fd21;

	shr.u32 %r21, %r39, 31;
add.s32 %r22, %r39, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r20|%p5, %r18, %r10, %r23, %r24;
shfl.sync.down.b32 %r19|%p6, %r17, %r10, %r23, %r24;

	mov.b64 %fd18, {%r19,%r20};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r39, 3;
mov.u32 %r39, %r10;
@%p7 bra $L__BB196_7;

$L__BB196_8:
rem.u32 %r25, %r2, %r40;
setp.ne.s32 %p8, %r25, 0;
@%p8 bra $L__BB196_10;

div.u32 %r26, %r2, %r40;
shl.b32 %r27, %r26, 3;
mov.u32 %r28, __smem_d;
add.s32 %r29, %r28, %r27;
st.shared.f64 [%r29], %fd21;

$L__BB196_10:
bar.sync 0;
setp.ne.s32 %p9, %r2, 0;
setp.eq.s32 %p10, %r2, 0;
mov.u32 %r30, 1;
vote.sync.ballot.b32 %r11, %p10, %r30;
@%p9 bra $L__BB196_14;

ld.shared.f64 %fd21, [__smem_d];
@%p4 bra $L__BB196_14;

mov.u32 %r37, 31;

$L__BB196_13:

	mov.b64 {%r31,%r32}, %fd21;

	shr.u32 %r35, %r40, 31;
add.s32 %r36, %r40, %r35;
shr.s32 %r13, %r36, 1;
shfl.sync.down.b32 %r34|%p13, %r32, %r13, %r37, %r11;
shfl.sync.down.b32 %r33|%p14, %r31, %r13, %r37, %r11;

	mov.b64 %fd20, {%r33,%r34};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p15, %r40, 3;
mov.u32 %r40, %r13;
@%p15 bra $L__BB196_13;

$L__BB196_14:
@%p9 bra $L__BB196_16;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB196_16:
ret;

}

.visible .entry _Z7reduce7IdLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB197_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB197_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB197_2;

$L__BB197_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB197_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB197_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB197_5;

$L__BB197_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB197_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB197_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 512;
mov.u32 %r46, 1;
@%p8 bra $L__BB197_10;

mov.u32 %r32, 512;
div.u32 %r46, %r32, %r47;

$L__BB197_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB197_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB197_14;

mov.u32 %r43, 31;

$L__BB197_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB197_13;

$L__BB197_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB197_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB197_16:
ret;

}

.visible .entry _Z7reduce7IdLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB198_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB198_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB198_2;

$L__BB198_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB198_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB198_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB198_5;

$L__BB198_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB198_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB198_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 256;
mov.u32 %r46, 1;
@%p8 bra $L__BB198_10;

mov.u32 %r32, 256;
div.u32 %r46, %r32, %r47;

$L__BB198_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB198_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB198_14;

mov.u32 %r43, 31;

$L__BB198_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB198_13;

$L__BB198_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB198_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB198_16:
ret;

}

.visible .entry _Z7reduce7IdLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB199_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB199_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB199_2;

$L__BB199_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB199_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB199_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB199_5;

$L__BB199_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB199_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB199_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 128;
mov.u32 %r46, 1;
@%p8 bra $L__BB199_10;

mov.u32 %r32, 128;
div.u32 %r46, %r32, %r47;

$L__BB199_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB199_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB199_14;

mov.u32 %r43, 31;

$L__BB199_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB199_13;

$L__BB199_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB199_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB199_16:
ret;

}

.visible .entry _Z7reduce7IdLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB200_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB200_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB200_2;

$L__BB200_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB200_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB200_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB200_5;

$L__BB200_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB200_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB200_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 64;
mov.u32 %r46, 1;
@%p8 bra $L__BB200_10;

mov.u32 %r32, 64;
div.u32 %r46, %r32, %r47;

$L__BB200_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB200_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB200_14;

mov.u32 %r43, 31;

$L__BB200_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB200_13;

$L__BB200_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB200_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB200_16:
ret;

}

.visible .entry _Z7reduce7IdLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB201_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB201_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB201_2;

$L__BB201_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB201_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB201_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB201_5;

$L__BB201_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB201_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB201_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 32;
mov.u32 %r46, 1;
@%p8 bra $L__BB201_10;

mov.u32 %r32, 32;
div.u32 %r46, %r32, %r47;

$L__BB201_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB201_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB201_14;

mov.u32 %r43, 31;

$L__BB201_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB201_13;

$L__BB201_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB201_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB201_16:
ret;

}

.visible .entry _Z7reduce7IdLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB202_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB202_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB202_2;

$L__BB202_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB202_6;

mov.u32 %r24, 31;
mov.u32 %r25, 65535;
mov.u32 %r45, %r47;

$L__BB202_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB202_5;

$L__BB202_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB202_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB202_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 16;
mov.u32 %r46, 1;
@%p8 bra $L__BB202_10;

mov.u32 %r32, 16;
div.u32 %r46, %r32, %r47;

$L__BB202_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 65535;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB202_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB202_14;

mov.u32 %r43, 31;

$L__BB202_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB202_13;

$L__BB202_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB202_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB202_16:
ret;

}

.visible .entry _Z7reduce7IdLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB203_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB203_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB203_2;

$L__BB203_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB203_6;

mov.u32 %r24, 31;
mov.u32 %r25, 255;
mov.u32 %r45, %r47;

$L__BB203_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB203_5;

$L__BB203_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB203_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB203_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 8;
mov.u32 %r46, 1;
@%p8 bra $L__BB203_10;

mov.u32 %r32, 8;
div.u32 %r46, %r32, %r47;

$L__BB203_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 255;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB203_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB203_14;

mov.u32 %r43, 31;

$L__BB203_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB203_13;

$L__BB203_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB203_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB203_16:
ret;

}

.visible .entry _Z7reduce7IdLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB204_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB204_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB204_2;

$L__BB204_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB204_6;

mov.u32 %r24, 31;
mov.u32 %r25, 15;
mov.u32 %r45, %r47;

$L__BB204_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB204_5;

$L__BB204_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB204_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB204_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 4;
mov.u32 %r46, 1;
@%p8 bra $L__BB204_10;

mov.u32 %r32, 4;
div.u32 %r46, %r32, %r47;

$L__BB204_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 15;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB204_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB204_14;

mov.u32 %r43, 31;

$L__BB204_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB204_13;

$L__BB204_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB204_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB204_16:
ret;

}

.visible .entry _Z7reduce7IdLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB205_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB205_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB205_2;

$L__BB205_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB205_6;

mov.u32 %r24, 31;
mov.u32 %r25, 3;
mov.u32 %r45, %r47;

$L__BB205_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB205_5;

$L__BB205_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB205_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB205_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 2;
mov.u32 %r46, 1;
@%p8 bra $L__BB205_10;

mov.u32 %r32, 2;
div.u32 %r46, %r32, %r47;

$L__BB205_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 3;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB205_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB205_14;

mov.u32 %r43, 31;

$L__BB205_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB205_13;

$L__BB205_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB205_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB205_16:
ret;

}

.visible .entry _Z7reduce7IdLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<38>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r13, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r35, %r1, %r2;
setp.ge.u32 %p1, %r35, %r13;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB206_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB206_2:
mul.wide.u32 %rd4, %r35, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r35, %r35, %r4;
setp.lt.u32 %p2, %r35, %r13;
@%p2 bra $L__BB206_2;

$L__BB206_3:
mov.u32 %r37, WARP_SZ;
setp.lt.s32 %p3, %r37, 2;
@%p3 bra $L__BB206_6;

mov.u32 %r20, 31;
mov.u32 %r21, 1;
mov.u32 %r36, %r37;

$L__BB206_5:

	mov.b64 {%r14,%r15}, %fd21;

	shr.u32 %r18, %r36, 31;
add.s32 %r19, %r36, %r18;
shr.s32 %r9, %r19, 1;
shfl.sync.down.b32 %r17|%p4, %r15, %r9, %r20, %r21;
shfl.sync.down.b32 %r16|%p5, %r14, %r9, %r20, %r21;

	mov.b64 %fd15, {%r16,%r17};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r36, 3;
mov.u32 %r36, %r9;
@%p6 bra $L__BB206_5;

$L__BB206_6:
rem.u32 %r22, %r2, %r37;
setp.ne.s32 %p7, %r22, 0;
@%p7 bra $L__BB206_8;

div.u32 %r23, %r2, %r37;
shl.b32 %r24, %r23, 3;
mov.u32 %r25, __smem_d;
add.s32 %r26, %r25, %r24;
st.shared.f64 [%r26], %fd21;

$L__BB206_8:
bar.sync 0;
setp.ne.s32 %p8, %r2, 0;
setp.eq.s32 %p9, %r2, 0;
mov.u32 %r27, 1;
vote.sync.ballot.b32 %r10, %p9, %r27;
@%p8 bra $L__BB206_12;

ld.shared.f64 %fd21, [__smem_d];
@%p3 bra $L__BB206_12;

mov.u32 %r34, 31;

$L__BB206_11:

	mov.b64 {%r28,%r29}, %fd21;

	shr.u32 %r32, %r37, 31;
add.s32 %r33, %r37, %r32;
shr.s32 %r12, %r33, 1;
shfl.sync.down.b32 %r31|%p12, %r29, %r12, %r34, %r10;
shfl.sync.down.b32 %r30|%p13, %r28, %r12, %r34, %r10;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p14, %r37, 3;
mov.u32 %r37, %r12;
@%p14 bra $L__BB206_11;

$L__BB206_12:
@%p8 bra $L__BB206_14;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB206_14:
ret;

}

.visible .entry _Z9cg_reduceIdEvPT_S1_j(
.param .u64 _Z9cg_reduceIdEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIdEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIdEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<55>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIdEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIdEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z9cg_reduceIdEvPT_S1_j_param_2];
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mov.u32 %r17, %tid.x;
mad.lo.s32 %r1, %r15, %r16, %r17;
mul.lo.s32 %r18, %r16, %r12;
mov.u32 %r19, %ntid.z;
mul.lo.s32 %r54, %r18, %r19;
mov.u32 %r3, %ctaid.x;
mad.lo.s32 %r53, %r54, %r3, %r1;
setp.ge.u32 %p1, %r53, %r11;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB207_3;

mov.u32 %r20, %nctaid.x;
mul.lo.s32 %r5, %r54, %r20;
cvta.to.global.u64 %rd1, %rd2;

$L__BB207_2:
mul.wide.u32 %rd4, %r53, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd27, %fd27, %fd12;
add.s32 %r53, %r53, %r5;
setp.lt.u32 %p2, %r53, %r11;
@%p2 bra $L__BB207_2;

$L__BB207_3:
shl.b32 %r21, %r1, 3;
mov.u32 %r22, __smem_d;
add.s32 %r8, %r22, %r21;
st.shared.f64 [%r8], %fd27;
setp.lt.u32 %p3, %r54, 64;
@%p3 bra $L__BB207_8;

$L__BB207_5:
barrier.sync 0;
shr.u32 %r10, %r54, 1;
setp.ge.u32 %p4, %r1, %r10;
@%p4 bra $L__BB207_7;

shl.b32 %r23, %r10, 3;
add.s32 %r24, %r8, %r23;
ld.shared.f64 %fd13, [%r24];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r8], %fd27;

$L__BB207_7:
setp.gt.u32 %p5, %r54, 127;
mov.u32 %r54, %r10;
@%p5 bra $L__BB207_5;

$L__BB207_8:
barrier.sync 0;
and.b32 %r25, %r1, 2097120;
setp.ne.s32 %p6, %r25, 0;
@%p6 bra $L__BB207_10;


	mov.b64 {%r26,%r27}, %fd27;

	mov.u32 %r46, 31;
mov.u32 %r47, 16;
mov.u32 %r48, -1;
shfl.sync.bfly.b32 %r29|%p7, %r27, %r47, %r46, %r48;
shfl.sync.bfly.b32 %r28|%p8, %r26, %r47, %r46, %r48;

	mov.b64 %fd15, {%r28,%r29};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r30,%r31}, %fd16;

	mov.u32 %r49, 8;
shfl.sync.bfly.b32 %r33|%p9, %r31, %r49, %r46, %r48;
shfl.sync.bfly.b32 %r32|%p10, %r30, %r49, %r46, %r48;

	mov.b64 %fd17, {%r32,%r33};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r34,%r35}, %fd18;

	mov.u32 %r50, 4;
shfl.sync.bfly.b32 %r37|%p11, %r35, %r50, %r46, %r48;
shfl.sync.bfly.b32 %r36|%p12, %r34, %r50, %r46, %r48;

	mov.b64 %fd19, {%r36,%r37};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r38,%r39}, %fd20;

	mov.u32 %r51, 2;
shfl.sync.bfly.b32 %r41|%p13, %r39, %r51, %r46, %r48;
shfl.sync.bfly.b32 %r40|%p14, %r38, %r51, %r46, %r48;

	mov.b64 %fd21, {%r40,%r41};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r42,%r43}, %fd22;

	mov.u32 %r52, 1;
shfl.sync.bfly.b32 %r45|%p15, %r43, %r52, %r46, %r48;
shfl.sync.bfly.b32 %r44|%p16, %r42, %r52, %r46, %r48;

	mov.b64 %fd23, {%r44,%r45};

	add.f64 %fd27, %fd22, %fd23;

$L__BB207_10:
setp.ne.s32 %p17, %r1, 0;
@%p17 bra $L__BB207_12;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r3, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB207_12:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<39>;
.reg .b32 %r<160>;
.reg .f64 %fd<69>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch[288];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB208_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB208_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd63, 0d0000000000000000;
@%p2 bra $L__BB208_6;

shl.b32 %r45, %r6, 10;
add.s32 %r152, %r45, %r3;
setp.ge.u32 %p3, %r152, %r35;
@%p3 bra $L__BB208_11;

shl.b32 %r8, %r5, 10;

$L__BB208_5:
mul.wide.u32 %rd5, %r152, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd63, %fd63, %fd18;
add.s32 %r152, %r152, %r8;
setp.lt.u32 %p4, %r152, %r35;
@%p4 bra $L__BB208_5;
bra.uni $L__BB208_11;

$L__BB208_6:
shl.b32 %r46, %r6, 11;
add.s32 %r153, %r46, %r3;
setp.ge.u32 %p5, %r153, %r35;
@%p5 bra $L__BB208_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 11;

$L__BB208_8:
cvt.u64.u32 %rd7, %r153;
mul.wide.u32 %rd8, %r153, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd63, %fd63, %fd21;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB208_10;

add.s32 %r47, %r153, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd63, %fd63, %fd22;

$L__BB208_10:
add.s32 %r153, %r153, %r12;
setp.lt.u32 %p7, %r153, %r35;
@%p7 bra $L__BB208_8;

$L__BB208_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r15, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd63;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd63, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r78, %r69;
shr.u32 %r18, %r4, 9;
shl.b32 %r79, %r18, 4;
mov.u32 %r80, 65535;
shl.b32 %r19, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r154, %r68;
@%p18 bra $L__BB208_13;

add.s32 %r82, %r71, 12;
atom.shared.or.b32 %r154, [%r82], %r17;

$L__BB208_13:
shfl.sync.idx.b32 %r86|%p19, %r154, %r68, %r72, %r74;
or.b32 %r87, %r86, %r17;
and.b32 %r88, %r87, %r19;
setp.eq.s32 %p20, %r88, %r19;
@%p20 bra $L__BB208_16;
bra.uni $L__BB208_15;

$L__BB208_16:
and.b32 %r91, %r4, 16;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra $L__BB208_18;

and.b32 %r112, %r4, 15;
and.b32 %r113, %r4, -512;
shr.u32 %r114, %r113, 5;
or.b32 %r115, %r114, %r112;
shl.b32 %r116, %r115, 3;
add.s32 %r118, %r71, %r116;
ld.shared.f64 %fd34, [%r118+32];

	mov.u32 %r92, %laneid;

	and.b32 %r119, %r92, -16;
shl.b32 %r121, %r80, %r119;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r122, 4127;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r75, %r122, %r121;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r75, %r122, %r121;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r124, %r97, -16;
shl.b32 %r125, %r80, %r124;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r76, %r122, %r125;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r76, %r122, %r125;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;

	mov.u32 %r102, %laneid;

	and.b32 %r127, %r102, -16;
shl.b32 %r128, %r80, %r127;

	mov.b64 {%r103,%r104}, %fd38;

	shfl.sync.bfly.b32 %r106|%p27, %r104, %r77, %r122, %r128;
shfl.sync.bfly.b32 %r105|%p28, %r103, %r77, %r122, %r128;

	mov.b64 %fd39, {%r105,%r106};

	add.f64 %fd40, %fd38, %fd39;

	mov.u32 %r107, %laneid;

	and.b32 %r130, %r107, -16;
shl.b32 %r131, %r80, %r130;

	mov.b64 {%r108,%r109}, %fd40;

	shfl.sync.bfly.b32 %r111|%p29, %r109, %r78, %r122, %r131;
shfl.sync.bfly.b32 %r110|%p30, %r108, %r78, %r122, %r131;

	mov.b64 %fd41, {%r110,%r111};

	add.f64 %fd42, %fd40, %fd41;
st.shared.f64 [%r118+32], %fd42;

$L__BB208_18:
bar.warp.sync -1;
@%p18 bra $L__BB208_20;

not.b32 %r133, %r19;
add.s32 %r135, %r71, 12;
atom.shared.and.b32 %r136, [%r135], %r133;
bra.uni $L__BB208_20;

$L__BB208_15:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch+12];
and.b32 %r90, %r89, %r17;
setp.eq.s32 %p21, %r90, 0;
@%p21 bra $L__BB208_20;
bra.uni $L__BB208_15;

$L__BB208_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r137, %r4, 511;
setp.ne.s32 %p32, %r137, 0;
@%p32 bra $L__BB208_22;

shl.b32 %r138, %r18, 3;
mov.u32 %r139, __smem_d;
add.s32 %r140, %r139, %r138;
st.shared.f64 [%r140], %fd8;

$L__BB208_22:
barrier.sync 0;
setp.ne.s32 %p33, %r3, 0;
@%p33 bra $L__BB208_31;

mul.lo.s32 %r141, %r2, %r1;
mov.u32 %r142, %ntid.z;
mad.lo.s32 %r143, %r141, %r142, 511;
shr.u32 %r22, %r143, 9;
setp.eq.s32 %p34, %r22, 0;
mov.f64 %fd68, 0d0000000000000000;
@%p34 bra $L__BB208_30;

add.s32 %r145, %r22, -1;
and.b32 %r159, %r22, 3;
setp.lt.u32 %p35, %r145, 3;
mov.f64 %fd68, 0d0000000000000000;
mov.u32 %r157, 0;
@%p35 bra $L__BB208_27;

sub.s32 %r156, %r22, %r159;

$L__BB208_26:
shl.b32 %r147, %r157, 3;
mov.u32 %r148, __smem_d;
add.s32 %r149, %r148, %r147;
ld.shared.v2.f64 {%fd47, %fd48}, [%r149];
add.f64 %fd51, %fd68, %fd47;
add.f64 %fd52, %fd51, %fd48;
ld.shared.v2.f64 {%fd53, %fd54}, [%r149+16];
add.f64 %fd57, %fd52, %fd53;
add.f64 %fd68, %fd57, %fd54;
add.s32 %r157, %r157, 4;
add.s32 %r156, %r156, -4;
setp.ne.s32 %p36, %r156, 0;
@%p36 bra $L__BB208_26;

$L__BB208_27:
setp.eq.s32 %p37, %r159, 0;
@%p37 bra $L__BB208_30;

shl.b32 %r150, %r157, 3;
mov.u32 %r151, __smem_d;
add.s32 %r158, %r151, %r150;

$L__BB208_29:
.pragma "nounroll";
ld.shared.f64 %fd58, [%r158];
add.f64 %fd68, %fd68, %fd58;
add.s32 %r158, %r158, 8;
add.s32 %r159, %r159, -1;
setp.ne.s32 %p38, %r159, 0;
@%p38 bra $L__BB208_29;

$L__BB208_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd68;

$L__BB208_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<37>;
.reg .b32 %r<152>;
.reg .f64 %fd<67>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch[160];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB209_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB209_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd61, 0d0000000000000000;
@%p2 bra $L__BB209_6;

shl.b32 %r45, %r6, 9;
add.s32 %r144, %r45, %r3;
setp.ge.u32 %p3, %r144, %r35;
@%p3 bra $L__BB209_11;

shl.b32 %r8, %r5, 9;

$L__BB209_5:
mul.wide.u32 %rd5, %r144, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd61, %fd61, %fd18;
add.s32 %r144, %r144, %r8;
setp.lt.u32 %p4, %r144, %r35;
@%p4 bra $L__BB209_5;
bra.uni $L__BB209_11;

$L__BB209_6:
shl.b32 %r46, %r6, 10;
add.s32 %r145, %r46, %r3;
setp.ge.u32 %p5, %r145, %r35;
@%p5 bra $L__BB209_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 10;

$L__BB209_8:
cvt.u64.u32 %rd7, %r145;
mul.wide.u32 %rd8, %r145, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd61, %fd61, %fd21;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB209_10;

add.s32 %r47, %r145, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd61, %fd61, %fd22;

$L__BB209_10:
add.s32 %r145, %r145, %r12;
setp.lt.u32 %p7, %r145, %r35;
@%p7 bra $L__BB209_8;

$L__BB209_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r15, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd61;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd61, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r78, %r69;
shr.u32 %r18, %r4, 8;
shl.b32 %r79, %r18, 3;
mov.u32 %r80, 255;
shl.b32 %r19, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r146, %r68;
@%p18 bra $L__BB209_13;

add.s32 %r82, %r71, 8;
atom.shared.or.b32 %r146, [%r82], %r17;

$L__BB209_13:
shfl.sync.idx.b32 %r86|%p19, %r146, %r68, %r72, %r74;
or.b32 %r87, %r86, %r17;
and.b32 %r88, %r87, %r19;
setp.eq.s32 %p20, %r88, %r19;
@%p20 bra $L__BB209_16;
bra.uni $L__BB209_15;

$L__BB209_16:
and.b32 %r91, %r4, 24;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra $L__BB209_18;

and.b32 %r107, %r4, 7;
and.b32 %r108, %r4, -256;
shr.u32 %r109, %r108, 5;
or.b32 %r110, %r109, %r107;
shl.b32 %r111, %r110, 3;
add.s32 %r113, %r71, %r111;
ld.shared.f64 %fd34, [%r113+32];

	mov.u32 %r92, %laneid;

	and.b32 %r114, %r92, -8;
shl.b32 %r116, %r80, %r114;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r117, 6175;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r76, %r117, %r116;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r76, %r117, %r116;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r119, %r97, -8;
shl.b32 %r120, %r80, %r119;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r77, %r117, %r120;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r77, %r117, %r120;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;

	mov.u32 %r102, %laneid;

	and.b32 %r122, %r102, -8;
shl.b32 %r123, %r80, %r122;

	mov.b64 {%r103,%r104}, %fd38;

	shfl.sync.bfly.b32 %r106|%p27, %r104, %r78, %r117, %r123;
shfl.sync.bfly.b32 %r105|%p28, %r103, %r78, %r117, %r123;

	mov.b64 %fd39, {%r105,%r106};

	add.f64 %fd40, %fd38, %fd39;
st.shared.f64 [%r113+32], %fd40;

$L__BB209_18:
bar.warp.sync -1;
@%p18 bra $L__BB209_20;

not.b32 %r125, %r19;
add.s32 %r127, %r71, 8;
atom.shared.and.b32 %r128, [%r127], %r125;
bra.uni $L__BB209_20;

$L__BB209_15:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch+8];
and.b32 %r90, %r89, %r17;
setp.eq.s32 %p21, %r90, 0;
@%p21 bra $L__BB209_20;
bra.uni $L__BB209_15;

$L__BB209_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r129, %r4, 255;
setp.ne.s32 %p30, %r129, 0;
@%p30 bra $L__BB209_22;

mov.u32 %r131, __smem_d;
add.s32 %r132, %r131, %r79;
st.shared.f64 [%r132], %fd8;

$L__BB209_22:
barrier.sync 0;
setp.ne.s32 %p31, %r3, 0;
@%p31 bra $L__BB209_31;

mul.lo.s32 %r133, %r2, %r1;
mov.u32 %r134, %ntid.z;
mad.lo.s32 %r135, %r133, %r134, 255;
shr.u32 %r22, %r135, 8;
setp.eq.s32 %p32, %r22, 0;
mov.f64 %fd66, 0d0000000000000000;
@%p32 bra $L__BB209_30;

add.s32 %r137, %r22, -1;
and.b32 %r151, %r22, 3;
setp.lt.u32 %p33, %r137, 3;
mov.f64 %fd66, 0d0000000000000000;
mov.u32 %r149, 0;
@%p33 bra $L__BB209_27;

sub.s32 %r148, %r22, %r151;

$L__BB209_26:
shl.b32 %r139, %r149, 3;
mov.u32 %r140, __smem_d;
add.s32 %r141, %r140, %r139;
ld.shared.v2.f64 {%fd45, %fd46}, [%r141];
add.f64 %fd49, %fd66, %fd45;
add.f64 %fd50, %fd49, %fd46;
ld.shared.v2.f64 {%fd51, %fd52}, [%r141+16];
add.f64 %fd55, %fd50, %fd51;
add.f64 %fd66, %fd55, %fd52;
add.s32 %r149, %r149, 4;
add.s32 %r148, %r148, -4;
setp.ne.s32 %p34, %r148, 0;
@%p34 bra $L__BB209_26;

$L__BB209_27:
setp.eq.s32 %p35, %r151, 0;
@%p35 bra $L__BB209_30;

shl.b32 %r142, %r149, 3;
mov.u32 %r143, __smem_d;
add.s32 %r150, %r143, %r142;

$L__BB209_29:
.pragma "nounroll";
ld.shared.f64 %fd56, [%r150];
add.f64 %fd66, %fd66, %fd56;
add.s32 %r150, %r150, 8;
add.s32 %r151, %r151, -1;
setp.ne.s32 %p36, %r151, 0;
@%p36 bra $L__BB209_29;

$L__BB209_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd66;

$L__BB209_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<35>;
.reg .b32 %r<144>;
.reg .f64 %fd<65>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch[96];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB210_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB210_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd59, 0d0000000000000000;
@%p2 bra $L__BB210_6;

shl.b32 %r45, %r6, 8;
add.s32 %r136, %r45, %r3;
setp.ge.u32 %p3, %r136, %r35;
@%p3 bra $L__BB210_11;

shl.b32 %r8, %r5, 8;

$L__BB210_5:
mul.wide.u32 %rd5, %r136, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd59, %fd59, %fd18;
add.s32 %r136, %r136, %r8;
setp.lt.u32 %p4, %r136, %r35;
@%p4 bra $L__BB210_5;
bra.uni $L__BB210_11;

$L__BB210_6:
shl.b32 %r46, %r6, 9;
add.s32 %r137, %r46, %r3;
setp.ge.u32 %p5, %r137, %r35;
@%p5 bra $L__BB210_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 9;

$L__BB210_8:
cvt.u64.u32 %rd7, %r137;
mul.wide.u32 %rd8, %r137, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd59, %fd59, %fd21;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB210_10;

add.s32 %r47, %r137, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd59, %fd59, %fd22;

$L__BB210_10:
add.s32 %r137, %r137, %r12;
setp.lt.u32 %p7, %r137, %r35;
@%p7 bra $L__BB210_8;

$L__BB210_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r15, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd59;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd59, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r78, %r69;
shr.u32 %r18, %r4, 7;
shl.b32 %r79, %r18, 2;
mov.u32 %r80, 15;
shl.b32 %r19, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r138, %r68;
@%p18 bra $L__BB210_13;

add.s32 %r82, %r71, 4;
atom.shared.or.b32 %r138, [%r82], %r17;

$L__BB210_13:
shfl.sync.idx.b32 %r86|%p19, %r138, %r68, %r72, %r74;
or.b32 %r87, %r86, %r17;
and.b32 %r88, %r87, %r19;
setp.eq.s32 %p20, %r88, %r19;
@%p20 bra $L__BB210_16;
bra.uni $L__BB210_15;

$L__BB210_16:
and.b32 %r91, %r4, 28;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra $L__BB210_18;

and.b32 %r102, %r4, 3;
and.b32 %r103, %r4, -128;
shr.u32 %r104, %r103, 5;
or.b32 %r105, %r104, %r102;
shl.b32 %r106, %r105, 3;
add.s32 %r108, %r71, %r106;
ld.shared.f64 %fd34, [%r108+32];

	mov.u32 %r92, %laneid;

	and.b32 %r109, %r92, -4;
shl.b32 %r111, %r80, %r109;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r112, 7199;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r77, %r112, %r111;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r77, %r112, %r111;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r114, %r97, -4;
shl.b32 %r115, %r80, %r114;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r78, %r112, %r115;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r78, %r112, %r115;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;
st.shared.f64 [%r108+32], %fd38;

$L__BB210_18:
bar.warp.sync -1;
@%p18 bra $L__BB210_20;

not.b32 %r117, %r19;
add.s32 %r119, %r71, 4;
atom.shared.and.b32 %r120, [%r119], %r117;
bra.uni $L__BB210_20;

$L__BB210_15:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch+4];
and.b32 %r90, %r89, %r17;
setp.eq.s32 %p21, %r90, 0;
@%p21 bra $L__BB210_20;
bra.uni $L__BB210_15;

$L__BB210_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r121, %r4, 127;
setp.ne.s32 %p28, %r121, 0;
@%p28 bra $L__BB210_22;

shl.b32 %r122, %r18, 3;
mov.u32 %r123, __smem_d;
add.s32 %r124, %r123, %r122;
st.shared.f64 [%r124], %fd8;

$L__BB210_22:
barrier.sync 0;
setp.ne.s32 %p29, %r3, 0;
@%p29 bra $L__BB210_31;

mul.lo.s32 %r125, %r2, %r1;
mov.u32 %r126, %ntid.z;
mad.lo.s32 %r127, %r125, %r126, 127;
shr.u32 %r22, %r127, 7;
setp.eq.s32 %p30, %r22, 0;
mov.f64 %fd64, 0d0000000000000000;
@%p30 bra $L__BB210_30;

add.s32 %r129, %r22, -1;
and.b32 %r143, %r22, 3;
setp.lt.u32 %p31, %r129, 3;
mov.f64 %fd64, 0d0000000000000000;
mov.u32 %r141, 0;
@%p31 bra $L__BB210_27;

sub.s32 %r140, %r22, %r143;

$L__BB210_26:
shl.b32 %r131, %r141, 3;
mov.u32 %r132, __smem_d;
add.s32 %r133, %r132, %r131;
ld.shared.v2.f64 {%fd43, %fd44}, [%r133];
add.f64 %fd47, %fd64, %fd43;
add.f64 %fd48, %fd47, %fd44;
ld.shared.v2.f64 {%fd49, %fd50}, [%r133+16];
add.f64 %fd53, %fd48, %fd49;
add.f64 %fd64, %fd53, %fd50;
add.s32 %r141, %r141, 4;
add.s32 %r140, %r140, -4;
setp.ne.s32 %p32, %r140, 0;
@%p32 bra $L__BB210_26;

$L__BB210_27:
setp.eq.s32 %p33, %r143, 0;
@%p33 bra $L__BB210_30;

shl.b32 %r134, %r141, 3;
mov.u32 %r135, __smem_d;
add.s32 %r142, %r135, %r134;

$L__BB210_29:
.pragma "nounroll";
ld.shared.f64 %fd54, [%r142];
add.f64 %fd64, %fd64, %fd54;
add.s32 %r142, %r142, 8;
add.s32 %r143, %r143, -1;
setp.ne.s32 %p34, %r143, 0;
@%p34 bra $L__BB210_29;

$L__BB210_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd64;

$L__BB210_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<33>;
.reg .b32 %r<134>;
.reg .f64 %fd<63>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB211_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB211_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd57, 0d0000000000000000;
@%p2 bra $L__BB211_6;

shl.b32 %r45, %r6, 7;
add.s32 %r126, %r45, %r3;
setp.ge.u32 %p3, %r126, %r35;
@%p3 bra $L__BB211_11;

shl.b32 %r8, %r5, 7;

$L__BB211_5:
mul.wide.u32 %rd5, %r126, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd57, %fd57, %fd18;
add.s32 %r126, %r126, %r8;
setp.lt.u32 %p4, %r126, %r35;
@%p4 bra $L__BB211_5;
bra.uni $L__BB211_11;

$L__BB211_6:
shl.b32 %r46, %r6, 8;
add.s32 %r127, %r46, %r3;
setp.ge.u32 %p5, %r127, %r35;
@%p5 bra $L__BB211_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 8;

$L__BB211_8:
cvt.u64.u32 %rd7, %r127;
mul.wide.u32 %rd8, %r127, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd57, %fd57, %fd21;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB211_10;

add.s32 %r47, %r127, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd57, %fd57, %fd22;

$L__BB211_10:
add.s32 %r127, %r127, %r12;
setp.lt.u32 %p7, %r127, %r35;
@%p7 bra $L__BB211_8;

$L__BB211_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, 3;
mov.u32 %r72, _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r15, %r72, %r70;

	mov.b64 {%r48,%r49}, %fd57;

	mov.u32 %r73, 31;
mov.u32 %r74, 16;
mov.u32 %r75, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r74, %r73, %r75;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r74, %r73, %r75;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd57, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r76, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r76, %r73, %r75;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r76, %r73, %r75;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r77, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r77, %r73, %r75;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r77, %r73, %r75;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r78, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r78, %r73, %r75;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r78, %r73, %r75;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r79, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r79, %r73, %r75;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r79, %r73, %r75;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r79, %r69;
shr.u32 %r18, %r4, 6;
shl.b32 %r80, %r18, 1;
shl.b32 %r19, %r71, %r80;
bar.warp.sync -1;
mov.u32 %r128, %r68;
@%p18 bra $L__BB211_13;

atom.shared.or.b32 %r128, [%r72], %r17;

$L__BB211_13:
shfl.sync.idx.b32 %r85|%p19, %r128, %r68, %r73, %r75;
or.b32 %r86, %r85, %r17;
and.b32 %r87, %r86, %r19;
setp.eq.s32 %p20, %r87, %r19;
@%p20 bra $L__BB211_16;
bra.uni $L__BB211_15;

$L__BB211_16:
and.b32 %r90, %r4, 30;
setp.ne.s32 %p22, %r90, 0;
@%p22 bra $L__BB211_18;

and.b32 %r96, %r4, 1;
and.b32 %r98, %r4, -64;
shr.u32 %r99, %r98, 5;
or.b32 %r100, %r99, %r96;
shl.b32 %r101, %r100, 3;
add.s32 %r104, %r72, %r101;
ld.shared.f64 %fd34, [%r104+32];

	mov.u32 %r91, %laneid;

	and.b32 %r105, %r91, -2;
shl.b32 %r106, %r71, %r105;

	mov.b64 {%r92,%r93}, %fd34;

	mov.u32 %r107, 7711;
shfl.sync.bfly.b32 %r95|%p23, %r93, %r79, %r107, %r106;
shfl.sync.bfly.b32 %r94|%p24, %r92, %r79, %r107, %r106;

	mov.b64 %fd35, {%r94,%r95};

	add.f64 %fd36, %fd34, %fd35;
st.shared.f64 [%r104+32], %fd36;

$L__BB211_18:
bar.warp.sync -1;
@%p18 bra $L__BB211_20;

not.b32 %r108, %r19;
atom.shared.and.b32 %r110, [%r72], %r108;
bra.uni $L__BB211_20;

$L__BB211_15:
ld.volatile.shared.u32 %r88, [_ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch];
and.b32 %r89, %r88, %r17;
setp.eq.s32 %p21, %r89, 0;
@%p21 bra $L__BB211_20;
bra.uni $L__BB211_15;

$L__BB211_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r111, %r4, 63;
setp.ne.s32 %p26, %r111, 0;
@%p26 bra $L__BB211_22;

shl.b32 %r112, %r18, 3;
mov.u32 %r113, __smem_d;
add.s32 %r114, %r113, %r112;
st.shared.f64 [%r114], %fd8;

$L__BB211_22:
barrier.sync 0;
setp.ne.s32 %p27, %r3, 0;
@%p27 bra $L__BB211_31;

mul.lo.s32 %r115, %r2, %r1;
mov.u32 %r116, %ntid.z;
mad.lo.s32 %r117, %r115, %r116, 63;
shr.u32 %r22, %r117, 6;
setp.eq.s32 %p28, %r22, 0;
mov.f64 %fd62, 0d0000000000000000;
@%p28 bra $L__BB211_30;

add.s32 %r119, %r22, -1;
and.b32 %r133, %r22, 3;
setp.lt.u32 %p29, %r119, 3;
mov.f64 %fd62, 0d0000000000000000;
mov.u32 %r131, 0;
@%p29 bra $L__BB211_27;

sub.s32 %r130, %r22, %r133;

$L__BB211_26:
shl.b32 %r121, %r131, 3;
mov.u32 %r122, __smem_d;
add.s32 %r123, %r122, %r121;
ld.shared.v2.f64 {%fd41, %fd42}, [%r123];
add.f64 %fd45, %fd62, %fd41;
add.f64 %fd46, %fd45, %fd42;
ld.shared.v2.f64 {%fd47, %fd48}, [%r123+16];
add.f64 %fd51, %fd46, %fd47;
add.f64 %fd62, %fd51, %fd48;
add.s32 %r131, %r131, 4;
add.s32 %r130, %r130, -4;
setp.ne.s32 %p30, %r130, 0;
@%p30 bra $L__BB211_26;

$L__BB211_27:
setp.eq.s32 %p31, %r133, 0;
@%p31 bra $L__BB211_30;

shl.b32 %r124, %r131, 3;
mov.u32 %r125, __smem_d;
add.s32 %r132, %r125, %r124;

$L__BB211_29:
.pragma "nounroll";
ld.shared.f64 %fd52, [%r132];
add.f64 %fd62, %fd62, %fd52;
add.s32 %r132, %r132, 8;
add.s32 %r133, %r133, -1;
setp.ne.s32 %p32, %r133, 0;
@%p32 bra $L__BB211_29;

$L__BB211_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd62;

$L__BB211_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<24>;
.reg .b32 %r<88>;
.reg .f64 %fd<59>;
.reg .b64 %rd<16>;


ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r30, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r31, %tid.z;
mov.u32 %r32, %tid.y;
mad.lo.s32 %r33, %r1, %r31, %r32;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r33, %r2, %r3;
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r34, %r30, -1;
and.b32 %r35, %r34, %r30;
setp.eq.s32 %p1, %r35, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd53, 0d0000000000000000;
@%p1 bra $L__BB212_4;

shl.b32 %r36, %r6, 6;
add.s32 %r80, %r36, %r3;
setp.ge.u32 %p2, %r80, %r30;
@%p2 bra $L__BB212_9;

shl.b32 %r8, %r5, 6;

$L__BB212_3:
mul.wide.u32 %rd5, %r80, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd53, %fd53, %fd18;
add.s32 %r80, %r80, %r8;
setp.lt.u32 %p3, %r80, %r30;
@%p3 bra $L__BB212_3;
bra.uni $L__BB212_9;

$L__BB212_4:
shl.b32 %r37, %r6, 7;
add.s32 %r81, %r37, %r3;
setp.ge.u32 %p4, %r81, %r30;
@%p4 bra $L__BB212_9;

cvt.u64.u32 %rd2, %r30;
shl.b32 %r12, %r5, 7;

$L__BB212_6:
cvt.u64.u32 %rd7, %r81;
mul.wide.u32 %rd8, %r81, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd53, %fd53, %fd21;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p5, %rd10, %rd2;
@%p5 bra $L__BB212_8;

add.s32 %r38, %r81, %r2;
mul.wide.u32 %rd11, %r38, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd53, %fd53, %fd22;

$L__BB212_8:
add.s32 %r81, %r81, %r12;
setp.lt.u32 %p6, %r81, %r30;
@%p6 bra $L__BB212_6;

$L__BB212_9:

	mov.b64 {%r39,%r40}, %fd53;

	mov.u32 %r59, 31;
mov.u32 %r60, 16;
mov.u32 %r61, -1;
shfl.sync.bfly.b32 %r42|%p7, %r40, %r60, %r59, %r61;
shfl.sync.bfly.b32 %r41|%p8, %r39, %r60, %r59, %r61;

	mov.b64 %fd24, {%r41,%r42};

	add.f64 %fd25, %fd53, %fd24;

	mov.b64 {%r43,%r44}, %fd25;

	mov.u32 %r62, 8;
shfl.sync.bfly.b32 %r46|%p9, %r44, %r62, %r59, %r61;
shfl.sync.bfly.b32 %r45|%p10, %r43, %r62, %r59, %r61;

	mov.b64 %fd26, {%r45,%r46};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r47,%r48}, %fd27;

	mov.u32 %r63, 4;
shfl.sync.bfly.b32 %r50|%p11, %r48, %r63, %r59, %r61;
shfl.sync.bfly.b32 %r49|%p12, %r47, %r63, %r59, %r61;

	mov.b64 %fd28, {%r49,%r50};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r51,%r52}, %fd29;

	mov.u32 %r64, 2;
shfl.sync.bfly.b32 %r54|%p13, %r52, %r64, %r59, %r61;
shfl.sync.bfly.b32 %r53|%p14, %r51, %r64, %r59, %r61;

	mov.b64 %fd30, {%r53,%r54};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r55,%r56}, %fd31;

	mov.u32 %r65, 1;
shfl.sync.bfly.b32 %r58|%p15, %r56, %r65, %r59, %r61;
shfl.sync.bfly.b32 %r57|%p16, %r55, %r65, %r59, %r61;

	mov.b64 %fd32, {%r57,%r58};

	add.f64 %fd8, %fd31, %fd32;
and.b32 %r66, %r4, 31;
setp.ne.s32 %p17, %r66, 0;
@%p17 bra $L__BB212_11;

shr.u32 %r67, %r4, 2;
and.b32 %r68, %r67, 1073741816;
mov.u32 %r69, __smem_d;
add.s32 %r70, %r69, %r68;
st.shared.f64 [%r70], %fd8;

$L__BB212_11:
barrier.sync 0;
setp.ne.s32 %p18, %r3, 0;
@%p18 bra $L__BB212_20;

mul.lo.s32 %r71, %r2, %r1;
mov.u32 %r72, %ntid.z;
mad.lo.s32 %r73, %r71, %r72, 31;
shr.u32 %r15, %r73, 5;
setp.eq.s32 %p19, %r15, 0;
mov.f64 %fd58, 0d0000000000000000;
@%p19 bra $L__BB212_19;

add.s32 %r75, %r15, -1;
and.b32 %r87, %r15, 3;
setp.lt.u32 %p20, %r75, 3;
mov.f64 %fd58, 0d0000000000000000;
mov.u32 %r85, 0;
@%p20 bra $L__BB212_16;

sub.s32 %r84, %r15, %r87;
mov.u32 %r82, __smem_d;

$L__BB212_15:
ld.shared.v2.f64 {%fd37, %fd38}, [%r82];
add.f64 %fd41, %fd58, %fd37;
add.f64 %fd42, %fd41, %fd38;
ld.shared.v2.f64 {%fd43, %fd44}, [%r82+16];
add.f64 %fd47, %fd42, %fd43;
add.f64 %fd58, %fd47, %fd44;
add.s32 %r85, %r85, 4;
add.s32 %r82, %r82, 32;
add.s32 %r84, %r84, -4;
setp.ne.s32 %p21, %r84, 0;
@%p21 bra $L__BB212_15;

$L__BB212_16:
setp.eq.s32 %p22, %r87, 0;
@%p22 bra $L__BB212_19;

shl.b32 %r78, %r85, 3;
mov.u32 %r79, __smem_d;
add.s32 %r86, %r79, %r78;

$L__BB212_18:
.pragma "nounroll";
ld.shared.f64 %fd48, [%r86];
add.f64 %fd58, %fd58, %fd48;
add.s32 %r86, %r86, 8;
add.s32 %r87, %r87, -1;
setp.ne.s32 %p23, %r87, 0;
@%p23 bra $L__BB212_18;

$L__BB212_19:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd58;

$L__BB212_20:
ret;

}


Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_80
code version = [7,5]
producer = <unknown>
host = linux
compile_size = 64bit
compressed








.version 7.5
.target sm_80
.address_size 64















.extern .shared .align 16 .b8 __smem_d[];
.extern .shared .align 16 .b8 __smem[];

.visible .entry _Z7reduce0IiEvPT_S1_j(
.param .u64 _Z7reduce0IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IiEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce0IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r11;
mov.u32 %r22, 0;
@%p1 bra $L__BB0_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r22, [%rd5];

$L__BB0_2:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.u32 [%r7], %r22;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB0_7;

mov.u32 %r23, 1;

$L__BB0_4:
shl.b32 %r9, %r23, 1;
rem.u32 %r15, %r3, %r9;
setp.ne.s32 %p3, %r15, 0;
@%p3 bra $L__BB0_6;

shl.b32 %r16, %r23, 2;
add.s32 %r17, %r7, %r16;
ld.shared.u32 %r18, [%r7];
ld.shared.u32 %r19, [%r17];
add.s32 %r20, %r18, %r19;
st.shared.u32 [%r7], %r20;

$L__BB0_6:
barrier.sync 0;
setp.lt.u32 %p4, %r9, %r1;
mov.u32 %r23, %r9;
@%p4 bra $L__BB0_4;

$L__BB0_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB0_9;

ld.shared.u32 %r21, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r21;

$L__BB0_9:
ret;

}

.visible .entry _Z7reduce1IiEvPT_S1_j(
.param .u64 _Z7reduce1IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<28>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IiEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce1IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r11;
mov.u32 %r26, 0;
@%p1 bra $L__BB1_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r26, [%rd5];

$L__BB1_2:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.u32 [%r14], %r26;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB1_7;

mov.u32 %r27, 1;

$L__BB1_4:
shl.b32 %r8, %r27, 1;
mul.lo.s32 %r9, %r8, %r3;
setp.ge.u32 %p3, %r9, %r1;
@%p3 bra $L__BB1_6;

add.s32 %r16, %r9, %r27;
shl.b32 %r17, %r16, 2;
add.s32 %r19, %r13, %r17;
shl.b32 %r20, %r9, 2;
add.s32 %r21, %r13, %r20;
ld.shared.u32 %r22, [%r21];
ld.shared.u32 %r23, [%r19];
add.s32 %r24, %r22, %r23;
st.shared.u32 [%r21], %r24;

$L__BB1_6:
barrier.sync 0;
setp.lt.u32 %p4, %r8, %r1;
mov.u32 %r27, %r8;
@%p4 bra $L__BB1_4;

$L__BB1_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB1_9;

ld.shared.u32 %r25, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r25;

$L__BB1_9:
ret;

}

.visible .entry _Z7reduce2IiEvPT_S1_j(
.param .u64 _Z7reduce2IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce2IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce2IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce2IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce2IiEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce2IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r12;
mov.u32 %r21, 0;
@%p1 bra $L__BB2_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r21, [%rd5];

$L__BB2_2:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.u32 [%r7], %r21;
barrier.sync 0;
shr.u32 %r22, %r1, 1;
setp.eq.s32 %p2, %r22, 0;
@%p2 bra $L__BB2_7;

$L__BB2_4:
setp.ge.u32 %p3, %r3, %r22;
@%p3 bra $L__BB2_6;

shl.b32 %r15, %r22, 2;
add.s32 %r16, %r7, %r15;
ld.shared.u32 %r17, [%r7];
ld.shared.u32 %r18, [%r16];
add.s32 %r19, %r17, %r18;
st.shared.u32 [%r7], %r19;

$L__BB2_6:
barrier.sync 0;
shr.u32 %r22, %r22, 1;
setp.ne.s32 %p4, %r22, 0;
@%p4 bra $L__BB2_4;

$L__BB2_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB2_9;

ld.shared.u32 %r20, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r20;

$L__BB2_9:
ret;

}

.visible .entry _Z7reduce3IiEvPT_S1_j(
.param .u64 _Z7reduce3IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IiEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .b32 %r<33>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IiEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce3IiEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r20, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r20, %r2, %r3;
setp.ge.u32 %p1, %r4, %r18;
mov.u32 %r31, 0;
@%p1 bra $L__BB3_2;

mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r31, [%rd5];

$L__BB3_2:
add.s32 %r7, %r4, %r1;
setp.ge.u32 %p2, %r7, %r18;
@%p2 bra $L__BB3_4;

mul.wide.u32 %rd6, %r7, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r21, [%rd7];
add.s32 %r31, %r21, %r31;

$L__BB3_4:
shl.b32 %r22, %r3, 2;
mov.u32 %r23, __smem;
add.s32 %r10, %r23, %r22;
st.shared.u32 [%r10], %r31;
barrier.sync 0;
shr.u32 %r29, %r1, 1;
setp.eq.s32 %p3, %r29, 0;
@%p3 bra $L__BB3_9;

$L__BB3_6:
setp.ge.u32 %p4, %r3, %r29;
@%p4 bra $L__BB3_8;

shl.b32 %r24, %r29, 2;
add.s32 %r25, %r10, %r24;
ld.shared.u32 %r26, [%r25];
add.s32 %r31, %r26, %r31;
st.shared.u32 [%r10], %r31;

$L__BB3_8:
barrier.sync 0;
shr.u32 %r29, %r29, 1;
setp.ne.s32 %p5, %r29, 0;
@%p5 bra $L__BB3_6;

$L__BB3_9:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra $L__BB3_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r31;

$L__BB3_11:
ret;

}

.visible .entry _Z7reduce4IiLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj512EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB4_2;

ld.global.u32 %r55, [%rd1];

$L__BB4_2:
add.s32 %r22, %r4, 512;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB4_4;

ld.global.u32 %r23, [%rd1+2048];
add.s32 %r55, %r23, %r55;

$L__BB4_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB4_9;

mov.u32 %r53, %r1;

$L__BB4_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB4_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB4_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB4_6;

$L__BB4_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB4_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB4_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB4_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB4_13:
ret;

}

.visible .entry _Z7reduce4IiLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj256EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB5_2;

ld.global.u32 %r55, [%rd1];

$L__BB5_2:
add.s32 %r22, %r4, 256;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB5_4;

ld.global.u32 %r23, [%rd1+1024];
add.s32 %r55, %r23, %r55;

$L__BB5_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB5_9;

mov.u32 %r53, %r1;

$L__BB5_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB5_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB5_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB5_6;

$L__BB5_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB5_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB5_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB5_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB5_13:
ret;

}

.visible .entry _Z7reduce4IiLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj128EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB6_2;

ld.global.u32 %r55, [%rd1];

$L__BB6_2:
add.s32 %r22, %r4, 128;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB6_4;

ld.global.u32 %r23, [%rd1+512];
add.s32 %r55, %r23, %r55;

$L__BB6_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB6_9;

mov.u32 %r53, %r1;

$L__BB6_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB6_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB6_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB6_6;

$L__BB6_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB6_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB6_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB6_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB6_13:
ret;

}

.visible .entry _Z7reduce4IiLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<58>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj64EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r55, 0;
@%p1 bra $L__BB7_2;

ld.global.u32 %r55, [%rd1];

$L__BB7_2:
add.s32 %r22, %r4, 64;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB7_4;

ld.global.u32 %r23, [%rd1+256];
add.s32 %r55, %r23, %r55;

$L__BB7_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r55;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB7_9;

mov.u32 %r53, %r1;

$L__BB7_6:
shr.u32 %r12, %r53, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB7_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r55, %r28, %r55;
st.shared.u32 [%r9], %r55;

$L__BB7_8:
barrier.sync 0;
setp.gt.u32 %p5, %r53, 131;
mov.u32 %r53, %r12;
@%p5 bra $L__BB7_6;

$L__BB7_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB7_11;

ld.shared.u32 %r33, [%r9+128];
add.s32 %r34, %r33, %r55;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r55, %r50, %r48;

$L__BB7_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB7_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r55;

$L__BB7_13:
ret;

}

.visible .entry _Z7reduce4IiLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj32EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB8_2;

ld.global.u32 %r53, [%rd1];

$L__BB8_2:
add.s32 %r22, %r4, 32;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB8_4;

ld.global.u32 %r23, [%rd1+128];
add.s32 %r53, %r23, %r53;

$L__BB8_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB8_9;

mov.u32 %r51, %r1;

$L__BB8_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB8_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB8_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB8_6;

$L__BB8_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB8_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB8_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB8_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB8_13:
ret;

}

.visible .entry _Z7reduce4IiLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj16EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB9_2;

ld.global.u32 %r53, [%rd1];

$L__BB9_2:
add.s32 %r22, %r4, 16;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB9_4;

ld.global.u32 %r23, [%rd1+64];
add.s32 %r53, %r23, %r53;

$L__BB9_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB9_9;

mov.u32 %r51, %r1;

$L__BB9_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB9_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB9_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB9_6;

$L__BB9_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB9_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB9_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB9_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB9_13:
ret;

}

.visible .entry _Z7reduce4IiLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj8EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB10_2;

ld.global.u32 %r53, [%rd1];

$L__BB10_2:
add.s32 %r22, %r4, 8;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB10_4;

ld.global.u32 %r23, [%rd1+32];
add.s32 %r53, %r23, %r53;

$L__BB10_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB10_9;

mov.u32 %r51, %r1;

$L__BB10_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB10_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB10_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB10_6;

$L__BB10_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB10_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB10_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB10_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB10_13:
ret;

}

.visible .entry _Z7reduce4IiLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj4EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB11_2;

ld.global.u32 %r53, [%rd1];

$L__BB11_2:
add.s32 %r22, %r4, 4;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB11_4;

ld.global.u32 %r23, [%rd1+16];
add.s32 %r53, %r23, %r53;

$L__BB11_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB11_9;

mov.u32 %r51, %r1;

$L__BB11_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB11_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB11_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB11_6;

$L__BB11_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB11_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB11_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB11_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB11_13:
ret;

}

.visible .entry _Z7reduce4IiLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj2EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB12_2;

ld.global.u32 %r53, [%rd1];

$L__BB12_2:
add.s32 %r22, %r4, 2;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB12_4;

ld.global.u32 %r23, [%rd1+8];
add.s32 %r53, %r23, %r53;

$L__BB12_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB12_9;

mov.u32 %r51, %r1;

$L__BB12_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB12_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB12_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB12_6;

$L__BB12_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB12_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB12_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB12_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB12_13:
ret;

}

.visible .entry _Z7reduce4IiLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IiLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj1EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce4IiLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r21, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r21, %r2, %r3;
setp.ge.u32 %p1, %r4, %r19;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra $L__BB13_2;

ld.global.u32 %r53, [%rd1];

$L__BB13_2:
add.s32 %r22, %r4, 1;
setp.ge.u32 %p2, %r22, %r19;
@%p2 bra $L__BB13_4;

ld.global.u32 %r23, [%rd1+4];
add.s32 %r53, %r23, %r53;

$L__BB13_4:
shl.b32 %r24, %r3, 2;
mov.u32 %r25, __smem;
add.s32 %r9, %r25, %r24;
st.shared.u32 [%r9], %r53;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB13_9;

mov.u32 %r51, %r1;

$L__BB13_6:
shr.u32 %r12, %r51, 1;
setp.ge.u32 %p4, %r3, %r12;
@%p4 bra $L__BB13_8;

shl.b32 %r26, %r12, 2;
add.s32 %r27, %r9, %r26;
ld.shared.u32 %r28, [%r27];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r9], %r53;

$L__BB13_8:
barrier.sync 0;
setp.gt.u32 %p5, %r51, 131;
mov.u32 %r51, %r12;
@%p5 bra $L__BB13_6;

$L__BB13_9:
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mad.lo.s32 %r16, %r32, %r1, %r3;
setp.gt.u32 %p6, %r16, 31;
@%p6 bra $L__BB13_11;

mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r53, %r35, %r34, %r36;
add.s32 %r38, %r37, %r53;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
add.s32 %r53, %r48, %r46;

$L__BB13_11:
setp.ne.s32 %p12, %r16, 0;
@%p12 bra $L__BB13_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB13_13:
ret;

}

.visible .entry _Z7reduce5IiLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<57>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj512EEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce5IiLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r20, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r20, %r2;
setp.ge.u32 %p1, %r3, %r18;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r52, 0;
@%p1 bra $L__BB14_2;

ld.global.u32 %r52, [%rd1];

$L__BB14_2:
add.s32 %r21, %r3, 512;
setp.ge.u32 %p2, %r21, %r18;
@%p2 bra $L__BB14_4;

ld.global.u32 %r22, [%rd1+2048];
add.s32 %r52, %r22, %r52;

$L__BB14_4:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r8, %r24, %r23;
st.shared.u32 [%r8], %r52;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB14_6;

ld.shared.u32 %r25, [%r8+1024];
add.s32 %r52, %r25, %r52;
st.shared.u32 [%r8], %r52;

$L__BB14_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB14_8;

ld.shared.u32 %r26, [%r8+512];
add.s32 %r52, %r26, %r52;
st.shared.u32 [%r8], %r52;

$L__BB14_8:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB14_10;

ld.shared.u32 %r27, [%r8+256];
add.s32 %r52, %r27, %r52;
st.shared.u32 [%r8], %r52;

$L__BB14_10:
barrier.sync 0;
mov.u32 %r28, %ntid.y;
mov.u32 %r29, %tid.z;
mov.u32 %r30, %tid.y;
mad.lo.s32 %r31, %r28, %r29, %r30;
mov.u32 %r32, %ntid.x;
mad.lo.s32 %r15, %r31, %r32, %r2;
setp.gt.u32 %p6, %r15, 31;
@%p6 bra $L__BB14_12;

ld.shared.u32 %r33, [%r8+128];
add.s32 %r34, %r33, %r52;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p7, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p9, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p10, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p11, %r48, %r49, %r36, %r38;
add.s32 %r52, %r50, %r48;

$L__BB14_12:
setp.ne.s32 %p12, %r15, 0;
@%p12 bra $L__BB14_14;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r52;

$L__BB14_14:
ret;

}

.visible .entry _Z7reduce5IiLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<53>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj256EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce5IiLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r18, %r2;
setp.ge.u32 %p1, %r3, %r16;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r49, 0;
@%p1 bra $L__BB15_2;

ld.global.u32 %r49, [%rd1];

$L__BB15_2:
add.s32 %r19, %r3, 256;
setp.ge.u32 %p2, %r19, %r16;
@%p2 bra $L__BB15_4;

ld.global.u32 %r20, [%rd1+1024];
add.s32 %r49, %r20, %r49;

$L__BB15_4:
shl.b32 %r21, %r2, 2;
mov.u32 %r22, __smem;
add.s32 %r8, %r22, %r21;
st.shared.u32 [%r8], %r49;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB15_6;

ld.shared.u32 %r23, [%r8+512];
add.s32 %r49, %r23, %r49;
st.shared.u32 [%r8], %r49;

$L__BB15_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB15_8;

ld.shared.u32 %r24, [%r8+256];
add.s32 %r49, %r24, %r49;
st.shared.u32 [%r8], %r49;

$L__BB15_8:
barrier.sync 0;
mov.u32 %r25, %ntid.y;
mov.u32 %r26, %tid.z;
mov.u32 %r27, %tid.y;
mad.lo.s32 %r28, %r25, %r26, %r27;
mov.u32 %r29, %ntid.x;
mad.lo.s32 %r13, %r28, %r29, %r2;
setp.gt.u32 %p5, %r13, 31;
@%p5 bra $L__BB15_10;

ld.shared.u32 %r30, [%r8+128];
add.s32 %r31, %r30, %r49;
mov.u32 %r32, 2;
mov.u32 %r33, 31;
mov.u32 %r34, 16;
mov.u32 %r35, -1;
shfl.sync.down.b32 %r36|%p6, %r31, %r34, %r33, %r35;
add.s32 %r37, %r36, %r31;
mov.u32 %r38, 8;
shfl.sync.down.b32 %r39|%p7, %r37, %r38, %r33, %r35;
add.s32 %r40, %r39, %r37;
mov.u32 %r41, 4;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r33, %r35;
add.s32 %r43, %r42, %r40;
shfl.sync.down.b32 %r44|%p9, %r43, %r32, %r33, %r35;
add.s32 %r45, %r44, %r43;
mov.u32 %r46, 1;
shfl.sync.down.b32 %r47|%p10, %r45, %r46, %r33, %r35;
add.s32 %r49, %r47, %r45;

$L__BB15_10:
setp.ne.s32 %p11, %r13, 0;
@%p11 bra $L__BB15_12;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r49;

$L__BB15_12:
ret;

}

.visible .entry _Z7reduce5IiLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<49>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj128EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce5IiLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r16, %r2;
setp.ge.u32 %p1, %r3, %r14;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r46, 0;
@%p1 bra $L__BB16_2;

ld.global.u32 %r46, [%rd1];

$L__BB16_2:
add.s32 %r17, %r3, 128;
setp.ge.u32 %p2, %r17, %r14;
@%p2 bra $L__BB16_4;

ld.global.u32 %r18, [%rd1+512];
add.s32 %r46, %r18, %r46;

$L__BB16_4:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r8, %r20, %r19;
st.shared.u32 [%r8], %r46;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB16_6;

ld.shared.u32 %r21, [%r8+256];
add.s32 %r46, %r21, %r46;
st.shared.u32 [%r8], %r46;

$L__BB16_6:
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r11, %r25, %r26, %r2;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra $L__BB16_8;

ld.shared.u32 %r27, [%r8+128];
add.s32 %r28, %r27, %r46;
mov.u32 %r29, 2;
mov.u32 %r30, 31;
mov.u32 %r31, 16;
mov.u32 %r32, -1;
shfl.sync.down.b32 %r33|%p5, %r28, %r31, %r30, %r32;
add.s32 %r34, %r33, %r28;
mov.u32 %r35, 8;
shfl.sync.down.b32 %r36|%p6, %r34, %r35, %r30, %r32;
add.s32 %r37, %r36, %r34;
mov.u32 %r38, 4;
shfl.sync.down.b32 %r39|%p7, %r37, %r38, %r30, %r32;
add.s32 %r40, %r39, %r37;
shfl.sync.down.b32 %r41|%p8, %r40, %r29, %r30, %r32;
add.s32 %r42, %r41, %r40;
mov.u32 %r43, 1;
shfl.sync.down.b32 %r44|%p9, %r42, %r43, %r30, %r32;
add.s32 %r46, %r44, %r42;

$L__BB16_8:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra $L__BB16_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

$L__BB16_10:
ret;

}

.visible .entry _Z7reduce5IiLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj64EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce5IiLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r14, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r14, %r2;
setp.ge.u32 %p1, %r3, %r12;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r43, 0;
@%p1 bra $L__BB17_2;

ld.global.u32 %r43, [%rd1];

$L__BB17_2:
add.s32 %r15, %r3, 64;
setp.ge.u32 %p2, %r15, %r12;
@%p2 bra $L__BB17_4;

ld.global.u32 %r16, [%rd1+256];
add.s32 %r43, %r16, %r43;

$L__BB17_4:
shl.b32 %r17, %r2, 2;
mov.u32 %r18, __smem;
add.s32 %r8, %r18, %r17;
st.shared.u32 [%r8], %r43;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r9, %r22, %r23, %r2;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra $L__BB17_6;

ld.shared.u32 %r24, [%r8+128];
add.s32 %r25, %r24, %r43;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p4, %r25, %r28, %r27, %r29;
add.s32 %r31, %r30, %r25;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p5, %r31, %r32, %r27, %r29;
add.s32 %r34, %r33, %r31;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p6, %r34, %r35, %r27, %r29;
add.s32 %r37, %r36, %r34;
shfl.sync.down.b32 %r38|%p7, %r37, %r26, %r27, %r29;
add.s32 %r39, %r38, %r37;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p8, %r39, %r40, %r27, %r29;
add.s32 %r43, %r41, %r39;

$L__BB17_6:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra $L__BB17_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r43;

$L__BB17_8:
ret;

}

.visible .entry _Z7reduce5IiLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj32EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB18_2;

ld.global.u32 %r41, [%rd1];

$L__BB18_2:
add.s32 %r14, %r3, 32;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB18_4;

ld.global.u32 %r15, [%rd1+128];
add.s32 %r41, %r15, %r41;

$L__BB18_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB18_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB18_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB18_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB18_8:
ret;

}

.visible .entry _Z7reduce5IiLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj16EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB19_2;

ld.global.u32 %r41, [%rd1];

$L__BB19_2:
add.s32 %r14, %r3, 16;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB19_4;

ld.global.u32 %r15, [%rd1+64];
add.s32 %r41, %r15, %r41;

$L__BB19_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB19_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB19_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB19_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB19_8:
ret;

}

.visible .entry _Z7reduce5IiLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj8EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB20_2;

ld.global.u32 %r41, [%rd1];

$L__BB20_2:
add.s32 %r14, %r3, 8;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB20_4;

ld.global.u32 %r15, [%rd1+32];
add.s32 %r41, %r15, %r41;

$L__BB20_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB20_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB20_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB20_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB20_8:
ret;

}

.visible .entry _Z7reduce5IiLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj4EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB21_2;

ld.global.u32 %r41, [%rd1];

$L__BB21_2:
add.s32 %r14, %r3, 4;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB21_4;

ld.global.u32 %r15, [%rd1+16];
add.s32 %r41, %r15, %r41;

$L__BB21_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB21_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB21_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB21_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB21_8:
ret;

}

.visible .entry _Z7reduce5IiLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj2EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB22_2;

ld.global.u32 %r41, [%rd1];

$L__BB22_2:
add.s32 %r14, %r3, 2;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB22_4;

ld.global.u32 %r15, [%rd1+8];
add.s32 %r41, %r15, %r41;

$L__BB22_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB22_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB22_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB22_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB22_8:
ret;

}

.visible .entry _Z7reduce5IiLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<43>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj1EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r13, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r13, %r2;
setp.ge.u32 %p1, %r3, %r11;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r41, 0;
@%p1 bra $L__BB23_2;

ld.global.u32 %r41, [%rd1];

$L__BB23_2:
add.s32 %r14, %r3, 1;
setp.ge.u32 %p2, %r14, %r11;
@%p2 bra $L__BB23_4;

ld.global.u32 %r15, [%rd1+4];
add.s32 %r41, %r15, %r41;

$L__BB23_4:
shl.b32 %r16, %r2, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r41;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r8, %r22, %r23, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB23_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r41, %r26, %r25, %r27;
add.s32 %r29, %r28, %r41;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r41, %r39, %r37;

$L__BB23_6:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB23_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r41;

$L__BB23_8:
ret;

}

.visible .entry _Z7reduce6IiLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<14>;
.reg .b32 %r<67>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r22, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r24, %ctaid.x;
shl.b32 %r25, %r24, 10;
mov.u32 %r1, %tid.x;
add.s32 %r59, %r25, %r1;
setp.ge.u32 %p1, %r59, %r22;
mov.u32 %r60, 0;
@%p1 bra $L__BB24_5;

mov.u32 %r27, %nctaid.x;
shl.b32 %r3, %r27, 10;

$L__BB24_2:
mul.wide.u32 %rd4, %r59, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r28, [%rd5];
add.s32 %r60, %r28, %r60;
add.s32 %r7, %r59, 512;
setp.ge.u32 %p2, %r7, %r22;
@%p2 bra $L__BB24_4;

mul.wide.u32 %rd6, %r7, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r29, [%rd7];
add.s32 %r60, %r29, %r60;

$L__BB24_4:
add.s32 %r59, %r59, %r3;
setp.lt.u32 %p3, %r59, %r22;
@%p3 bra $L__BB24_2;

$L__BB24_5:
shl.b32 %r30, %r1, 2;
mov.u32 %r31, __smem;
add.s32 %r12, %r31, %r30;
st.shared.u32 [%r12], %r60;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 255;
@%p4 bra $L__BB24_7;

ld.shared.u32 %r32, [%r12+1024];
add.s32 %r60, %r32, %r60;
st.shared.u32 [%r12], %r60;

$L__BB24_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 127;
@%p5 bra $L__BB24_9;

ld.shared.u32 %r33, [%r12+512];
add.s32 %r60, %r33, %r60;
st.shared.u32 [%r12], %r60;

$L__BB24_9:
barrier.sync 0;
setp.gt.u32 %p6, %r1, 63;
@%p6 bra $L__BB24_11;

ld.shared.u32 %r34, [%r12+256];
add.s32 %r60, %r34, %r60;
st.shared.u32 [%r12], %r60;

$L__BB24_11:
barrier.sync 0;
mov.u32 %r35, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r35, %r36, %r37;
mov.u32 %r39, %ntid.x;
mad.lo.s32 %r19, %r38, %r39, %r1;
setp.gt.u32 %p7, %r19, 31;
@%p7 bra $L__BB24_13;

ld.shared.u32 %r40, [%r12+128];
add.s32 %r41, %r40, %r60;
mov.u32 %r42, 2;
mov.u32 %r43, 31;
mov.u32 %r44, 16;
mov.u32 %r45, -1;
shfl.sync.down.b32 %r46|%p8, %r41, %r44, %r43, %r45;
add.s32 %r47, %r46, %r41;
mov.u32 %r48, 8;
shfl.sync.down.b32 %r49|%p9, %r47, %r48, %r43, %r45;
add.s32 %r50, %r49, %r47;
mov.u32 %r51, 4;
shfl.sync.down.b32 %r52|%p10, %r50, %r51, %r43, %r45;
add.s32 %r53, %r52, %r50;
shfl.sync.down.b32 %r54|%p11, %r53, %r42, %r43, %r45;
add.s32 %r55, %r54, %r53;
mov.u32 %r56, 1;
shfl.sync.down.b32 %r57|%p12, %r55, %r56, %r43, %r45;
add.s32 %r60, %r57, %r55;

$L__BB24_13:
setp.ne.s32 %p13, %r19, 0;
@%p13 bra $L__BB24_15;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r24, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r60;

$L__BB24_15:
ret;

}

.visible .entry _Z7reduce6IiLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<63>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r20, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r22, %ctaid.x;
shl.b32 %r23, %r22, 9;
mov.u32 %r1, %tid.x;
add.s32 %r56, %r23, %r1;
setp.ge.u32 %p1, %r56, %r20;
mov.u32 %r57, 0;
@%p1 bra $L__BB25_5;

mov.u32 %r25, %nctaid.x;
shl.b32 %r3, %r25, 9;

$L__BB25_2:
mul.wide.u32 %rd4, %r56, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r26, [%rd5];
add.s32 %r57, %r26, %r57;
add.s32 %r7, %r56, 256;
setp.ge.u32 %p2, %r7, %r20;
@%p2 bra $L__BB25_4;

mul.wide.u32 %rd6, %r7, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r27, [%rd7];
add.s32 %r57, %r27, %r57;

$L__BB25_4:
add.s32 %r56, %r56, %r3;
setp.lt.u32 %p3, %r56, %r20;
@%p3 bra $L__BB25_2;

$L__BB25_5:
shl.b32 %r28, %r1, 2;
mov.u32 %r29, __smem;
add.s32 %r12, %r29, %r28;
st.shared.u32 [%r12], %r57;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 127;
@%p4 bra $L__BB25_7;

ld.shared.u32 %r30, [%r12+512];
add.s32 %r57, %r30, %r57;
st.shared.u32 [%r12], %r57;

$L__BB25_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 63;
@%p5 bra $L__BB25_9;

ld.shared.u32 %r31, [%r12+256];
add.s32 %r57, %r31, %r57;
st.shared.u32 [%r12], %r57;

$L__BB25_9:
barrier.sync 0;
mov.u32 %r32, %ntid.y;
mov.u32 %r33, %tid.z;
mov.u32 %r34, %tid.y;
mad.lo.s32 %r35, %r32, %r33, %r34;
mov.u32 %r36, %ntid.x;
mad.lo.s32 %r17, %r35, %r36, %r1;
setp.gt.u32 %p6, %r17, 31;
@%p6 bra $L__BB25_11;

ld.shared.u32 %r37, [%r12+128];
add.s32 %r38, %r37, %r57;
mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r43|%p7, %r38, %r41, %r40, %r42;
add.s32 %r44, %r43, %r38;
mov.u32 %r45, 8;
shfl.sync.down.b32 %r46|%p8, %r44, %r45, %r40, %r42;
add.s32 %r47, %r46, %r44;
mov.u32 %r48, 4;
shfl.sync.down.b32 %r49|%p9, %r47, %r48, %r40, %r42;
add.s32 %r50, %r49, %r47;
shfl.sync.down.b32 %r51|%p10, %r50, %r39, %r40, %r42;
add.s32 %r52, %r51, %r50;
mov.u32 %r53, 1;
shfl.sync.down.b32 %r54|%p11, %r52, %r53, %r40, %r42;
add.s32 %r57, %r54, %r52;

$L__BB25_11:
setp.ne.s32 %p12, %r17, 0;
@%p12 bra $L__BB25_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r22, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r57;

$L__BB25_13:
ret;

}

.visible .entry _Z7reduce6IiLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<58>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r21, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r52, %r21, %r2;
setp.ge.u32 %p1, %r52, %r19;
mov.u32 %r53, 0;
@%p1 bra $L__BB26_5;

mov.u32 %r23, %nctaid.x;
shl.b32 %r4, %r23, 8;

$L__BB26_2:
mul.wide.u32 %rd4, %r52, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r24, [%rd5];
add.s32 %r53, %r24, %r53;
add.s32 %r8, %r52, 128;
setp.ge.u32 %p2, %r8, %r19;
@%p2 bra $L__BB26_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r25, [%rd7];
add.s32 %r53, %r25, %r53;

$L__BB26_4:
add.s32 %r52, %r52, %r4;
setp.lt.u32 %p3, %r52, %r19;
@%p3 bra $L__BB26_2;

$L__BB26_5:
shl.b32 %r26, %r2, 2;
mov.u32 %r27, __smem;
add.s32 %r13, %r27, %r26;
st.shared.u32 [%r13], %r53;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB26_7;

ld.shared.u32 %r28, [%r13+256];
add.s32 %r53, %r28, %r53;
st.shared.u32 [%r13], %r53;

$L__BB26_7:
barrier.sync 0;
mov.u32 %r29, %ntid.y;
mov.u32 %r30, %tid.z;
mov.u32 %r31, %tid.y;
mad.lo.s32 %r32, %r29, %r30, %r31;
mov.u32 %r33, %ntid.x;
mad.lo.s32 %r16, %r32, %r33, %r2;
setp.gt.u32 %p5, %r16, 31;
@%p5 bra $L__BB26_9;

ld.shared.u32 %r34, [%r13+128];
add.s32 %r35, %r34, %r53;
mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p6, %r35, %r38, %r37, %r39;
add.s32 %r41, %r40, %r35;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p7, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p8, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p9, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p10, %r49, %r50, %r37, %r39;
add.s32 %r53, %r51, %r49;

$L__BB26_9:
setp.ne.s32 %p11, %r16, 0;
@%p11 bra $L__BB26_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r53;

$L__BB26_11:
ret;

}

.visible .entry _Z7reduce6IiLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<54>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r17, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r49, %r19, %r2;
setp.ge.u32 %p1, %r49, %r17;
mov.u32 %r50, 0;
@%p1 bra $L__BB27_5;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 7;

$L__BB27_2:
mul.wide.u32 %rd4, %r49, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r22, [%rd5];
add.s32 %r50, %r22, %r50;
add.s32 %r8, %r49, 64;
setp.ge.u32 %p2, %r8, %r17;
@%p2 bra $L__BB27_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r23, [%rd7];
add.s32 %r50, %r23, %r50;

$L__BB27_4:
add.s32 %r49, %r49, %r4;
setp.lt.u32 %p3, %r49, %r17;
@%p3 bra $L__BB27_2;

$L__BB27_5:
shl.b32 %r24, %r2, 2;
mov.u32 %r25, __smem;
add.s32 %r13, %r25, %r24;
st.shared.u32 [%r13], %r50;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r14, %r29, %r30, %r2;
setp.gt.u32 %p4, %r14, 31;
@%p4 bra $L__BB27_7;

ld.shared.u32 %r31, [%r13+128];
add.s32 %r32, %r31, %r50;
mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p5, %r32, %r35, %r34, %r36;
add.s32 %r38, %r37, %r32;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p6, %r38, %r39, %r34, %r36;
add.s32 %r41, %r40, %r38;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p7, %r41, %r42, %r34, %r36;
add.s32 %r44, %r43, %r41;
shfl.sync.down.b32 %r45|%p8, %r44, %r33, %r34, %r36;
add.s32 %r46, %r45, %r44;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p9, %r46, %r47, %r34, %r36;
add.s32 %r50, %r48, %r46;

$L__BB27_7:
setp.ne.s32 %p10, %r14, 0;
@%p10 bra $L__BB27_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r50;

$L__BB27_9:
ret;

}

.visible .entry _Z7reduce6IiLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB28_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 6;

$L__BB28_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 32;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB28_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB28_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB28_2;

$L__BB28_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB28_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB28_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB28_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB28_9:
ret;

}

.visible .entry _Z7reduce6IiLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB29_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 5;

$L__BB29_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 16;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB29_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB29_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB29_2;

$L__BB29_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB29_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB29_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB29_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB29_9:
ret;

}

.visible .entry _Z7reduce6IiLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB30_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 4;

$L__BB30_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 8;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB30_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB30_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB30_2;

$L__BB30_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB30_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB30_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB30_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB30_9:
ret;

}

.visible .entry _Z7reduce6IiLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB31_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 3;

$L__BB31_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 4;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB31_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB31_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB31_2;

$L__BB31_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB31_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB31_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB31_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB31_9:
ret;

}

.visible .entry _Z7reduce6IiLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB32_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 2;

$L__BB32_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 2;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB32_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB32_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB32_2;

$L__BB32_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB32_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB32_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB32_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB32_9:
ret;

}

.visible .entry _Z7reduce6IiLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<52>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r18, %r2;
setp.ge.u32 %p1, %r47, %r16;
mov.u32 %r48, 0;
@%p1 bra $L__BB33_5;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 1;

$L__BB33_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r48, %r21, %r48;
add.s32 %r8, %r47, 1;
setp.ge.u32 %p2, %r8, %r16;
@%p2 bra $L__BB33_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r22, [%rd7];
add.s32 %r48, %r22, %r48;

$L__BB33_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r16;
@%p3 bra $L__BB33_2;

$L__BB33_5:
shl.b32 %r23, %r2, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.u32 [%r25], %r48;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r13, %r29, %r30, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB33_7;

mov.u32 %r31, 2;
mov.u32 %r32, 31;
mov.u32 %r33, 16;
mov.u32 %r34, -1;
shfl.sync.down.b32 %r35|%p5, %r48, %r33, %r32, %r34;
add.s32 %r36, %r35, %r48;
mov.u32 %r37, 8;
shfl.sync.down.b32 %r38|%p6, %r36, %r37, %r32, %r34;
add.s32 %r39, %r38, %r36;
mov.u32 %r40, 4;
shfl.sync.down.b32 %r41|%p7, %r39, %r40, %r32, %r34;
add.s32 %r42, %r41, %r39;
shfl.sync.down.b32 %r43|%p8, %r42, %r31, %r32, %r34;
add.s32 %r44, %r43, %r42;
mov.u32 %r45, 1;
shfl.sync.down.b32 %r46|%p9, %r44, %r45, %r32, %r34;
add.s32 %r48, %r46, %r44;

$L__BB33_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB33_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r48;

$L__BB33_9:
ret;

}

.visible .entry _Z7reduce6IiLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<61>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r20, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r54, %r22, %r2;
setp.ge.u32 %p1, %r54, %r20;
mov.u32 %r56, 0;
@%p1 bra $L__BB34_3;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB34_2:
mul.wide.u32 %rd4, %r54, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r56, %r25, %r56;
add.s32 %r54, %r54, %r4;
setp.lt.u32 %p2, %r54, %r20;
@%p2 bra $L__BB34_2;

$L__BB34_3:
shl.b32 %r26, %r2, 2;
mov.u32 %r27, __smem;
add.s32 %r10, %r27, %r26;
st.shared.u32 [%r10], %r56;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB34_5;

ld.shared.u32 %r28, [%r10+1024];
add.s32 %r56, %r28, %r56;
st.shared.u32 [%r10], %r56;

$L__BB34_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB34_7;

ld.shared.u32 %r29, [%r10+512];
add.s32 %r56, %r29, %r56;
st.shared.u32 [%r10], %r56;

$L__BB34_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB34_9;

ld.shared.u32 %r30, [%r10+256];
add.s32 %r56, %r30, %r56;
st.shared.u32 [%r10], %r56;

$L__BB34_9:
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r17, %r34, %r35, %r2;
setp.gt.u32 %p6, %r17, 31;
@%p6 bra $L__BB34_11;

ld.shared.u32 %r36, [%r10+128];
add.s32 %r37, %r36, %r56;
mov.u32 %r38, 2;
mov.u32 %r39, 31;
mov.u32 %r40, 16;
mov.u32 %r41, -1;
shfl.sync.down.b32 %r42|%p7, %r37, %r40, %r39, %r41;
add.s32 %r43, %r42, %r37;
mov.u32 %r44, 8;
shfl.sync.down.b32 %r45|%p8, %r43, %r44, %r39, %r41;
add.s32 %r46, %r45, %r43;
mov.u32 %r47, 4;
shfl.sync.down.b32 %r48|%p9, %r46, %r47, %r39, %r41;
add.s32 %r49, %r48, %r46;
shfl.sync.down.b32 %r50|%p10, %r49, %r38, %r39, %r41;
add.s32 %r51, %r50, %r49;
mov.u32 %r52, 1;
shfl.sync.down.b32 %r53|%p11, %r51, %r52, %r39, %r41;
add.s32 %r56, %r53, %r51;

$L__BB34_11:
setp.ne.s32 %p12, %r17, 0;
@%p12 bra $L__BB34_13;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r56;

$L__BB34_13:
ret;

}

.visible .entry _Z7reduce6IiLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<57>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r20, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r51, %r20, %r2;
setp.ge.u32 %p1, %r51, %r18;
mov.u32 %r53, 0;
@%p1 bra $L__BB35_3;

mov.u32 %r22, %nctaid.x;
shl.b32 %r4, %r22, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB35_2:
mul.wide.u32 %rd4, %r51, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r23, [%rd5];
add.s32 %r53, %r23, %r53;
add.s32 %r51, %r51, %r4;
setp.lt.u32 %p2, %r51, %r18;
@%p2 bra $L__BB35_2;

$L__BB35_3:
shl.b32 %r24, %r2, 2;
mov.u32 %r25, __smem;
add.s32 %r10, %r25, %r24;
st.shared.u32 [%r10], %r53;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB35_5;

ld.shared.u32 %r26, [%r10+512];
add.s32 %r53, %r26, %r53;
st.shared.u32 [%r10], %r53;

$L__BB35_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB35_7;

ld.shared.u32 %r27, [%r10+256];
add.s32 %r53, %r27, %r53;
st.shared.u32 [%r10], %r53;

$L__BB35_7:
barrier.sync 0;
mov.u32 %r28, %ntid.y;
mov.u32 %r29, %tid.z;
mov.u32 %r30, %tid.y;
mad.lo.s32 %r31, %r28, %r29, %r30;
mov.u32 %r32, %ntid.x;
mad.lo.s32 %r15, %r31, %r32, %r2;
setp.gt.u32 %p5, %r15, 31;
@%p5 bra $L__BB35_9;

ld.shared.u32 %r33, [%r10+128];
add.s32 %r34, %r33, %r53;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p6, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p7, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p8, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p9, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p10, %r48, %r49, %r36, %r38;
add.s32 %r53, %r50, %r48;

$L__BB35_9:
setp.ne.s32 %p11, %r15, 0;
@%p11 bra $L__BB35_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

$L__BB35_11:
ret;

}

.visible .entry _Z7reduce6IiLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<53>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r48, %r18, %r2;
setp.ge.u32 %p1, %r48, %r16;
mov.u32 %r50, 0;
@%p1 bra $L__BB36_3;

mov.u32 %r20, %nctaid.x;
shl.b32 %r4, %r20, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB36_2:
mul.wide.u32 %rd4, %r48, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r21, [%rd5];
add.s32 %r50, %r21, %r50;
add.s32 %r48, %r48, %r4;
setp.lt.u32 %p2, %r48, %r16;
@%p2 bra $L__BB36_2;

$L__BB36_3:
shl.b32 %r22, %r2, 2;
mov.u32 %r23, __smem;
add.s32 %r10, %r23, %r22;
st.shared.u32 [%r10], %r50;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB36_5;

ld.shared.u32 %r24, [%r10+256];
add.s32 %r50, %r24, %r50;
st.shared.u32 [%r10], %r50;

$L__BB36_5:
barrier.sync 0;
mov.u32 %r25, %ntid.y;
mov.u32 %r26, %tid.z;
mov.u32 %r27, %tid.y;
mad.lo.s32 %r28, %r25, %r26, %r27;
mov.u32 %r29, %ntid.x;
mad.lo.s32 %r13, %r28, %r29, %r2;
setp.gt.u32 %p4, %r13, 31;
@%p4 bra $L__BB36_7;

ld.shared.u32 %r30, [%r10+128];
add.s32 %r31, %r30, %r50;
mov.u32 %r32, 2;
mov.u32 %r33, 31;
mov.u32 %r34, 16;
mov.u32 %r35, -1;
shfl.sync.down.b32 %r36|%p5, %r31, %r34, %r33, %r35;
add.s32 %r37, %r36, %r31;
mov.u32 %r38, 8;
shfl.sync.down.b32 %r39|%p6, %r37, %r38, %r33, %r35;
add.s32 %r40, %r39, %r37;
mov.u32 %r41, 4;
shfl.sync.down.b32 %r42|%p7, %r40, %r41, %r33, %r35;
add.s32 %r43, %r42, %r40;
shfl.sync.down.b32 %r44|%p8, %r43, %r32, %r33, %r35;
add.s32 %r45, %r44, %r43;
mov.u32 %r46, 1;
shfl.sync.down.b32 %r47|%p9, %r45, %r46, %r33, %r35;
add.s32 %r50, %r47, %r45;

$L__BB36_7:
setp.ne.s32 %p10, %r13, 0;
@%p10 bra $L__BB36_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r50;

$L__BB36_9:
ret;

}

.visible .entry _Z7reduce6IiLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<49>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r16, %r2;
setp.ge.u32 %p1, %r45, %r14;
mov.u32 %r47, 0;
@%p1 bra $L__BB37_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB37_2:
mul.wide.u32 %rd4, %r45, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r19, [%rd5];
add.s32 %r47, %r19, %r47;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p2, %r45, %r14;
@%p2 bra $L__BB37_2;

$L__BB37_3:
shl.b32 %r20, %r2, 2;
mov.u32 %r21, __smem;
add.s32 %r10, %r21, %r20;
st.shared.u32 [%r10], %r47;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r11, %r25, %r26, %r2;
setp.gt.u32 %p3, %r11, 31;
@%p3 bra $L__BB37_5;

ld.shared.u32 %r27, [%r10+128];
add.s32 %r28, %r27, %r47;
mov.u32 %r29, 2;
mov.u32 %r30, 31;
mov.u32 %r31, 16;
mov.u32 %r32, -1;
shfl.sync.down.b32 %r33|%p4, %r28, %r31, %r30, %r32;
add.s32 %r34, %r33, %r28;
mov.u32 %r35, 8;
shfl.sync.down.b32 %r36|%p5, %r34, %r35, %r30, %r32;
add.s32 %r37, %r36, %r34;
mov.u32 %r38, 4;
shfl.sync.down.b32 %r39|%p6, %r37, %r38, %r30, %r32;
add.s32 %r40, %r39, %r37;
shfl.sync.down.b32 %r41|%p7, %r40, %r29, %r30, %r32;
add.s32 %r42, %r41, %r40;
mov.u32 %r43, 1;
shfl.sync.down.b32 %r44|%p8, %r42, %r43, %r30, %r32;
add.s32 %r47, %r44, %r42;

$L__BB37_5:
setp.ne.s32 %p9, %r11, 0;
@%p9 bra $L__BB37_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r47;

$L__BB37_7:
ret;

}

.visible .entry _Z7reduce6IiLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB38_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB38_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB38_2;

$L__BB38_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB38_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB38_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB38_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB38_7:
ret;

}

.visible .entry _Z7reduce6IiLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB39_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB39_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB39_2;

$L__BB39_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB39_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB39_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB39_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB39_7:
ret;

}

.visible .entry _Z7reduce6IiLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB40_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB40_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB40_2;

$L__BB40_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB40_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB40_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB40_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB40_7:
ret;

}

.visible .entry _Z7reduce6IiLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB41_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB41_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB41_2;

$L__BB41_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB41_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB41_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB41_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB41_7:
ret;

}

.visible .entry _Z7reduce6IiLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r43, %r15, %r2;
setp.ge.u32 %p1, %r43, %r13;
mov.u32 %r45, 0;
@%p1 bra $L__BB42_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB42_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r45, %r18, %r45;
add.s32 %r43, %r43, %r4;
setp.lt.u32 %p2, %r43, %r13;
@%p2 bra $L__BB42_2;

$L__BB42_3:
shl.b32 %r19, %r2, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r10, %r25, %r26, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB42_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r45, %r29, %r28, %r30;
add.s32 %r32, %r31, %r45;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

$L__BB42_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB42_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

$L__BB42_7:
ret;

}

.visible .entry _Z7reduce6IiLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r1, %r2;
setp.ge.u32 %p1, %r41, %r13;
mov.u32 %r43, 0;
@%p1 bra $L__BB43_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB43_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r16, [%rd5];
add.s32 %r43, %r16, %r43;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p2, %r41, %r13;
@%p2 bra $L__BB43_2;

$L__BB43_3:
shl.b32 %r17, %r2, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.u32 [%r19], %r43;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r10, %r23, %r24, %r2;
setp.gt.u32 %p3, %r10, 31;
@%p3 bra $L__BB43_5;

mov.u32 %r25, 2;
mov.u32 %r26, 31;
mov.u32 %r27, 16;
mov.u32 %r28, -1;
shfl.sync.down.b32 %r29|%p4, %r43, %r27, %r26, %r28;
add.s32 %r30, %r29, %r43;
mov.u32 %r31, 8;
shfl.sync.down.b32 %r32|%p5, %r30, %r31, %r26, %r28;
add.s32 %r33, %r32, %r30;
mov.u32 %r34, 4;
shfl.sync.down.b32 %r35|%p6, %r33, %r34, %r26, %r28;
add.s32 %r36, %r35, %r33;
shfl.sync.down.b32 %r37|%p7, %r36, %r25, %r26, %r28;
add.s32 %r38, %r37, %r36;
mov.u32 %r39, 1;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r26, %r28;
add.s32 %r43, %r40, %r38;

$L__BB43_5:
setp.ne.s32 %p9, %r10, 0;
@%p9 bra $L__BB43_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r43;

$L__BB43_7:
ret;

}

.visible .entry _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB44_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 11;

$L__BB44_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 1024;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB44_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB44_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB44_2;

$L__BB44_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB44_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB44_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 1024;
mov.u32 %r44, 1;
@%p6 bra $L__BB44_9;

mov.u32 %r34, 1024;
div.u32 %r44, %r34, %r14;

$L__BB44_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB44_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB44_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB44_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB44_13:
ret;

}

.visible .entry _Z7reduce7IiLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB45_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 10;

$L__BB45_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 512;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB45_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB45_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB45_2;

$L__BB45_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB45_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB45_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 512;
mov.u32 %r44, 1;
@%p6 bra $L__BB45_9;

mov.u32 %r34, 512;
div.u32 %r44, %r34, %r14;

$L__BB45_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB45_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB45_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB45_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB45_13:
ret;

}

.visible .entry _Z7reduce7IiLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB46_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 9;

$L__BB46_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 256;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB46_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB46_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB46_2;

$L__BB46_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB46_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB46_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 256;
mov.u32 %r44, 1;
@%p6 bra $L__BB46_9;

mov.u32 %r34, 256;
div.u32 %r44, %r34, %r14;

$L__BB46_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB46_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB46_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB46_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB46_13:
ret;

}

.visible .entry _Z7reduce7IiLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB47_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 8;

$L__BB47_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 128;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB47_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB47_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB47_2;

$L__BB47_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB47_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB47_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 128;
mov.u32 %r44, 1;
@%p6 bra $L__BB47_9;

mov.u32 %r34, 128;
div.u32 %r44, %r34, %r14;

$L__BB47_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB47_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB47_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB47_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB47_13:
ret;

}

.visible .entry _Z7reduce7IiLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB48_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 7;

$L__BB48_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 64;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB48_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB48_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB48_2;

$L__BB48_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB48_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB48_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 64;
mov.u32 %r44, 1;
@%p6 bra $L__BB48_9;

mov.u32 %r34, 64;
div.u32 %r44, %r34, %r14;

$L__BB48_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB48_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB48_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB48_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB48_13:
ret;

}

.visible .entry _Z7reduce7IiLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB49_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 6;

$L__BB49_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 32;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB49_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB49_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB49_2;

$L__BB49_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB49_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB49_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 32;
mov.u32 %r44, 1;
@%p6 bra $L__BB49_9;

mov.u32 %r34, 32;
div.u32 %r44, %r34, %r14;

$L__BB49_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB49_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB49_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB49_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB49_13:
ret;

}

.visible .entry _Z7reduce7IiLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB50_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 5;

$L__BB50_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 16;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB50_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB50_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB50_2;

$L__BB50_5:
mov.u32 %r27, 65535;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB50_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB50_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 16;
mov.u32 %r44, 1;
@%p6 bra $L__BB50_9;

mov.u32 %r34, 16;
div.u32 %r44, %r34, %r14;

$L__BB50_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB50_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB50_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB50_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB50_13:
ret;

}

.visible .entry _Z7reduce7IiLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB51_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 4;

$L__BB51_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 8;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB51_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB51_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB51_2;

$L__BB51_5:
mov.u32 %r27, 255;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB51_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB51_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 8;
mov.u32 %r44, 1;
@%p6 bra $L__BB51_9;

mov.u32 %r34, 8;
div.u32 %r44, %r34, %r14;

$L__BB51_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB51_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB51_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB51_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB51_13:
ret;

}

.visible .entry _Z7reduce7IiLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB52_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 3;

$L__BB52_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 4;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB52_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB52_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB52_2;

$L__BB52_5:
mov.u32 %r27, 15;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB52_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB52_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 4;
mov.u32 %r44, 1;
@%p6 bra $L__BB52_9;

mov.u32 %r34, 4;
div.u32 %r44, %r34, %r14;

$L__BB52_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB52_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB52_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB52_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB52_13:
ret;

}

.visible .entry _Z7reduce7IiLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra $L__BB53_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 2;

$L__BB53_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 2;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra $L__BB53_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

$L__BB53_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra $L__BB53_2;

$L__BB53_5:
mov.u32 %r27, 3;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra $L__BB53_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

$L__BB53_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 2;
mov.u32 %r44, 1;
@%p6 bra $L__BB53_9;

mov.u32 %r34, 2;
div.u32 %r44, %r34, %r14;

$L__BB53_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra $L__BB53_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

$L__BB53_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra $L__BB53_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

$L__BB53_13:
ret;

}

.visible .entry _Z7reduce7IiLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r18, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r20, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r33, %r20, %r2;
setp.ge.u32 %p2, %r33, %r18;
mov.u32 %r34, 0;
@%p2 bra $L__BB54_5;

mov.u32 %r22, %nctaid.x;
shl.b32 %r4, %r22, 1;

$L__BB54_2:
mul.wide.u32 %rd4, %r33, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r23, [%rd5];
add.s32 %r34, %r23, %r34;
add.s32 %r8, %r33, 1;
setp.ge.u32 %p3, %r8, %r18;
@%p3 bra $L__BB54_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r24, [%rd7];
add.s32 %r34, %r24, %r34;

$L__BB54_4:
add.s32 %r33, %r33, %r4;
setp.lt.u32 %p4, %r33, %r18;
@%p4 bra $L__BB54_2;

$L__BB54_5:
mov.u32 %r25, 1;
redux.sync.add.s32 %r37, %r34, %r25;
mov.u32 %r14, WARP_SZ;
rem.u32 %r26, %r2, %r14;
setp.ne.s32 %p5, %r26, 0;
@%p5 bra $L__BB54_7;

div.u32 %r27, %r2, %r14;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r37;

$L__BB54_7:
bar.sync 0;
setp.ne.s32 %p6, %r2, 0;
setp.eq.s32 %p7, %r2, 0;
vote.sync.ballot.b32 %r15, %p7, %r25;
@%p6 bra $L__BB54_9;

ld.shared.u32 %r32, [__smem];
redux.sync.add.s32 %r37, %r32, %r15;

$L__BB54_9:
@%p6 bra $L__BB54_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r37;

$L__BB54_11:
ret;

}

.visible .entry _Z7reduce7IiLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB55_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB55_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB55_2;

$L__BB55_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB55_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB55_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 512;
mov.u32 %r39, 1;
@%p5 bra $L__BB55_7;

mov.u32 %r30, 512;
div.u32 %r39, %r30, %r11;

$L__BB55_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB55_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB55_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB55_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB55_11:
ret;

}

.visible .entry _Z7reduce7IiLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB56_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB56_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB56_2;

$L__BB56_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB56_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB56_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 256;
mov.u32 %r39, 1;
@%p5 bra $L__BB56_7;

mov.u32 %r30, 256;
div.u32 %r39, %r30, %r11;

$L__BB56_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB56_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB56_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB56_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB56_11:
ret;

}

.visible .entry _Z7reduce7IiLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB57_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB57_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB57_2;

$L__BB57_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB57_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB57_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 128;
mov.u32 %r39, 1;
@%p5 bra $L__BB57_7;

mov.u32 %r30, 128;
div.u32 %r39, %r30, %r11;

$L__BB57_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB57_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB57_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB57_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB57_11:
ret;

}

.visible .entry _Z7reduce7IiLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB58_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB58_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB58_2;

$L__BB58_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB58_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB58_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 64;
mov.u32 %r39, 1;
@%p5 bra $L__BB58_7;

mov.u32 %r30, 64;
div.u32 %r39, %r30, %r11;

$L__BB58_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB58_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB58_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB58_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB58_11:
ret;

}

.visible .entry _Z7reduce7IiLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB59_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB59_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB59_2;

$L__BB59_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB59_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB59_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 32;
mov.u32 %r39, 1;
@%p5 bra $L__BB59_7;

mov.u32 %r30, 32;
div.u32 %r39, %r30, %r11;

$L__BB59_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB59_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB59_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB59_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB59_11:
ret;

}

.visible .entry _Z7reduce7IiLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB60_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB60_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB60_2;

$L__BB60_3:
mov.u32 %r23, 65535;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB60_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB60_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 16;
mov.u32 %r39, 1;
@%p5 bra $L__BB60_7;

mov.u32 %r30, 16;
div.u32 %r39, %r30, %r11;

$L__BB60_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB60_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB60_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB60_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB60_11:
ret;

}

.visible .entry _Z7reduce7IiLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB61_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB61_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB61_2;

$L__BB61_3:
mov.u32 %r23, 255;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB61_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB61_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 8;
mov.u32 %r39, 1;
@%p5 bra $L__BB61_7;

mov.u32 %r30, 8;
div.u32 %r39, %r30, %r11;

$L__BB61_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB61_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB61_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB61_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB61_11:
ret;

}

.visible .entry _Z7reduce7IiLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB62_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB62_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB62_2;

$L__BB62_3:
mov.u32 %r23, 15;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB62_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB62_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 4;
mov.u32 %r39, 1;
@%p5 bra $L__BB62_7;

mov.u32 %r30, 4;
div.u32 %r39, %r30, %r11;

$L__BB62_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB62_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB62_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB62_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB62_11:
ret;

}

.visible .entry _Z7reduce7IiLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra $L__BB63_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB63_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra $L__BB63_2;

$L__BB63_3:
mov.u32 %r23, 3;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra $L__BB63_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

$L__BB63_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 2;
mov.u32 %r39, 1;
@%p5 bra $L__BB63_7;

mov.u32 %r30, 2;
div.u32 %r39, %r30, %r11;

$L__BB63_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra $L__BB63_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

$L__BB63_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra $L__BB63_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

$L__BB63_11:
ret;

}

.visible .entry _Z7reduce7IiLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<8>;
.reg .b32 %r<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r27, %r1, %r2;
setp.ge.u32 %p2, %r27, %r15;
mov.u32 %r29, 0;
@%p2 bra $L__BB64_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB64_2:
mul.wide.u32 %rd4, %r27, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r18, [%rd5];
add.s32 %r29, %r18, %r29;
add.s32 %r27, %r27, %r4;
setp.lt.u32 %p3, %r27, %r15;
@%p3 bra $L__BB64_2;

$L__BB64_3:
mov.u32 %r19, 1;
redux.sync.add.s32 %r30, %r29, %r19;
mov.u32 %r11, WARP_SZ;
rem.u32 %r20, %r2, %r11;
setp.ne.s32 %p4, %r20, 0;
@%p4 bra $L__BB64_5;

div.u32 %r21, %r2, %r11;
shl.b32 %r22, %r21, 2;
mov.u32 %r23, __smem;
add.s32 %r24, %r23, %r22;
st.shared.u32 [%r24], %r30;

$L__BB64_5:
bar.sync 0;
setp.ne.s32 %p5, %r2, 0;
setp.eq.s32 %p6, %r2, 0;
vote.sync.ballot.b32 %r12, %p6, %r19;
@%p5 bra $L__BB64_7;

ld.shared.u32 %r26, [__smem];
redux.sync.add.s32 %r30, %r26, %r12;

$L__BB64_7:
@%p5 bra $L__BB64_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r30;

$L__BB64_9:
ret;

}

.visible .entry _Z9cg_reduceIiEvPT_S1_j(
.param .u64 _Z9cg_reduceIiEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIiEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIiEvPT_S1_j_param_2
)
{
.reg .pred %p<8>;
.reg .b32 %r<49>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIiEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIiEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z9cg_reduceIiEvPT_S1_j_param_2];
mov.u32 %r21, %ntid.y;
mov.u32 %r22, %tid.z;
mov.u32 %r23, %tid.y;
mad.lo.s32 %r24, %r21, %r22, %r23;
mov.u32 %r25, %ntid.x;
mov.u32 %r26, %tid.x;
mad.lo.s32 %r1, %r24, %r25, %r26;
mul.lo.s32 %r27, %r25, %r21;
mov.u32 %r28, %ntid.z;
mul.lo.s32 %r44, %r27, %r28;
mov.u32 %r29, %ctaid.x;
mad.lo.s32 %r41, %r44, %r29, %r1;
setp.ge.u32 %p1, %r41, %r19;
mov.u32 %r46, 0;
@%p1 bra $L__BB65_3;

mov.u32 %r31, %nctaid.x;
mul.lo.s32 %r4, %r44, %r31;
cvta.to.global.u64 %rd1, %rd2;

$L__BB65_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r32, [%rd5];
add.s32 %r46, %r32, %r46;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p2, %r41, %r19;
@%p2 bra $L__BB65_2;

$L__BB65_3:
shl.b32 %r33, %r1, 2;
mov.u32 %r34, __smem;
add.s32 %r10, %r34, %r33;
st.shared.u32 [%r10], %r46;
setp.lt.u32 %p3, %r44, 64;
@%p3 bra $L__BB65_8;

$L__BB65_5:
barrier.sync 0;
shr.u32 %r13, %r44, 1;
setp.ge.u32 %p4, %r1, %r13;
@%p4 bra $L__BB65_7;

shl.b32 %r35, %r13, 2;
add.s32 %r36, %r10, %r35;
ld.shared.u32 %r37, [%r36];
add.s32 %r46, %r37, %r46;
st.shared.u32 [%r10], %r46;

$L__BB65_7:
setp.gt.u32 %p5, %r44, 127;
mov.u32 %r44, %r13;
@%p5 bra $L__BB65_5;

$L__BB65_8:
barrier.sync 0;
and.b32 %r38, %r1, 2097120;
setp.ne.s32 %p6, %r38, 0;
@%p6 bra $L__BB65_10;

mov.u32 %r39, -1;
redux.sync.add.s32 %r46, %r46, %r39;

$L__BB65_10:
setp.ne.s32 %p7, %r1, 0;
@%p7 bra $L__BB65_12;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r29, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

$L__BB65_12:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<21>;
.reg .b32 %r<156>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch[160];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB66_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB66_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB66_6;

shl.b32 %r63, %r6, 10;
add.s32 %r138, %r63, %r3;
setp.ge.u32 %p3, %r138, %r52;
mov.u32 %r143, 0;
@%p3 bra $L__BB66_11;

shl.b32 %r8, %r5, 10;

$L__BB66_5:
mul.wide.u32 %rd5, %r138, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r143, %r65, %r143;
add.s32 %r138, %r138, %r8;
setp.lt.u32 %p4, %r138, %r52;
@%p4 bra $L__BB66_5;
bra.uni $L__BB66_11;

$L__BB66_6:
shl.b32 %r67, %r6, 11;
add.s32 %r140, %r67, %r3;
setp.ge.u32 %p5, %r140, %r52;
mov.u32 %r143, 0;
@%p5 bra $L__BB66_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 11;

$L__BB66_8:
cvt.u64.u32 %rd7, %r140;
mul.wide.u32 %rd8, %r140, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r143, %r69, %r143;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB66_10;

add.s32 %r70, %r140, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r143, %r71, %r143;

$L__BB66_10:
add.s32 %r140, %r140, %r14;
setp.lt.u32 %p7, %r140, %r52;
@%p7 bra $L__BB66_8;

$L__BB66_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r143, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 9;
shl.b32 %r79, %r25, 4;
mov.u32 %r80, 65535;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r144, %r72;
@%p8 bra $L__BB66_13;

add.s32 %r82, %r75, 12;
atom.shared.or.b32 %r144, [%r82], %r24;

$L__BB66_13:
mov.u32 %r83, 31;
shfl.sync.idx.b32 %r86|%p9, %r144, %r72, %r83, %r77;
or.b32 %r87, %r86, %r24;
and.b32 %r88, %r87, %r26;
setp.eq.s32 %p10, %r88, %r26;
@%p10 bra $L__BB66_15;
bra.uni $L__BB66_14;

$L__BB66_15:
and.b32 %r91, %r4, 16;
setp.ne.s32 %p12, %r91, 0;
@%p12 bra $L__BB66_17;

and.b32 %r93, %r4, 15;
and.b32 %r94, %r4, -512;
shr.u32 %r95, %r94, 5;
or.b32 %r96, %r95, %r93;
shl.b32 %r97, %r96, 2;
add.s32 %r99, %r75, %r97;

	mov.u32 %r92, %laneid;

	and.b32 %r100, %r92, -16;
shl.b32 %r102, %r80, %r100;
ld.shared.u32 %r103, [%r99+32];
redux.sync.add.s32 %r104, %r103, %r102;
st.shared.u32 [%r99+32], %r104;

$L__BB66_17:
bar.warp.sync -1;
@%p8 bra $L__BB66_19;

not.b32 %r105, %r26;
add.s32 %r107, %r75, 12;
atom.shared.and.b32 %r108, [%r107], %r105;
bra.uni $L__BB66_19;

$L__BB66_14:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch+12];
and.b32 %r90, %r89, %r24;
setp.eq.s32 %p11, %r90, 0;
@%p11 bra $L__BB66_19;
bra.uni $L__BB66_14;

$L__BB66_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r109, %r4, 511;
setp.ne.s32 %p14, %r109, 0;
@%p14 bra $L__BB66_21;

shl.b32 %r110, %r25, 2;
mov.u32 %r111, __smem;
add.s32 %r112, %r111, %r110;
st.shared.u32 [%r112], %r29;

$L__BB66_21:
barrier.sync 0;
setp.ne.s32 %p15, %r3, 0;
@%p15 bra $L__BB66_30;

mul.lo.s32 %r114, %r2, %r1;
mov.u32 %r115, %ntid.z;
mad.lo.s32 %r116, %r114, %r115, 511;
shr.u32 %r30, %r116, 9;
setp.eq.s32 %p16, %r30, 0;
mov.u32 %r155, 0;
@%p16 bra $L__BB66_29;

add.s32 %r120, %r30, -1;
and.b32 %r154, %r30, 3;
setp.lt.u32 %p17, %r120, 3;
mov.u32 %r150, 0;
mov.u32 %r155, %r150;
@%p17 bra $L__BB66_26;

sub.s32 %r148, %r30, %r154;
mov.u32 %r145, __smem;

$L__BB66_25:
ld.shared.v4.u32 {%r124, %r125, %r126, %r127}, [%r145];
add.s32 %r132, %r124, %r155;
add.s32 %r133, %r125, %r132;
add.s32 %r134, %r126, %r133;
add.s32 %r155, %r127, %r134;
add.s32 %r150, %r150, 4;
add.s32 %r145, %r145, 16;
add.s32 %r148, %r148, -4;
setp.ne.s32 %p18, %r148, 0;
@%p18 bra $L__BB66_25;

$L__BB66_26:
setp.eq.s32 %p19, %r154, 0;
@%p19 bra $L__BB66_29;

shl.b32 %r135, %r150, 2;
mov.u32 %r136, __smem;
add.s32 %r152, %r136, %r135;

$L__BB66_28:
.pragma "nounroll";
ld.shared.u32 %r137, [%r152];
add.s32 %r155, %r137, %r155;
add.s32 %r152, %r152, 4;
add.s32 %r154, %r154, -1;
setp.ne.s32 %p20, %r154, 0;
@%p20 bra $L__BB66_28;

$L__BB66_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r155;

$L__BB66_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<24>;
.reg .b32 %r<172>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch[96];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB67_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB67_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB67_6;

shl.b32 %r63, %r6, 9;
add.s32 %r154, %r63, %r3;
setp.ge.u32 %p3, %r154, %r52;
mov.u32 %r159, 0;
@%p3 bra $L__BB67_11;

shl.b32 %r8, %r5, 9;

$L__BB67_5:
mul.wide.u32 %rd5, %r154, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r159, %r65, %r159;
add.s32 %r154, %r154, %r8;
setp.lt.u32 %p4, %r154, %r52;
@%p4 bra $L__BB67_5;
bra.uni $L__BB67_11;

$L__BB67_6:
shl.b32 %r67, %r6, 10;
add.s32 %r156, %r67, %r3;
setp.ge.u32 %p5, %r156, %r52;
mov.u32 %r159, 0;
@%p5 bra $L__BB67_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 10;

$L__BB67_8:
cvt.u64.u32 %rd7, %r156;
mul.wide.u32 %rd8, %r156, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r159, %r69, %r159;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB67_10;

add.s32 %r70, %r156, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r159, %r71, %r159;

$L__BB67_10:
add.s32 %r156, %r156, %r14;
setp.lt.u32 %p7, %r156, %r52;
@%p7 bra $L__BB67_8;

$L__BB67_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r159, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 8;
shl.b32 %r79, %r25, 3;
mov.u32 %r80, 255;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r160, %r72;
@%p8 bra $L__BB67_13;

add.s32 %r82, %r75, 8;
atom.shared.or.b32 %r160, [%r82], %r24;

$L__BB67_13:
mov.u32 %r83, 31;
shfl.sync.idx.b32 %r86|%p9, %r160, %r72, %r83, %r77;
or.b32 %r87, %r86, %r24;
and.b32 %r88, %r87, %r26;
setp.eq.s32 %p10, %r88, %r26;
@%p10 bra $L__BB67_15;
bra.uni $L__BB67_14;

$L__BB67_15:
and.b32 %r91, %r4, 24;
setp.ne.s32 %p12, %r91, 0;
@%p12 bra $L__BB67_17;

and.b32 %r95, %r4, 7;
and.b32 %r96, %r4, -256;
shr.u32 %r97, %r96, 5;
or.b32 %r98, %r97, %r95;
shl.b32 %r99, %r98, 2;
mov.u32 %r100, 2;
add.s32 %r102, %r75, %r99;
ld.shared.u32 %r103, [%r102+32];

	mov.u32 %r92, %laneid;

	and.b32 %r104, %r92, -8;
shl.b32 %r106, %r80, %r104;
mov.u32 %r107, 6175;
mov.u32 %r108, 4;
shfl.sync.bfly.b32 %r109|%p13, %r103, %r108, %r107, %r106;
add.s32 %r110, %r109, %r103;

	mov.u32 %r93, %laneid;

	and.b32 %r111, %r93, -8;
shl.b32 %r112, %r80, %r111;
shfl.sync.bfly.b32 %r113|%p14, %r110, %r100, %r107, %r112;
add.s32 %r114, %r113, %r110;

	mov.u32 %r94, %laneid;

	and.b32 %r115, %r94, -8;
shl.b32 %r116, %r80, %r115;
shfl.sync.bfly.b32 %r118|%p15, %r114, %r76, %r107, %r116;
add.s32 %r119, %r118, %r114;
st.shared.u32 [%r102+32], %r119;

$L__BB67_17:
bar.warp.sync -1;
@%p8 bra $L__BB67_19;

not.b32 %r120, %r26;
add.s32 %r122, %r75, 8;
atom.shared.and.b32 %r123, [%r122], %r120;
bra.uni $L__BB67_19;

$L__BB67_14:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch+8];
and.b32 %r90, %r89, %r24;
setp.eq.s32 %p11, %r90, 0;
@%p11 bra $L__BB67_19;
bra.uni $L__BB67_14;

$L__BB67_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r124, %r4, 255;
setp.ne.s32 %p17, %r124, 0;
@%p17 bra $L__BB67_21;

shl.b32 %r125, %r25, 2;
mov.u32 %r126, __smem;
add.s32 %r127, %r126, %r125;
st.shared.u32 [%r127], %r29;

$L__BB67_21:
barrier.sync 0;
setp.ne.s32 %p18, %r3, 0;
@%p18 bra $L__BB67_30;

mul.lo.s32 %r129, %r2, %r1;
mov.u32 %r130, %ntid.z;
mad.lo.s32 %r131, %r129, %r130, 255;
shr.u32 %r30, %r131, 8;
setp.eq.s32 %p19, %r30, 0;
mov.u32 %r171, 0;
@%p19 bra $L__BB67_29;

add.s32 %r135, %r30, -1;
and.b32 %r170, %r30, 3;
setp.lt.u32 %p20, %r135, 3;
mov.u32 %r166, 0;
mov.u32 %r171, %r166;
@%p20 bra $L__BB67_26;

sub.s32 %r164, %r30, %r170;
mov.u32 %r161, __smem;

$L__BB67_25:
ld.shared.v4.u32 {%r139, %r140, %r141, %r142}, [%r161];
add.s32 %r147, %r139, %r171;
add.s32 %r148, %r140, %r147;
add.s32 %r149, %r141, %r148;
add.s32 %r171, %r142, %r149;
add.s32 %r166, %r166, 4;
add.s32 %r161, %r161, 16;
add.s32 %r164, %r164, -4;
setp.ne.s32 %p21, %r164, 0;
@%p21 bra $L__BB67_25;

$L__BB67_26:
setp.eq.s32 %p22, %r170, 0;
@%p22 bra $L__BB67_29;

shl.b32 %r150, %r166, 2;
mov.u32 %r151, __smem;
add.s32 %r168, %r151, %r150;

$L__BB67_28:
.pragma "nounroll";
ld.shared.u32 %r152, [%r168];
add.s32 %r171, %r152, %r171;
add.s32 %r168, %r168, 4;
add.s32 %r170, %r170, -1;
setp.ne.s32 %p23, %r170, 0;
@%p23 bra $L__BB67_28;

$L__BB67_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r171;

$L__BB67_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<23>;
.reg .b32 %r<165>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB68_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB68_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB68_6;

shl.b32 %r63, %r6, 8;
add.s32 %r147, %r63, %r3;
setp.ge.u32 %p3, %r147, %r52;
mov.u32 %r152, 0;
@%p3 bra $L__BB68_11;

shl.b32 %r8, %r5, 8;

$L__BB68_5:
mul.wide.u32 %rd5, %r147, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r152, %r65, %r152;
add.s32 %r147, %r147, %r8;
setp.lt.u32 %p4, %r147, %r52;
@%p4 bra $L__BB68_5;
bra.uni $L__BB68_11;

$L__BB68_6:
shl.b32 %r67, %r6, 9;
add.s32 %r149, %r67, %r3;
setp.ge.u32 %p5, %r149, %r52;
mov.u32 %r152, 0;
@%p5 bra $L__BB68_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 9;

$L__BB68_8:
cvt.u64.u32 %rd7, %r149;
mul.wide.u32 %rd8, %r149, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r152, %r69, %r152;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB68_10;

add.s32 %r70, %r149, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r152, %r71, %r152;

$L__BB68_10:
add.s32 %r149, %r149, %r14;
setp.lt.u32 %p7, %r149, %r52;
@%p7 bra $L__BB68_8;

$L__BB68_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r152, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 7;
shl.b32 %r79, %r25, 2;
mov.u32 %r80, 15;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r153, %r72;
@%p8 bra $L__BB68_13;

add.s32 %r82, %r75, 4;
atom.shared.or.b32 %r153, [%r82], %r24;

$L__BB68_13:
mov.u32 %r83, 31;
shfl.sync.idx.b32 %r86|%p9, %r153, %r72, %r83, %r77;
or.b32 %r87, %r86, %r24;
and.b32 %r88, %r87, %r26;
setp.eq.s32 %p10, %r88, %r26;
@%p10 bra $L__BB68_15;
bra.uni $L__BB68_14;

$L__BB68_15:
and.b32 %r91, %r4, 28;
setp.ne.s32 %p12, %r91, 0;
@%p12 bra $L__BB68_17;

and.b32 %r94, %r4, 3;
and.b32 %r95, %r4, -128;
shr.u32 %r96, %r95, 5;
or.b32 %r97, %r96, %r94;
shl.b32 %r98, %r97, 2;
mov.u32 %r99, 2;
add.s32 %r101, %r75, %r98;
ld.shared.u32 %r102, [%r101+32];

	mov.u32 %r92, %laneid;

	and.b32 %r103, %r92, -4;
shl.b32 %r105, %r80, %r103;
mov.u32 %r106, 7199;
shfl.sync.bfly.b32 %r107|%p13, %r102, %r99, %r106, %r105;
add.s32 %r108, %r107, %r102;

	mov.u32 %r93, %laneid;

	and.b32 %r109, %r93, -4;
shl.b32 %r110, %r80, %r109;
shfl.sync.bfly.b32 %r112|%p14, %r108, %r76, %r106, %r110;
add.s32 %r113, %r112, %r108;
st.shared.u32 [%r101+32], %r113;

$L__BB68_17:
bar.warp.sync -1;
@%p8 bra $L__BB68_19;

not.b32 %r114, %r26;
add.s32 %r116, %r75, 4;
atom.shared.and.b32 %r117, [%r116], %r114;
bra.uni $L__BB68_19;

$L__BB68_14:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch+4];
and.b32 %r90, %r89, %r24;
setp.eq.s32 %p11, %r90, 0;
@%p11 bra $L__BB68_19;
bra.uni $L__BB68_14;

$L__BB68_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r118, %r4, 127;
setp.ne.s32 %p16, %r118, 0;
@%p16 bra $L__BB68_21;

mov.u32 %r120, __smem;
add.s32 %r121, %r120, %r79;
st.shared.u32 [%r121], %r29;

$L__BB68_21:
barrier.sync 0;
setp.ne.s32 %p17, %r3, 0;
@%p17 bra $L__BB68_30;

mul.lo.s32 %r123, %r2, %r1;
mov.u32 %r124, %ntid.z;
mad.lo.s32 %r125, %r123, %r124, 127;
shr.u32 %r30, %r125, 7;
setp.eq.s32 %p18, %r30, 0;
mov.u32 %r164, 0;
@%p18 bra $L__BB68_29;

add.s32 %r129, %r30, -1;
and.b32 %r163, %r30, 3;
setp.lt.u32 %p19, %r129, 3;
mov.u32 %r159, 0;
mov.u32 %r164, %r159;
@%p19 bra $L__BB68_26;

sub.s32 %r157, %r30, %r163;
mov.u32 %r154, __smem;

$L__BB68_25:
ld.shared.v4.u32 {%r133, %r134, %r135, %r136}, [%r154];
add.s32 %r141, %r133, %r164;
add.s32 %r142, %r134, %r141;
add.s32 %r143, %r135, %r142;
add.s32 %r164, %r136, %r143;
add.s32 %r159, %r159, 4;
add.s32 %r154, %r154, 16;
add.s32 %r157, %r157, -4;
setp.ne.s32 %p20, %r157, 0;
@%p20 bra $L__BB68_25;

$L__BB68_26:
setp.eq.s32 %p21, %r163, 0;
@%p21 bra $L__BB68_29;

shl.b32 %r144, %r159, 2;
mov.u32 %r145, __smem;
add.s32 %r161, %r145, %r144;

$L__BB68_28:
.pragma "nounroll";
ld.shared.u32 %r146, [%r161];
add.s32 %r164, %r146, %r164;
add.s32 %r161, %r161, 4;
add.s32 %r163, %r163, -1;
setp.ne.s32 %p22, %r163, 0;
@%p22 bra $L__BB68_28;

$L__BB68_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r164;

$L__BB68_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<22>;
.reg .b32 %r<157>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch[48];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r52, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r1, %r53, %r54;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r55, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB69_2;

shl.b32 %r56, %r4, 2;
mov.u32 %r57, _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r58, %r57, %r56;
mov.u32 %r59, 0;
st.shared.u32 [%r58], %r59;

$L__BB69_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r60, %r52, -1;
and.b32 %r61, %r60, %r52;
setp.eq.s32 %p2, %r61, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB69_6;

shl.b32 %r63, %r6, 7;
add.s32 %r139, %r63, %r3;
setp.ge.u32 %p3, %r139, %r52;
mov.u32 %r144, 0;
@%p3 bra $L__BB69_11;

shl.b32 %r8, %r5, 7;

$L__BB69_5:
mul.wide.u32 %rd5, %r139, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r65, [%rd6];
add.s32 %r144, %r65, %r144;
add.s32 %r139, %r139, %r8;
setp.lt.u32 %p4, %r139, %r52;
@%p4 bra $L__BB69_5;
bra.uni $L__BB69_11;

$L__BB69_6:
shl.b32 %r67, %r6, 8;
add.s32 %r141, %r67, %r3;
setp.ge.u32 %p5, %r141, %r52;
mov.u32 %r144, 0;
@%p5 bra $L__BB69_11;

cvt.u64.u32 %rd2, %r52;
shl.b32 %r14, %r5, 8;

$L__BB69_8:
cvt.u64.u32 %rd7, %r141;
mul.wide.u32 %rd8, %r141, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r69, [%rd9];
add.s32 %r144, %r69, %r144;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB69_10;

add.s32 %r70, %r141, %r2;
mul.wide.u32 %rd11, %r70, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r71, [%rd12];
add.s32 %r144, %r71, %r144;

$L__BB69_10:
add.s32 %r141, %r141, %r14;
setp.lt.u32 %p7, %r141, %r52;
@%p7 bra $L__BB69_8;

$L__BB69_11:
shr.u32 %r73, %r4, 5;
shl.b32 %r74, %r73, 2;
mov.u32 %r75, _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r22, %r75, %r74;
mov.u32 %r76, 1;
mov.u32 %r77, -1;
redux.sync.add.s32 %r78, %r144, %r77;
mov.u32 %r72, 0;
st.shared.u32 [%r22+32], %r78;
and.b32 %r23, %r4, 31;
setp.ne.s32 %p8, %r23, 0;
shl.b32 %r24, %r76, %r73;
shr.u32 %r25, %r4, 6;
shl.b32 %r79, %r25, 1;
mov.u32 %r80, 3;
shl.b32 %r26, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r145, %r72;
@%p8 bra $L__BB69_13;

atom.shared.or.b32 %r145, [%r75], %r24;

$L__BB69_13:
mov.u32 %r82, 31;
shfl.sync.idx.b32 %r85|%p9, %r145, %r72, %r82, %r77;
or.b32 %r86, %r85, %r24;
and.b32 %r87, %r86, %r26;
setp.eq.s32 %p10, %r87, %r26;
@%p10 bra $L__BB69_15;
bra.uni $L__BB69_14;

$L__BB69_15:
and.b32 %r90, %r4, 30;
setp.ne.s32 %p12, %r90, 0;
@%p12 bra $L__BB69_17;

and.b32 %r92, %r4, 1;
and.b32 %r94, %r4, -64;
shr.u32 %r95, %r94, 5;
or.b32 %r96, %r95, %r92;
shl.b32 %r97, %r96, 2;
add.s32 %r99, %r75, %r97;
ld.shared.u32 %r100, [%r99+32];

	mov.u32 %r91, %laneid;

	and.b32 %r101, %r91, -2;
shl.b32 %r103, %r80, %r101;
mov.u32 %r104, 7711;
shfl.sync.bfly.b32 %r105|%p13, %r100, %r76, %r104, %r103;
add.s32 %r106, %r105, %r100;
st.shared.u32 [%r99+32], %r106;

$L__BB69_17:
bar.warp.sync -1;
@%p8 bra $L__BB69_19;

not.b32 %r107, %r26;
atom.shared.and.b32 %r109, [%r75], %r107;
bra.uni $L__BB69_19;

$L__BB69_14:
ld.volatile.shared.u32 %r88, [_ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch];
and.b32 %r89, %r88, %r24;
setp.eq.s32 %p11, %r89, 0;
@%p11 bra $L__BB69_19;
bra.uni $L__BB69_14;

$L__BB69_19:
ld.shared.u32 %r29, [%r22+32];
bar.warp.sync -1;
and.b32 %r110, %r4, 63;
setp.ne.s32 %p15, %r110, 0;
@%p15 bra $L__BB69_21;

shl.b32 %r111, %r25, 2;
mov.u32 %r112, __smem;
add.s32 %r113, %r112, %r111;
st.shared.u32 [%r113], %r29;

$L__BB69_21:
barrier.sync 0;
setp.ne.s32 %p16, %r3, 0;
@%p16 bra $L__BB69_30;

mul.lo.s32 %r115, %r2, %r1;
mov.u32 %r116, %ntid.z;
mad.lo.s32 %r117, %r115, %r116, 63;
shr.u32 %r30, %r117, 6;
setp.eq.s32 %p17, %r30, 0;
mov.u32 %r156, 0;
@%p17 bra $L__BB69_29;

add.s32 %r121, %r30, -1;
and.b32 %r155, %r30, 3;
setp.lt.u32 %p18, %r121, 3;
mov.u32 %r151, 0;
mov.u32 %r156, %r151;
@%p18 bra $L__BB69_26;

sub.s32 %r149, %r30, %r155;
mov.u32 %r146, __smem;

$L__BB69_25:
ld.shared.v4.u32 {%r125, %r126, %r127, %r128}, [%r146];
add.s32 %r133, %r125, %r156;
add.s32 %r134, %r126, %r133;
add.s32 %r135, %r127, %r134;
add.s32 %r156, %r128, %r135;
add.s32 %r151, %r151, 4;
add.s32 %r146, %r146, 16;
add.s32 %r149, %r149, -4;
setp.ne.s32 %p19, %r149, 0;
@%p19 bra $L__BB69_25;

$L__BB69_26:
setp.eq.s32 %p20, %r155, 0;
@%p20 bra $L__BB69_29;

shl.b32 %r136, %r151, 2;
mov.u32 %r137, __smem;
add.s32 %r153, %r137, %r136;

$L__BB69_28:
.pragma "nounroll";
ld.shared.u32 %r138, [%r153];
add.s32 %r156, %r138, %r156;
add.s32 %r153, %r153, 4;
add.s32 %r155, %r155, -1;
setp.ne.s32 %p21, %r155, 0;
@%p21 bra $L__BB69_28;

$L__BB69_29:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r156;

$L__BB69_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<113>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_jE7scratch[40];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r45, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r46, %tid.z;
mov.u32 %r47, %tid.y;
mad.lo.s32 %r48, %r1, %r46, %r47;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r48, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB70_2;

shl.b32 %r49, %r4, 2;
mov.u32 %r50, _ZZ20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_jE7scratch;
add.s32 %r51, %r50, %r49;
mov.u32 %r52, 0;
st.shared.u32 [%r51], %r52;

$L__BB70_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r53, %r45, -1;
and.b32 %r54, %r53, %r45;
setp.eq.s32 %p2, %r54, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra $L__BB70_6;

shl.b32 %r56, %r6, 6;
add.s32 %r96, %r56, %r3;
setp.ge.u32 %p3, %r96, %r45;
mov.u32 %r101, 0;
@%p3 bra $L__BB70_11;

shl.b32 %r8, %r5, 6;

$L__BB70_5:
mul.wide.u32 %rd5, %r96, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r58, [%rd6];
add.s32 %r101, %r58, %r101;
add.s32 %r96, %r96, %r8;
setp.lt.u32 %p4, %r96, %r45;
@%p4 bra $L__BB70_5;
bra.uni $L__BB70_11;

$L__BB70_6:
shl.b32 %r60, %r6, 7;
add.s32 %r98, %r60, %r3;
setp.ge.u32 %p5, %r98, %r45;
mov.u32 %r101, 0;
@%p5 bra $L__BB70_11;

cvt.u64.u32 %rd2, %r45;
shl.b32 %r14, %r5, 7;

$L__BB70_8:
cvt.u64.u32 %rd7, %r98;
mul.wide.u32 %rd8, %r98, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.u32 %r62, [%rd9];
add.s32 %r101, %r62, %r101;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB70_10;

add.s32 %r63, %r98, %r2;
mul.wide.u32 %rd11, %r63, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.u32 %r64, [%rd12];
add.s32 %r101, %r64, %r101;

$L__BB70_10:
add.s32 %r98, %r98, %r14;
setp.lt.u32 %p7, %r98, %r45;
@%p7 bra $L__BB70_8;

$L__BB70_11:
mov.u32 %r65, -1;
redux.sync.add.s32 %r22, %r101, %r65;
and.b32 %r66, %r4, 31;
setp.ne.s32 %p8, %r66, 0;
@%p8 bra $L__BB70_13;

shr.u32 %r67, %r4, 3;
and.b32 %r68, %r67, 536870908;
mov.u32 %r69, __smem;
add.s32 %r70, %r69, %r68;
st.shared.u32 [%r70], %r22;

$L__BB70_13:
barrier.sync 0;
setp.ne.s32 %p9, %r3, 0;
@%p9 bra $L__BB70_22;

mul.lo.s32 %r72, %r2, %r1;
mov.u32 %r73, %ntid.z;
mad.lo.s32 %r74, %r72, %r73, 31;
shr.u32 %r23, %r74, 5;
setp.eq.s32 %p10, %r23, 0;
mov.u32 %r112, 0;
@%p10 bra $L__BB70_21;

add.s32 %r78, %r23, -1;
and.b32 %r111, %r23, 3;
setp.lt.u32 %p11, %r78, 3;
mov.u32 %r107, 0;
mov.u32 %r112, %r107;
@%p11 bra $L__BB70_18;

sub.s32 %r105, %r23, %r111;
mov.u32 %r102, __smem;

$L__BB70_17:
ld.shared.v4.u32 {%r82, %r83, %r84, %r85}, [%r102];
add.s32 %r90, %r82, %r112;
add.s32 %r91, %r83, %r90;
add.s32 %r92, %r84, %r91;
add.s32 %r112, %r85, %r92;
add.s32 %r107, %r107, 4;
add.s32 %r102, %r102, 16;
add.s32 %r105, %r105, -4;
setp.ne.s32 %p12, %r105, 0;
@%p12 bra $L__BB70_17;

$L__BB70_18:
setp.eq.s32 %p13, %r111, 0;
@%p13 bra $L__BB70_21;

shl.b32 %r93, %r107, 2;
mov.u32 %r94, __smem;
add.s32 %r109, %r94, %r93;

$L__BB70_20:
.pragma "nounroll";
ld.shared.u32 %r95, [%r109];
add.s32 %r112, %r95, %r112;
add.s32 %r109, %r109, 4;
add.s32 %r111, %r111, -1;
setp.ne.s32 %p14, %r111, 0;
@%p14 bra $L__BB70_20;

$L__BB70_21:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.u32 [%rd15], %r112;

$L__BB70_22:
ret;

}

.visible .entry _Z7reduce0IfEvPT_S1_j(
.param .u64 _Z7reduce0IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<16>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IfEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce0IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f32 %f8, 0f00000000;
@%p1 bra $L__BB71_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

$L__BB71_2:
shl.b32 %r9, %r3, 2;
mov.u32 %r10, __smem;
add.s32 %r5, %r10, %r9;
st.shared.f32 [%r5], %f8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB71_7;

mov.u32 %r15, 1;

$L__BB71_4:
shl.b32 %r7, %r15, 1;
rem.u32 %r12, %r3, %r7;
setp.ne.s32 %p3, %r12, 0;
@%p3 bra $L__BB71_6;

shl.b32 %r13, %r15, 2;
add.s32 %r14, %r5, %r13;
ld.shared.f32 %f4, [%r5];
ld.shared.f32 %f5, [%r14];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r5], %f6;

$L__BB71_6:
barrier.sync 0;
setp.lt.u32 %p4, %r7, %r1;
mov.u32 %r15, %r7;
@%p4 bra $L__BB71_4;

$L__BB71_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB71_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

$L__BB71_9:
ret;

}

.visible .entry _Z7reduce1IfEvPT_S1_j(
.param .u64 _Z7reduce1IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<20>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IfEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce1IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f32 %f8, 0f00000000;
@%p1 bra $L__BB72_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

$L__BB72_2:
shl.b32 %r9, %r3, 2;
mov.u32 %r10, __smem;
add.s32 %r11, %r10, %r9;
st.shared.f32 [%r11], %f8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB72_7;

mov.u32 %r19, 1;

$L__BB72_4:
shl.b32 %r6, %r19, 1;
mul.lo.s32 %r7, %r6, %r3;
setp.ge.u32 %p3, %r7, %r1;
@%p3 bra $L__BB72_6;

add.s32 %r13, %r7, %r19;
shl.b32 %r14, %r13, 2;
add.s32 %r16, %r10, %r14;
shl.b32 %r17, %r7, 2;
add.s32 %r18, %r10, %r17;
ld.shared.f32 %f4, [%r18];
ld.shared.f32 %f5, [%r16];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r18], %f6;

$L__BB72_6:
barrier.sync 0;
setp.lt.u32 %p4, %r6, %r1;
mov.u32 %r19, %r6;
@%p4 bra $L__BB72_4;

$L__BB72_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB72_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

$L__BB72_9:
ret;

}

.visible .entry _Z7reduce2IfEvPT_S1_j(
.param .u64 _Z7reduce2IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce2IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce2IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<15>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce2IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce2IfEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce2IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r9;
mov.f32 %f8, 0f00000000;
@%p1 bra $L__BB73_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

$L__BB73_2:
shl.b32 %r10, %r3, 2;
mov.u32 %r11, __smem;
add.s32 %r5, %r11, %r10;
st.shared.f32 [%r5], %f8;
barrier.sync 0;
shr.u32 %r14, %r1, 1;
setp.eq.s32 %p2, %r14, 0;
@%p2 bra $L__BB73_7;

$L__BB73_4:
setp.ge.u32 %p3, %r3, %r14;
@%p3 bra $L__BB73_6;

shl.b32 %r12, %r14, 2;
add.s32 %r13, %r5, %r12;
ld.shared.f32 %f4, [%r5];
ld.shared.f32 %f5, [%r13];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r5], %f6;

$L__BB73_6:
barrier.sync 0;
shr.u32 %r14, %r14, 1;
setp.ne.s32 %p4, %r14, 0;
@%p4 bra $L__BB73_4;

$L__BB73_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB73_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

$L__BB73_9:
ret;

}

.visible .entry _Z7reduce3IfEvPT_S1_j(
.param .u64 _Z7reduce3IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IfEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .f32 %f<17>;
.reg .b32 %r<17>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IfEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce3IfEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
mov.f32 %f15, 0f00000000;
@%p1 bra $L__BB74_2;

mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f15, [%rd5];

$L__BB74_2:
add.s32 %r5, %r4, %r1;
setp.ge.u32 %p2, %r5, %r10;
@%p2 bra $L__BB74_4;

mul.wide.u32 %rd6, %r5, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f10, [%rd7];
add.f32 %f15, %f15, %f10;

$L__BB74_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r6, %r13, %r12;
st.shared.f32 [%r6], %f15;
barrier.sync 0;
shr.u32 %r16, %r1, 1;
setp.eq.s32 %p3, %r16, 0;
@%p3 bra $L__BB74_9;

$L__BB74_6:
setp.ge.u32 %p4, %r3, %r16;
@%p4 bra $L__BB74_8;

shl.b32 %r14, %r16, 2;
add.s32 %r15, %r6, %r14;
ld.shared.f32 %f11, [%r15];
add.f32 %f15, %f15, %f11;
st.shared.f32 [%r6], %f15;

$L__BB74_8:
barrier.sync 0;
shr.u32 %r16, %r16, 1;
setp.ne.s32 %p5, %r16, 0;
@%p5 bra $L__BB74_6;

$L__BB74_9:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra $L__BB74_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f15;

$L__BB74_11:
ret;

}

.visible .entry _Z7reduce4IfLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj512EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB75_2;

ld.global.f32 %f28, [%rd1];

$L__BB75_2:
add.s32 %r11, %r4, 512;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB75_4;

ld.global.f32 %f12, [%rd1+2048];
add.f32 %f28, %f28, %f12;

$L__BB75_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB75_9;

mov.u32 %r37, %r1;

$L__BB75_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB75_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB75_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB75_6;

$L__BB75_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB75_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB75_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB75_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB75_13:
ret;

}

.visible .entry _Z7reduce4IfLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj256EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB76_2;

ld.global.f32 %f28, [%rd1];

$L__BB76_2:
add.s32 %r11, %r4, 256;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB76_4;

ld.global.f32 %f12, [%rd1+1024];
add.f32 %f28, %f28, %f12;

$L__BB76_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB76_9;

mov.u32 %r37, %r1;

$L__BB76_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB76_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB76_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB76_6;

$L__BB76_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB76_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB76_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB76_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB76_13:
ret;

}

.visible .entry _Z7reduce4IfLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj128EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB77_2;

ld.global.f32 %f28, [%rd1];

$L__BB77_2:
add.s32 %r11, %r4, 128;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB77_4;

ld.global.f32 %f12, [%rd1+512];
add.f32 %f28, %f28, %f12;

$L__BB77_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB77_9;

mov.u32 %r37, %r1;

$L__BB77_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB77_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB77_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB77_6;

$L__BB77_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB77_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB77_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB77_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB77_13:
ret;

}

.visible .entry _Z7reduce4IfLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj64EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra $L__BB78_2;

ld.global.f32 %f28, [%rd1];

$L__BB78_2:
add.s32 %r11, %r4, 64;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB78_4;

ld.global.f32 %f12, [%rd1+256];
add.f32 %f28, %f28, %f12;

$L__BB78_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB78_9;

mov.u32 %r37, %r1;

$L__BB78_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB78_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r5], %f28;

$L__BB78_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB78_6;

$L__BB78_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB78_11;

ld.shared.f32 %f14, [%r5+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r20, %f15;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f16, %r25;
add.f32 %f17, %f15, %f16;
mov.b32 %r26, %f17;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f18, %r28;
add.f32 %f19, %f17, %f18;
mov.b32 %r29, %f19;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f20, %r31;
add.f32 %f21, %f19, %f20;
mov.b32 %r32, %f21;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f22, %r33;
add.f32 %f23, %f21, %f22;
mov.b32 %r34, %f23;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f24, %r36;
add.f32 %f28, %f23, %f24;

$L__BB78_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB78_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

$L__BB78_13:
ret;

}

.visible .entry _Z7reduce4IfLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj32EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB79_2;

ld.global.f32 %f26, [%rd1];

$L__BB79_2:
add.s32 %r11, %r4, 32;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB79_4;

ld.global.f32 %f12, [%rd1+128];
add.f32 %f26, %f26, %f12;

$L__BB79_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB79_9;

mov.u32 %r37, %r1;

$L__BB79_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB79_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB79_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB79_6;

$L__BB79_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB79_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB79_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB79_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB79_13:
ret;

}

.visible .entry _Z7reduce4IfLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj16EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB80_2;

ld.global.f32 %f26, [%rd1];

$L__BB80_2:
add.s32 %r11, %r4, 16;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB80_4;

ld.global.f32 %f12, [%rd1+64];
add.f32 %f26, %f26, %f12;

$L__BB80_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB80_9;

mov.u32 %r37, %r1;

$L__BB80_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB80_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB80_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB80_6;

$L__BB80_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB80_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB80_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB80_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB80_13:
ret;

}

.visible .entry _Z7reduce4IfLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj8EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB81_2;

ld.global.f32 %f26, [%rd1];

$L__BB81_2:
add.s32 %r11, %r4, 8;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB81_4;

ld.global.f32 %f12, [%rd1+32];
add.f32 %f26, %f26, %f12;

$L__BB81_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB81_9;

mov.u32 %r37, %r1;

$L__BB81_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB81_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB81_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB81_6;

$L__BB81_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB81_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB81_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB81_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB81_13:
ret;

}

.visible .entry _Z7reduce4IfLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj4EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB82_2;

ld.global.f32 %f26, [%rd1];

$L__BB82_2:
add.s32 %r11, %r4, 4;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB82_4;

ld.global.f32 %f12, [%rd1+16];
add.f32 %f26, %f26, %f12;

$L__BB82_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB82_9;

mov.u32 %r37, %r1;

$L__BB82_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB82_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB82_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB82_6;

$L__BB82_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB82_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB82_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB82_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB82_13:
ret;

}

.visible .entry _Z7reduce4IfLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj2EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB83_2;

ld.global.f32 %f26, [%rd1];

$L__BB83_2:
add.s32 %r11, %r4, 2;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB83_4;

ld.global.f32 %f12, [%rd1+8];
add.f32 %f26, %f26, %f12;

$L__BB83_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB83_9;

mov.u32 %r37, %r1;

$L__BB83_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB83_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB83_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB83_6;

$L__BB83_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB83_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB83_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB83_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB83_13:
ret;

}

.visible .entry _Z7reduce4IfLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IfLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB84_2;

ld.global.f32 %f26, [%rd1];

$L__BB84_2:
add.s32 %r11, %r4, 1;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB84_4;

ld.global.f32 %f12, [%rd1+4];
add.f32 %f26, %f26, %f12;

$L__BB84_4:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r5, %r13, %r12;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB84_9;

mov.u32 %r37, %r1;

$L__BB84_6:
shr.u32 %r7, %r37, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB84_8;

shl.b32 %r14, %r7, 2;
add.s32 %r15, %r5, %r14;
ld.shared.f32 %f13, [%r15];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r5], %f26;

$L__BB84_8:
barrier.sync 0;
setp.gt.u32 %p5, %r37, 131;
mov.u32 %r37, %r7;
@%p5 bra $L__BB84_6;

$L__BB84_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB84_11;

mov.b32 %r20, %f26;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f26, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f26, %f21, %f22;

$L__BB84_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB84_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB84_13:
ret;

}

.visible .entry _Z7reduce5IfLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj512EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f30, 0f00000000;
@%p1 bra $L__BB85_2;

ld.global.f32 %f30, [%rd1];

$L__BB85_2:
add.s32 %r8, %r3, 512;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB85_4;

ld.global.f32 %f14, [%rd1+2048];
add.f32 %f30, %f30, %f14;

$L__BB85_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB85_6;

ld.shared.f32 %f15, [%r4+1024];
add.f32 %f30, %f30, %f15;
st.shared.f32 [%r4], %f30;

$L__BB85_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB85_8;

ld.shared.f32 %f16, [%r4+512];
add.f32 %f30, %f30, %f16;
st.shared.f32 [%r4], %f30;

$L__BB85_8:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB85_10;

ld.shared.f32 %f17, [%r4+256];
add.f32 %f30, %f30, %f17;
st.shared.f32 [%r4], %f30;

$L__BB85_10:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p6, %r5, 31;
@%p6 bra $L__BB85_12;

ld.shared.f32 %f18, [%r4+128];
add.f32 %f19, %f30, %f18;
mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p7, %r16, %r19, %r18, %r20;
mov.b32 %f20, %r21;
add.f32 %f21, %f19, %f20;
mov.b32 %r22, %f21;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p8, %r22, %r23, %r18, %r20;
mov.b32 %f22, %r24;
add.f32 %f23, %f21, %f22;
mov.b32 %r25, %f23;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p9, %r25, %r26, %r18, %r20;
mov.b32 %f24, %r27;
add.f32 %f25, %f23, %f24;
mov.b32 %r28, %f25;
shfl.sync.down.b32 %r29|%p10, %r28, %r17, %r18, %r20;
mov.b32 %f26, %r29;
add.f32 %f27, %f25, %f26;
mov.b32 %r30, %f27;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p11, %r30, %r31, %r18, %r20;
mov.b32 %f28, %r32;
add.f32 %f30, %f27, %f28;

$L__BB85_12:
setp.ne.s32 %p12, %r5, 0;
@%p12 bra $L__BB85_14;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f30;

$L__BB85_14:
ret;

}

.visible .entry _Z7reduce5IfLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj256EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f27, 0f00000000;
@%p1 bra $L__BB86_2;

ld.global.f32 %f27, [%rd1];

$L__BB86_2:
add.s32 %r8, %r3, 256;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB86_4;

ld.global.f32 %f12, [%rd1+1024];
add.f32 %f27, %f27, %f12;

$L__BB86_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB86_6;

ld.shared.f32 %f13, [%r4+512];
add.f32 %f27, %f27, %f13;
st.shared.f32 [%r4], %f27;

$L__BB86_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB86_8;

ld.shared.f32 %f14, [%r4+256];
add.f32 %f27, %f27, %f14;
st.shared.f32 [%r4], %f27;

$L__BB86_8:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p5, %r5, 31;
@%p5 bra $L__BB86_10;

ld.shared.f32 %f15, [%r4+128];
add.f32 %f16, %f27, %f15;
mov.b32 %r16, %f16;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p6, %r16, %r19, %r18, %r20;
mov.b32 %f17, %r21;
add.f32 %f18, %f16, %f17;
mov.b32 %r22, %f18;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p7, %r22, %r23, %r18, %r20;
mov.b32 %f19, %r24;
add.f32 %f20, %f18, %f19;
mov.b32 %r25, %f20;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r26, %r18, %r20;
mov.b32 %f21, %r27;
add.f32 %f22, %f20, %f21;
mov.b32 %r28, %f22;
shfl.sync.down.b32 %r29|%p9, %r28, %r17, %r18, %r20;
mov.b32 %f23, %r29;
add.f32 %f24, %f22, %f23;
mov.b32 %r30, %f24;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p10, %r30, %r31, %r18, %r20;
mov.b32 %f25, %r32;
add.f32 %f27, %f24, %f25;

$L__BB86_10:
setp.ne.s32 %p11, %r5, 0;
@%p11 bra $L__BB86_12;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f27;

$L__BB86_12:
ret;

}

.visible .entry _Z7reduce5IfLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj128EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f24, 0f00000000;
@%p1 bra $L__BB87_2;

ld.global.f32 %f24, [%rd1];

$L__BB87_2:
add.s32 %r8, %r3, 128;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB87_4;

ld.global.f32 %f10, [%rd1+512];
add.f32 %f24, %f24, %f10;

$L__BB87_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB87_6;

ld.shared.f32 %f11, [%r4+256];
add.f32 %f24, %f24, %f11;
st.shared.f32 [%r4], %f24;

$L__BB87_6:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p4, %r5, 31;
@%p4 bra $L__BB87_8;

ld.shared.f32 %f12, [%r4+128];
add.f32 %f13, %f24, %f12;
mov.b32 %r16, %f13;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p5, %r16, %r19, %r18, %r20;
mov.b32 %f14, %r21;
add.f32 %f15, %f13, %f14;
mov.b32 %r22, %f15;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p6, %r22, %r23, %r18, %r20;
mov.b32 %f16, %r24;
add.f32 %f17, %f15, %f16;
mov.b32 %r25, %f17;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p7, %r25, %r26, %r18, %r20;
mov.b32 %f18, %r27;
add.f32 %f19, %f17, %f18;
mov.b32 %r28, %f19;
shfl.sync.down.b32 %r29|%p8, %r28, %r17, %r18, %r20;
mov.b32 %f20, %r29;
add.f32 %f21, %f19, %f20;
mov.b32 %r30, %f21;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r18, %r20;
mov.b32 %f22, %r32;
add.f32 %f24, %f21, %f22;

$L__BB87_8:
setp.ne.s32 %p10, %r5, 0;
@%p10 bra $L__BB87_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f24;

$L__BB87_10:
ret;

}

.visible .entry _Z7reduce5IfLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<23>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj64EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IfLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB88_2;

ld.global.f32 %f21, [%rd1];

$L__BB88_2:
add.s32 %r8, %r3, 64;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB88_4;

ld.global.f32 %f8, [%rd1+256];
add.f32 %f21, %f21, %f8;

$L__BB88_4:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r4, %r10, %r9;
st.shared.f32 [%r4], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p3, %r5, 31;
@%p3 bra $L__BB88_6;

ld.shared.f32 %f9, [%r4+128];
add.f32 %f10, %f21, %f9;
mov.b32 %r16, %f10;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f11, %r21;
add.f32 %f12, %f10, %f11;
mov.b32 %r22, %f12;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f13, %r24;
add.f32 %f14, %f12, %f13;
mov.b32 %r25, %f14;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f15, %r27;
add.f32 %f16, %f14, %f15;
mov.b32 %r28, %f16;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f17, %r29;
add.f32 %f18, %f16, %f17;
mov.b32 %r30, %f18;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f19, %r32;
add.f32 %f21, %f18, %f19;

$L__BB88_6:
setp.ne.s32 %p9, %r5, 0;
@%p9 bra $L__BB88_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f21;

$L__BB88_8:
ret;

}

.visible .entry _Z7reduce5IfLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj32EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB89_2;

ld.global.f32 %f19, [%rd1];

$L__BB89_2:
add.s32 %r7, %r3, 32;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB89_4;

ld.global.f32 %f8, [%rd1+128];
add.f32 %f19, %f19, %f8;

$L__BB89_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB89_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB89_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB89_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB89_8:
ret;

}

.visible .entry _Z7reduce5IfLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj16EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB90_2;

ld.global.f32 %f19, [%rd1];

$L__BB90_2:
add.s32 %r7, %r3, 16;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB90_4;

ld.global.f32 %f8, [%rd1+64];
add.f32 %f19, %f19, %f8;

$L__BB90_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB90_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB90_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB90_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB90_8:
ret;

}

.visible .entry _Z7reduce5IfLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj8EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB91_2;

ld.global.f32 %f19, [%rd1];

$L__BB91_2:
add.s32 %r7, %r3, 8;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB91_4;

ld.global.f32 %f8, [%rd1+32];
add.f32 %f19, %f19, %f8;

$L__BB91_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB91_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB91_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB91_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB91_8:
ret;

}

.visible .entry _Z7reduce5IfLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj4EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB92_2;

ld.global.f32 %f19, [%rd1];

$L__BB92_2:
add.s32 %r7, %r3, 4;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB92_4;

ld.global.f32 %f8, [%rd1+16];
add.f32 %f19, %f19, %f8;

$L__BB92_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB92_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB92_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB92_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB92_8:
ret;

}

.visible .entry _Z7reduce5IfLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj2EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB93_2;

ld.global.f32 %f19, [%rd1];

$L__BB93_2:
add.s32 %r7, %r3, 2;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB93_4;

ld.global.f32 %f8, [%rd1+8];
add.f32 %f19, %f19, %f8;

$L__BB93_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB93_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB93_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB93_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB93_8:
ret;

}

.visible .entry _Z7reduce5IfLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<33>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj1EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IfLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB94_2;

ld.global.f32 %f19, [%rd1];

$L__BB94_2:
add.s32 %r7, %r3, 1;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB94_4;

ld.global.f32 %f8, [%rd1+4];
add.f32 %f19, %f19, %f8;

$L__BB94_4:
shl.b32 %r8, %r2, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB94_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

$L__BB94_6:
setp.ne.s32 %p9, %r4, 0;
@%p9 bra $L__BB94_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB94_8:
ret;

}

.visible .entry _Z7reduce6IfLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<14>;
.reg .f32 %f<39>;
.reg .b32 %r<39>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r10, %ctaid.x;
shl.b32 %r11, %r10, 10;
mov.u32 %r1, %tid.x;
add.s32 %r38, %r11, %r1;
setp.ge.u32 %p1, %r38, %r9;
mov.f32 %f32, 0f00000000;
@%p1 bra $L__BB95_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r3, %r12, 10;

$L__BB95_2:
mul.wide.u32 %rd4, %r38, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f16, [%rd5];
add.f32 %f32, %f32, %f16;
add.s32 %r5, %r38, 512;
setp.ge.u32 %p2, %r5, %r9;
@%p2 bra $L__BB95_4;

mul.wide.u32 %rd6, %r5, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f17, [%rd7];
add.f32 %f32, %f32, %f17;

$L__BB95_4:
add.s32 %r38, %r38, %r3;
setp.lt.u32 %p3, %r38, %r9;
@%p3 bra $L__BB95_2;

$L__BB95_5:
shl.b32 %r13, %r1, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.f32 [%r7], %f32;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 255;
@%p4 bra $L__BB95_7;

ld.shared.f32 %f18, [%r7+1024];
add.f32 %f32, %f32, %f18;
st.shared.f32 [%r7], %f32;

$L__BB95_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 127;
@%p5 bra $L__BB95_9;

ld.shared.f32 %f19, [%r7+512];
add.f32 %f32, %f32, %f19;
st.shared.f32 [%r7], %f32;

$L__BB95_9:
barrier.sync 0;
setp.gt.u32 %p6, %r1, 63;
@%p6 bra $L__BB95_11;

ld.shared.f32 %f20, [%r7+256];
add.f32 %f32, %f32, %f20;
st.shared.f32 [%r7], %f32;

$L__BB95_11:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r1;
setp.gt.u32 %p7, %r8, 31;
@%p7 bra $L__BB95_13;

ld.shared.f32 %f21, [%r7+128];
add.f32 %f22, %f32, %f21;
mov.b32 %r20, %f22;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p8, %r20, %r23, %r22, %r24;
mov.b32 %f23, %r25;
add.f32 %f24, %f22, %f23;
mov.b32 %r26, %f24;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p9, %r26, %r27, %r22, %r24;
mov.b32 %f25, %r28;
add.f32 %f26, %f24, %f25;
mov.b32 %r29, %f26;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p10, %r29, %r30, %r22, %r24;
mov.b32 %f27, %r31;
add.f32 %f28, %f26, %f27;
mov.b32 %r32, %f28;
shfl.sync.down.b32 %r33|%p11, %r32, %r21, %r22, %r24;
mov.b32 %f29, %r33;
add.f32 %f30, %f28, %f29;
mov.b32 %r34, %f30;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p12, %r34, %r35, %r22, %r24;
mov.b32 %f31, %r36;
add.f32 %f32, %f30, %f31;

$L__BB95_13:
setp.ne.s32 %p13, %r8, 0;
@%p13 bra $L__BB95_15;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r10, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f32;

$L__BB95_15:
ret;

}

.visible .entry _Z7reduce6IfLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<39>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r10, %ctaid.x;
shl.b32 %r11, %r10, 9;
mov.u32 %r1, %tid.x;
add.s32 %r38, %r11, %r1;
setp.ge.u32 %p1, %r38, %r9;
mov.f32 %f29, 0f00000000;
@%p1 bra $L__BB96_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r3, %r12, 9;

$L__BB96_2:
mul.wide.u32 %rd4, %r38, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f14, [%rd5];
add.f32 %f29, %f29, %f14;
add.s32 %r5, %r38, 256;
setp.ge.u32 %p2, %r5, %r9;
@%p2 bra $L__BB96_4;

mul.wide.u32 %rd6, %r5, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f15, [%rd7];
add.f32 %f29, %f29, %f15;

$L__BB96_4:
add.s32 %r38, %r38, %r3;
setp.lt.u32 %p3, %r38, %r9;
@%p3 bra $L__BB96_2;

$L__BB96_5:
shl.b32 %r13, %r1, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.f32 [%r7], %f29;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r1, 127;
@%p4 bra $L__BB96_7;

ld.shared.f32 %f16, [%r7+512];
add.f32 %f29, %f29, %f16;
st.shared.f32 [%r7], %f29;

$L__BB96_7:
barrier.sync 0;
setp.gt.u32 %p5, %r1, 63;
@%p5 bra $L__BB96_9;

ld.shared.f32 %f17, [%r7+256];
add.f32 %f29, %f29, %f17;
st.shared.f32 [%r7], %f29;

$L__BB96_9:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r1;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB96_11;

ld.shared.f32 %f18, [%r7+128];
add.f32 %f19, %f29, %f18;
mov.b32 %r20, %f19;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p7, %r20, %r23, %r22, %r24;
mov.b32 %f20, %r25;
add.f32 %f21, %f19, %f20;
mov.b32 %r26, %f21;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p8, %r26, %r27, %r22, %r24;
mov.b32 %f22, %r28;
add.f32 %f23, %f21, %f22;
mov.b32 %r29, %f23;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r30, %r22, %r24;
mov.b32 %f24, %r31;
add.f32 %f25, %f23, %f24;
mov.b32 %r32, %f25;
shfl.sync.down.b32 %r33|%p10, %r32, %r21, %r22, %r24;
mov.b32 %f26, %r33;
add.f32 %f27, %f25, %f26;
mov.b32 %r34, %f27;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p11, %r34, %r35, %r22, %r24;
mov.b32 %f28, %r36;
add.f32 %f29, %f27, %f28;

$L__BB96_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB96_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r10, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f29;

$L__BB96_13:
ret;

}

.visible .entry _Z7reduce6IfLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r11, %r2;
setp.ge.u32 %p1, %r37, %r10;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB97_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 8;

$L__BB97_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f26, %f26, %f12;
add.s32 %r6, %r37, 128;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB97_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f13, [%rd7];
add.f32 %f26, %f26, %f13;

$L__BB97_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r10;
@%p3 bra $L__BB97_2;

$L__BB97_5:
shl.b32 %r13, %r2, 2;
mov.u32 %r14, __smem;
add.s32 %r8, %r14, %r13;
st.shared.f32 [%r8], %f26;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB97_7;

ld.shared.f32 %f14, [%r8+256];
add.f32 %f26, %f26, %f14;
st.shared.f32 [%r8], %f26;

$L__BB97_7:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p5, %r9, 31;
@%p5 bra $L__BB97_9;

ld.shared.f32 %f15, [%r8+128];
add.f32 %f16, %f26, %f15;
mov.b32 %r20, %f16;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p6, %r20, %r23, %r22, %r24;
mov.b32 %f17, %r25;
add.f32 %f18, %f16, %f17;
mov.b32 %r26, %f18;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p7, %r26, %r27, %r22, %r24;
mov.b32 %f19, %r28;
add.f32 %f20, %f18, %f19;
mov.b32 %r29, %f20;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p8, %r29, %r30, %r22, %r24;
mov.b32 %f21, %r31;
add.f32 %f22, %f20, %f21;
mov.b32 %r32, %f22;
shfl.sync.down.b32 %r33|%p9, %r32, %r21, %r22, %r24;
mov.b32 %f23, %r33;
add.f32 %f24, %f22, %f23;
mov.b32 %r34, %f24;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p10, %r34, %r35, %r22, %r24;
mov.b32 %f25, %r36;
add.f32 %f26, %f24, %f25;

$L__BB97_9:
setp.ne.s32 %p11, %r9, 0;
@%p11 bra $L__BB97_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f26;

$L__BB97_11:
ret;

}

.visible .entry _Z7reduce6IfLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r11, %r2;
setp.ge.u32 %p1, %r37, %r10;
mov.f32 %f23, 0f00000000;
@%p1 bra $L__BB98_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 7;

$L__BB98_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f23, %f23, %f10;
add.s32 %r6, %r37, 64;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB98_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f23, %f23, %f11;

$L__BB98_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r10;
@%p3 bra $L__BB98_2;

$L__BB98_5:
shl.b32 %r13, %r2, 2;
mov.u32 %r14, __smem;
add.s32 %r8, %r14, %r13;
st.shared.f32 [%r8], %f23;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p4, %r9, 31;
@%p4 bra $L__BB98_7;

ld.shared.f32 %f12, [%r8+128];
add.f32 %f13, %f23, %f12;
mov.b32 %r20, %f13;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f14, %r25;
add.f32 %f15, %f13, %f14;
mov.b32 %r26, %f15;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f16, %r28;
add.f32 %f17, %f15, %f16;
mov.b32 %r29, %f17;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f18, %r31;
add.f32 %f19, %f17, %f18;
mov.b32 %r32, %f19;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f20, %r33;
add.f32 %f21, %f19, %f20;
mov.b32 %r34, %f21;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f22, %r36;
add.f32 %f23, %f21, %f22;

$L__BB98_7:
setp.ne.s32 %p10, %r9, 0;
@%p10 bra $L__BB98_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f23;

$L__BB98_9:
ret;

}

.visible .entry _Z7reduce6IfLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB99_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;

$L__BB99_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 32;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB99_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB99_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB99_2;

$L__BB99_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB99_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB99_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB99_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB99_9:
ret;

}

.visible .entry _Z7reduce6IfLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB100_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 5;

$L__BB100_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 16;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB100_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB100_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB100_2;

$L__BB100_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB100_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB100_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB100_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB100_9:
ret;

}

.visible .entry _Z7reduce6IfLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB101_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 4;

$L__BB101_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 8;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB101_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB101_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB101_2;

$L__BB101_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB101_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB101_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB101_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB101_9:
ret;

}

.visible .entry _Z7reduce6IfLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB102_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 3;

$L__BB102_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 4;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB102_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB102_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB102_2;

$L__BB102_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB102_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB102_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB102_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB102_9:
ret;

}

.visible .entry _Z7reduce6IfLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB103_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 2;

$L__BB103_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 2;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB103_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB103_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB103_2;

$L__BB103_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB103_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB103_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB103_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB103_9:
ret;

}

.visible .entry _Z7reduce6IfLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r37, %r10, %r2;
setp.ge.u32 %p1, %r37, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB104_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 1;

$L__BB104_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r6, %r37, 1;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB104_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f11, [%rd7];
add.f32 %f21, %f21, %f11;

$L__BB104_4:
add.s32 %r37, %r37, %r4;
setp.lt.u32 %p3, %r37, %r9;
@%p3 bra $L__BB104_2;

$L__BB104_5:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.f32 [%r14], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB104_7;

mov.b32 %r20, %f21;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p5, %r20, %r23, %r22, %r24;
mov.b32 %f12, %r25;
add.f32 %f13, %f21, %f12;
mov.b32 %r26, %f13;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r22, %r24;
mov.b32 %f14, %r28;
add.f32 %f15, %f13, %f14;
mov.b32 %r29, %f15;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p7, %r29, %r30, %r22, %r24;
mov.b32 %f16, %r31;
add.f32 %f17, %f15, %f16;
mov.b32 %r32, %f17;
shfl.sync.down.b32 %r33|%p8, %r32, %r21, %r22, %r24;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r22, %r24;
mov.b32 %f20, %r36;
add.f32 %f21, %f19, %f20;

$L__BB104_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB104_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f21;

$L__BB104_9:
ret;

}

.visible .entry _Z7reduce6IfLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f30, 0f00000000;
@%p1 bra $L__BB105_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB105_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f14, [%rd5];
add.f32 %f30, %f30, %f14;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB105_2;

$L__BB105_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB105_5;

ld.shared.f32 %f15, [%r7+1024];
add.f32 %f30, %f30, %f15;
st.shared.f32 [%r7], %f30;

$L__BB105_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB105_7;

ld.shared.f32 %f16, [%r7+512];
add.f32 %f30, %f30, %f16;
st.shared.f32 [%r7], %f30;

$L__BB105_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB105_9;

ld.shared.f32 %f17, [%r7+256];
add.f32 %f30, %f30, %f17;
st.shared.f32 [%r7], %f30;

$L__BB105_9:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB105_11;

ld.shared.f32 %f18, [%r7+128];
add.f32 %f19, %f30, %f18;
mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p7, %r19, %r22, %r21, %r23;
mov.b32 %f20, %r24;
add.f32 %f21, %f19, %f20;
mov.b32 %r25, %f21;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p8, %r25, %r26, %r21, %r23;
mov.b32 %f22, %r27;
add.f32 %f23, %f21, %f22;
mov.b32 %r28, %f23;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p9, %r28, %r29, %r21, %r23;
mov.b32 %f24, %r30;
add.f32 %f25, %f23, %f24;
mov.b32 %r31, %f25;
shfl.sync.down.b32 %r32|%p10, %r31, %r20, %r21, %r23;
mov.b32 %f26, %r32;
add.f32 %f27, %f25, %f26;
mov.b32 %r33, %f27;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p11, %r33, %r34, %r21, %r23;
mov.b32 %f28, %r35;
add.f32 %f30, %f27, %f28;

$L__BB105_11:
setp.ne.s32 %p12, %r8, 0;
@%p12 bra $L__BB105_13;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f30;

$L__BB105_13:
ret;

}

.visible .entry _Z7reduce6IfLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f27, 0f00000000;
@%p1 bra $L__BB106_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB106_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f27, %f27, %f12;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB106_2;

$L__BB106_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB106_5;

ld.shared.f32 %f13, [%r7+512];
add.f32 %f27, %f27, %f13;
st.shared.f32 [%r7], %f27;

$L__BB106_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB106_7;

ld.shared.f32 %f14, [%r7+256];
add.f32 %f27, %f27, %f14;
st.shared.f32 [%r7], %f27;

$L__BB106_7:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p5, %r8, 31;
@%p5 bra $L__BB106_9;

ld.shared.f32 %f15, [%r7+128];
add.f32 %f16, %f27, %f15;
mov.b32 %r19, %f16;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p6, %r19, %r22, %r21, %r23;
mov.b32 %f17, %r24;
add.f32 %f18, %f16, %f17;
mov.b32 %r25, %f18;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r26, %r21, %r23;
mov.b32 %f19, %r27;
add.f32 %f20, %f18, %f19;
mov.b32 %r28, %f20;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r29, %r21, %r23;
mov.b32 %f21, %r30;
add.f32 %f22, %f20, %f21;
mov.b32 %r31, %f22;
shfl.sync.down.b32 %r32|%p9, %r31, %r20, %r21, %r23;
mov.b32 %f23, %r32;
add.f32 %f24, %f22, %f23;
mov.b32 %r33, %f24;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p10, %r33, %r34, %r21, %r23;
mov.b32 %f25, %r35;
add.f32 %f27, %f24, %f25;

$L__BB106_9:
setp.ne.s32 %p11, %r8, 0;
@%p11 bra $L__BB106_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f27;

$L__BB106_11:
ret;

}

.visible .entry _Z7reduce6IfLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f24, 0f00000000;
@%p1 bra $L__BB107_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB107_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f24, %f24, %f10;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB107_2;

$L__BB107_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB107_5;

ld.shared.f32 %f11, [%r7+256];
add.f32 %f24, %f24, %f11;
st.shared.f32 [%r7], %f24;

$L__BB107_5:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB107_7;

ld.shared.f32 %f12, [%r7+128];
add.f32 %f13, %f24, %f12;
mov.b32 %r19, %f13;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p5, %r19, %r22, %r21, %r23;
mov.b32 %f14, %r24;
add.f32 %f15, %f13, %f14;
mov.b32 %r25, %f15;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r21, %r23;
mov.b32 %f16, %r27;
add.f32 %f17, %f15, %f16;
mov.b32 %r28, %f17;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p7, %r28, %r29, %r21, %r23;
mov.b32 %f18, %r30;
add.f32 %f19, %f17, %f18;
mov.b32 %r31, %f19;
shfl.sync.down.b32 %r32|%p8, %r31, %r20, %r21, %r23;
mov.b32 %f20, %r32;
add.f32 %f21, %f19, %f20;
mov.b32 %r33, %f21;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p9, %r33, %r34, %r21, %r23;
mov.b32 %f22, %r35;
add.f32 %f24, %f21, %f22;

$L__BB107_7:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra $L__BB107_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f24;

$L__BB107_9:
ret;

}

.visible .entry _Z7reduce6IfLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<23>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r10, %r2;
setp.ge.u32 %p1, %r36, %r9;
mov.f32 %f21, 0f00000000;
@%p1 bra $L__BB108_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB108_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f21, %f21, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r9;
@%p2 bra $L__BB108_2;

$L__BB108_3:
shl.b32 %r12, %r2, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.f32 [%r7], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB108_5;

ld.shared.f32 %f9, [%r7+128];
add.f32 %f10, %f21, %f9;
mov.b32 %r19, %f10;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f15, %r30;
add.f32 %f16, %f14, %f15;
mov.b32 %r31, %f16;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f17, %r32;
add.f32 %f18, %f16, %f17;
mov.b32 %r33, %f18;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f19, %r35;
add.f32 %f21, %f18, %f19;

$L__BB108_5:
setp.ne.s32 %p9, %r8, 0;
@%p9 bra $L__BB108_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f21;

$L__BB108_7:
ret;

}

.visible .entry _Z7reduce6IfLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB109_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB109_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB109_2;

$L__BB109_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB109_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB109_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB109_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB109_7:
ret;

}

.visible .entry _Z7reduce6IfLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB110_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB110_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB110_2;

$L__BB110_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB110_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB110_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB110_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB110_7:
ret;

}

.visible .entry _Z7reduce6IfLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB111_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB111_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB111_2;

$L__BB111_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB111_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB111_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB111_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB111_7:
ret;

}

.visible .entry _Z7reduce6IfLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB112_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB112_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB112_2;

$L__BB112_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB112_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB112_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB112_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB112_7:
ret;

}

.visible .entry _Z7reduce6IfLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<37>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r9, %r2;
setp.ge.u32 %p1, %r36, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB113_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB113_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p2, %r36, %r8;
@%p2 bra $L__BB113_2;

$L__BB113_3:
shl.b32 %r11, %r2, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB113_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

$L__BB113_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB113_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB113_7:
ret;

}

.visible .entry _Z7reduce6IfLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r34, %r1, %r2;
setp.ge.u32 %p1, %r34, %r8;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB114_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB114_2:
mul.wide.u32 %rd4, %r34, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r34, %r34, %r4;
setp.lt.u32 %p2, %r34, %r8;
@%p2 bra $L__BB114_2;

$L__BB114_3:
shl.b32 %r9, %r2, 2;
mov.u32 %r10, __smem;
add.s32 %r11, %r10, %r9;
st.shared.f32 [%r11], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r7, %r15, %r16, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB114_5;

mov.b32 %r17, %f19;
mov.u32 %r18, 2;
mov.u32 %r19, 31;
mov.u32 %r20, 16;
mov.u32 %r21, -1;
shfl.sync.down.b32 %r22|%p4, %r17, %r20, %r19, %r21;
mov.b32 %f9, %r22;
add.f32 %f10, %f19, %f9;
mov.b32 %r23, %f10;
mov.u32 %r24, 8;
shfl.sync.down.b32 %r25|%p5, %r23, %r24, %r19, %r21;
mov.b32 %f11, %r25;
add.f32 %f12, %f10, %f11;
mov.b32 %r26, %f12;
mov.u32 %r27, 4;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r19, %r21;
mov.b32 %f13, %r28;
add.f32 %f14, %f12, %f13;
mov.b32 %r29, %f14;
shfl.sync.down.b32 %r30|%p7, %r29, %r18, %r19, %r21;
mov.b32 %f15, %r30;
add.f32 %f16, %f14, %f15;
mov.b32 %r31, %f16;
mov.u32 %r32, 1;
shfl.sync.down.b32 %r33|%p8, %r31, %r32, %r19, %r21;
mov.b32 %f17, %r33;
add.f32 %f19, %f16, %f17;

$L__BB114_5:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra $L__BB114_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB114_7:
ret;

}

.visible .entry _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB115_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 11;

$L__BB115_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 1024;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB115_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB115_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB115_2;

$L__BB115_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB115_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB115_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB115_7;

$L__BB115_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB115_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB115_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 1024;
mov.u32 %r43, 1;
@%p8 bra $L__BB115_12;

mov.u32 %r31, 1024;
div.u32 %r43, %r31, %r44;

$L__BB115_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB115_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB115_16;

mov.u32 %r39, 31;

$L__BB115_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB115_15;

$L__BB115_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB115_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB115_18:
ret;

}

.visible .entry _Z7reduce7IfLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB116_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 10;

$L__BB116_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 512;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB116_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB116_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB116_2;

$L__BB116_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB116_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB116_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB116_7;

$L__BB116_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB116_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB116_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 512;
mov.u32 %r43, 1;
@%p8 bra $L__BB116_12;

mov.u32 %r31, 512;
div.u32 %r43, %r31, %r44;

$L__BB116_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB116_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB116_16;

mov.u32 %r39, 31;

$L__BB116_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB116_15;

$L__BB116_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB116_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB116_18:
ret;

}

.visible .entry _Z7reduce7IfLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB117_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 9;

$L__BB117_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 256;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB117_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB117_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB117_2;

$L__BB117_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB117_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB117_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB117_7;

$L__BB117_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB117_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB117_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 256;
mov.u32 %r43, 1;
@%p8 bra $L__BB117_12;

mov.u32 %r31, 256;
div.u32 %r43, %r31, %r44;

$L__BB117_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB117_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB117_16;

mov.u32 %r39, 31;

$L__BB117_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB117_15;

$L__BB117_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB117_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB117_18:
ret;

}

.visible .entry _Z7reduce7IfLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB118_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 8;

$L__BB118_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 128;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB118_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB118_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB118_2;

$L__BB118_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB118_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB118_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB118_7;

$L__BB118_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB118_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB118_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 128;
mov.u32 %r43, 1;
@%p8 bra $L__BB118_12;

mov.u32 %r31, 128;
div.u32 %r43, %r31, %r44;

$L__BB118_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB118_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB118_16;

mov.u32 %r39, 31;

$L__BB118_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB118_15;

$L__BB118_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB118_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB118_18:
ret;

}

.visible .entry _Z7reduce7IfLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB119_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 7;

$L__BB119_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 64;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB119_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB119_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB119_2;

$L__BB119_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB119_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB119_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB119_7;

$L__BB119_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB119_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB119_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 64;
mov.u32 %r43, 1;
@%p8 bra $L__BB119_12;

mov.u32 %r31, 64;
div.u32 %r43, %r31, %r44;

$L__BB119_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB119_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB119_16;

mov.u32 %r39, 31;

$L__BB119_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB119_15;

$L__BB119_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB119_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB119_18:
ret;

}

.visible .entry _Z7reduce7IfLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB120_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;

$L__BB120_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 32;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB120_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB120_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB120_2;

$L__BB120_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB120_8;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

$L__BB120_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB120_7;

$L__BB120_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB120_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB120_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 32;
mov.u32 %r43, 1;
@%p8 bra $L__BB120_12;

mov.u32 %r31, 32;
div.u32 %r43, %r31, %r44;

$L__BB120_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB120_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB120_16;

mov.u32 %r39, 31;

$L__BB120_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB120_15;

$L__BB120_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB120_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB120_18:
ret;

}

.visible .entry _Z7reduce7IfLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB121_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 5;

$L__BB121_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 16;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB121_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB121_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB121_2;

$L__BB121_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB121_8;

mov.u32 %r22, 31;
mov.u32 %r23, 65535;
mov.u32 %r42, %r44;

$L__BB121_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB121_7;

$L__BB121_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB121_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB121_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 16;
mov.u32 %r43, 1;
@%p8 bra $L__BB121_12;

mov.u32 %r31, 16;
div.u32 %r43, %r31, %r44;

$L__BB121_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 65535;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB121_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB121_16;

mov.u32 %r39, 31;

$L__BB121_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB121_15;

$L__BB121_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB121_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB121_18:
ret;

}

.visible .entry _Z7reduce7IfLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB122_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 4;

$L__BB122_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 8;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB122_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB122_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB122_2;

$L__BB122_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB122_8;

mov.u32 %r22, 31;
mov.u32 %r23, 255;
mov.u32 %r42, %r44;

$L__BB122_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB122_7;

$L__BB122_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB122_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB122_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 8;
mov.u32 %r43, 1;
@%p8 bra $L__BB122_12;

mov.u32 %r31, 8;
div.u32 %r43, %r31, %r44;

$L__BB122_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 255;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB122_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB122_16;

mov.u32 %r39, 31;

$L__BB122_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB122_15;

$L__BB122_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB122_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB122_18:
ret;

}

.visible .entry _Z7reduce7IfLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB123_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 3;

$L__BB123_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 4;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB123_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB123_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB123_2;

$L__BB123_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB123_8;

mov.u32 %r22, 31;
mov.u32 %r23, 15;
mov.u32 %r42, %r44;

$L__BB123_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB123_7;

$L__BB123_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB123_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB123_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 4;
mov.u32 %r43, 1;
@%p8 bra $L__BB123_12;

mov.u32 %r31, 4;
div.u32 %r43, %r31, %r44;

$L__BB123_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 15;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB123_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB123_16;

mov.u32 %r39, 31;

$L__BB123_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB123_15;

$L__BB123_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB123_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB123_18:
ret;

}

.visible .entry _Z7reduce7IfLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<45>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p1, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB124_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 2;

$L__BB124_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r41, 2;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB124_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB124_4:
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra $L__BB124_2;

$L__BB124_5:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra $L__BB124_8;

mov.u32 %r22, 31;
mov.u32 %r23, 3;
mov.u32 %r42, %r44;

$L__BB124_7:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r10, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r10, %r22, %r23;
mov.b32 %f17, %r24;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r10;
@%p6 bra $L__BB124_7;

$L__BB124_8:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra $L__BB124_10;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

$L__BB124_10:
bar.sync 0;
setp.gt.u32 %p8, %r44, 2;
mov.u32 %r43, 1;
@%p8 bra $L__BB124_12;

mov.u32 %r31, 2;
div.u32 %r43, %r31, %r44;

$L__BB124_12:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 3;
vote.sync.ballot.b32 %r13, %p10, %r32;
@%p9 bra $L__BB124_16;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra $L__BB124_16;

mov.u32 %r39, 31;

$L__BB124_15:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p13, %r36, %r15, %r39, %r13;
mov.b32 %f18, %r40;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r44, 3;
mov.u32 %r44, %r15;
@%p14 bra $L__BB124_15;

$L__BB124_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra $L__BB124_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB124_18:
ret;

}

.visible .entry _Z7reduce7IfLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<26>;
.reg .b32 %r<37>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r14, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r34, %r15, %r2;
setp.ge.u32 %p1, %r34, %r14;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB125_5;

mov.u32 %r16, %nctaid.x;
shl.b32 %r4, %r16, 1;

$L__BB125_2:
mul.wide.u32 %rd4, %r34, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r34, 1;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra $L__BB125_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

$L__BB125_4:
add.s32 %r34, %r34, %r4;
setp.lt.u32 %p3, %r34, %r14;
@%p3 bra $L__BB125_2;

$L__BB125_5:
mov.u32 %r36, WARP_SZ;
setp.lt.s32 %p4, %r36, 2;
@%p4 bra $L__BB125_8;

mov.u32 %r20, 31;
mov.u32 %r21, 1;
mov.u32 %r35, %r36;

$L__BB125_7:
mov.b32 %r17, %f19;
shr.u32 %r18, %r35, 31;
add.s32 %r19, %r35, %r18;
shr.s32 %r10, %r19, 1;
shfl.sync.down.b32 %r22|%p5, %r17, %r10, %r20, %r21;
mov.b32 %f17, %r22;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p6, %r35, 3;
mov.u32 %r35, %r10;
@%p6 bra $L__BB125_7;

$L__BB125_8:
rem.u32 %r23, %r2, %r36;
setp.ne.s32 %p7, %r23, 0;
@%p7 bra $L__BB125_10;

div.u32 %r24, %r2, %r36;
shl.b32 %r25, %r24, 2;
mov.u32 %r26, __smem;
add.s32 %r27, %r26, %r25;
st.shared.f32 [%r27], %f19;

$L__BB125_10:
bar.sync 0;
setp.ne.s32 %p8, %r2, 0;
setp.eq.s32 %p9, %r2, 0;
mov.u32 %r28, 1;
vote.sync.ballot.b32 %r11, %p9, %r28;
@%p8 bra $L__BB125_14;

ld.shared.f32 %f19, [__smem];
@%p4 bra $L__BB125_14;

mov.u32 %r32, 31;

$L__BB125_13:
mov.b32 %r29, %f19;
shr.u32 %r30, %r36, 31;
add.s32 %r31, %r36, %r30;
shr.s32 %r13, %r31, 1;
shfl.sync.down.b32 %r33|%p12, %r29, %r13, %r32, %r11;
mov.b32 %f18, %r33;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p13, %r36, 3;
mov.u32 %r36, %r13;
@%p13 bra $L__BB125_13;

$L__BB125_14:
@%p8 bra $L__BB125_16;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

$L__BB125_16:
ret;

}

.visible .entry _Z7reduce7IfLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB126_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB126_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB126_2;

$L__BB126_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB126_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB126_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB126_5;

$L__BB126_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB126_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB126_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 512;
mov.u32 %r42, 1;
@%p7 bra $L__BB126_10;

mov.u32 %r30, 512;
div.u32 %r42, %r30, %r43;

$L__BB126_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB126_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB126_14;

mov.u32 %r38, 31;

$L__BB126_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB126_13;

$L__BB126_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB126_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB126_16:
ret;

}

.visible .entry _Z7reduce7IfLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB127_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB127_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB127_2;

$L__BB127_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB127_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB127_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB127_5;

$L__BB127_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB127_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB127_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 256;
mov.u32 %r42, 1;
@%p7 bra $L__BB127_10;

mov.u32 %r30, 256;
div.u32 %r42, %r30, %r43;

$L__BB127_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB127_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB127_14;

mov.u32 %r38, 31;

$L__BB127_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB127_13;

$L__BB127_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB127_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB127_16:
ret;

}

.visible .entry _Z7reduce7IfLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB128_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB128_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB128_2;

$L__BB128_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB128_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB128_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB128_5;

$L__BB128_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB128_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB128_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 128;
mov.u32 %r42, 1;
@%p7 bra $L__BB128_10;

mov.u32 %r30, 128;
div.u32 %r42, %r30, %r43;

$L__BB128_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB128_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB128_14;

mov.u32 %r38, 31;

$L__BB128_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB128_13;

$L__BB128_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB128_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB128_16:
ret;

}

.visible .entry _Z7reduce7IfLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB129_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB129_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB129_2;

$L__BB129_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB129_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB129_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB129_5;

$L__BB129_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB129_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB129_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 64;
mov.u32 %r42, 1;
@%p7 bra $L__BB129_10;

mov.u32 %r30, 64;
div.u32 %r42, %r30, %r43;

$L__BB129_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB129_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB129_14;

mov.u32 %r38, 31;

$L__BB129_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB129_13;

$L__BB129_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB129_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB129_16:
ret;

}

.visible .entry _Z7reduce7IfLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB130_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB130_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB130_2;

$L__BB130_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB130_6;

mov.u32 %r21, 31;
mov.u32 %r22, -1;
mov.u32 %r41, %r43;

$L__BB130_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB130_5;

$L__BB130_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB130_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB130_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 32;
mov.u32 %r42, 1;
@%p7 bra $L__BB130_10;

mov.u32 %r30, 32;
div.u32 %r42, %r30, %r43;

$L__BB130_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, -1;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB130_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB130_14;

mov.u32 %r38, 31;

$L__BB130_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB130_13;

$L__BB130_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB130_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB130_16:
ret;

}

.visible .entry _Z7reduce7IfLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB131_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB131_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB131_2;

$L__BB131_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB131_6;

mov.u32 %r21, 31;
mov.u32 %r22, 65535;
mov.u32 %r41, %r43;

$L__BB131_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB131_5;

$L__BB131_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB131_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB131_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 16;
mov.u32 %r42, 1;
@%p7 bra $L__BB131_10;

mov.u32 %r30, 16;
div.u32 %r42, %r30, %r43;

$L__BB131_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 65535;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB131_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB131_14;

mov.u32 %r38, 31;

$L__BB131_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB131_13;

$L__BB131_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB131_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB131_16:
ret;

}

.visible .entry _Z7reduce7IfLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB132_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB132_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB132_2;

$L__BB132_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB132_6;

mov.u32 %r21, 31;
mov.u32 %r22, 255;
mov.u32 %r41, %r43;

$L__BB132_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB132_5;

$L__BB132_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB132_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB132_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 8;
mov.u32 %r42, 1;
@%p7 bra $L__BB132_10;

mov.u32 %r30, 8;
div.u32 %r42, %r30, %r43;

$L__BB132_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 255;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB132_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB132_14;

mov.u32 %r38, 31;

$L__BB132_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB132_13;

$L__BB132_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB132_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB132_16:
ret;

}

.visible .entry _Z7reduce7IfLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB133_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB133_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB133_2;

$L__BB133_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB133_6;

mov.u32 %r21, 31;
mov.u32 %r22, 15;
mov.u32 %r41, %r43;

$L__BB133_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB133_5;

$L__BB133_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB133_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB133_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 4;
mov.u32 %r42, 1;
@%p7 bra $L__BB133_10;

mov.u32 %r30, 4;
div.u32 %r42, %r30, %r43;

$L__BB133_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 15;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB133_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB133_14;

mov.u32 %r38, 31;

$L__BB133_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB133_13;

$L__BB133_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB133_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB133_16:
ret;

}

.visible .entry _Z7reduce7IfLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r16, %r2;
setp.ge.u32 %p1, %r40, %r15;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB134_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB134_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p2, %r40, %r15;
@%p2 bra $L__BB134_2;

$L__BB134_3:
mov.u32 %r43, WARP_SZ;
setp.lt.s32 %p3, %r43, 2;
@%p3 bra $L__BB134_6;

mov.u32 %r21, 31;
mov.u32 %r22, 3;
mov.u32 %r41, %r43;

$L__BB134_5:
mov.b32 %r18, %f19;
shr.u32 %r19, %r41, 31;
add.s32 %r20, %r41, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r23|%p4, %r18, %r9, %r21, %r22;
mov.b32 %f14, %r23;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r41, 3;
mov.u32 %r41, %r9;
@%p5 bra $L__BB134_5;

$L__BB134_6:
rem.u32 %r24, %r2, %r43;
setp.ne.s32 %p6, %r24, 0;
@%p6 bra $L__BB134_8;

div.u32 %r25, %r2, %r43;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

$L__BB134_8:
bar.sync 0;
setp.gt.u32 %p7, %r43, 2;
mov.u32 %r42, 1;
@%p7 bra $L__BB134_10;

mov.u32 %r30, 2;
div.u32 %r42, %r30, %r43;

$L__BB134_10:
setp.ge.u32 %p8, %r2, %r42;
setp.lt.u32 %p9, %r2, %r42;
mov.u32 %r31, 3;
vote.sync.ballot.b32 %r12, %p9, %r31;
@%p8 bra $L__BB134_14;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.f32 %f19, [%r34];
@%p3 bra $L__BB134_14;

mov.u32 %r38, 31;

$L__BB134_13:
mov.b32 %r35, %f19;
shr.u32 %r36, %r43, 31;
add.s32 %r37, %r43, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r39|%p12, %r35, %r14, %r38, %r12;
mov.b32 %f15, %r39;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r43, 3;
mov.u32 %r43, %r14;
@%p13 bra $L__BB134_13;

$L__BB134_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra $L__BB134_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB134_16:
ret;

}

.visible .entry _Z7reduce7IfLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<14>;
.reg .f32 %f<22>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r13, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r31, %r1, %r2;
setp.ge.u32 %p1, %r31, %r13;
mov.f32 %f19, 0f00000000;
@%p1 bra $L__BB135_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB135_2:
mul.wide.u32 %rd4, %r31, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r31, %r31, %r4;
setp.lt.u32 %p2, %r31, %r13;
@%p2 bra $L__BB135_2;

$L__BB135_3:
mov.u32 %r33, WARP_SZ;
setp.lt.s32 %p3, %r33, 2;
@%p3 bra $L__BB135_6;

mov.u32 %r17, 31;
mov.u32 %r18, 1;
mov.u32 %r32, %r33;

$L__BB135_5:
mov.b32 %r14, %f19;
shr.u32 %r15, %r32, 31;
add.s32 %r16, %r32, %r15;
shr.s32 %r9, %r16, 1;
shfl.sync.down.b32 %r19|%p4, %r14, %r9, %r17, %r18;
mov.b32 %f14, %r19;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p5, %r32, 3;
mov.u32 %r32, %r9;
@%p5 bra $L__BB135_5;

$L__BB135_6:
rem.u32 %r20, %r2, %r33;
setp.ne.s32 %p6, %r20, 0;
@%p6 bra $L__BB135_8;

div.u32 %r21, %r2, %r33;
shl.b32 %r22, %r21, 2;
mov.u32 %r23, __smem;
add.s32 %r24, %r23, %r22;
st.shared.f32 [%r24], %f19;

$L__BB135_8:
bar.sync 0;
setp.ne.s32 %p7, %r2, 0;
setp.eq.s32 %p8, %r2, 0;
mov.u32 %r25, 1;
vote.sync.ballot.b32 %r10, %p8, %r25;
@%p7 bra $L__BB135_12;

ld.shared.f32 %f19, [__smem];
@%p3 bra $L__BB135_12;

mov.u32 %r29, 31;

$L__BB135_11:
mov.b32 %r26, %f19;
shr.u32 %r27, %r33, 31;
add.s32 %r28, %r33, %r27;
shr.s32 %r12, %r28, 1;
shfl.sync.down.b32 %r30|%p11, %r26, %r12, %r29, %r10;
mov.b32 %f15, %r30;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p12, %r33, 3;
mov.u32 %r33, %r12;
@%p12 bra $L__BB135_11;

$L__BB135_12:
@%p7 bra $L__BB135_14;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

$L__BB135_14:
ret;

}

.visible .entry _Z9cg_reduceIfEvPT_S1_j(
.param .u64 _Z9cg_reduceIfEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIfEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIfEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<46>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIfEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIfEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z9cg_reduceIfEvPT_S1_j_param_2];
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r1, %r14, %r15, %r16;
mul.lo.s32 %r17, %r15, %r11;
mov.u32 %r18, %ntid.z;
mul.lo.s32 %r45, %r17, %r18;
mov.u32 %r19, %ctaid.x;
mad.lo.s32 %r44, %r45, %r19, %r1;
setp.ge.u32 %p1, %r44, %r10;
mov.f32 %f26, 0f00000000;
@%p1 bra $L__BB136_3;

mov.u32 %r20, %nctaid.x;
mul.lo.s32 %r4, %r45, %r20;
cvta.to.global.u64 %rd1, %rd2;

$L__BB136_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f26, %f26, %f12;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r10;
@%p2 bra $L__BB136_2;

$L__BB136_3:
shl.b32 %r21, %r1, 2;
mov.u32 %r22, __smem;
add.s32 %r7, %r22, %r21;
st.shared.f32 [%r7], %f26;
setp.lt.u32 %p3, %r45, 64;
@%p3 bra $L__BB136_8;

$L__BB136_5:
barrier.sync 0;
shr.u32 %r9, %r45, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra $L__BB136_7;

shl.b32 %r23, %r9, 2;
add.s32 %r24, %r7, %r23;
ld.shared.f32 %f13, [%r24];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r7], %f26;

$L__BB136_7:
setp.gt.u32 %p5, %r45, 127;
mov.u32 %r45, %r9;
@%p5 bra $L__BB136_5;

$L__BB136_8:
barrier.sync 0;
and.b32 %r25, %r1, 2097120;
setp.ne.s32 %p6, %r25, 0;
@%p6 bra $L__BB136_10;

mov.b32 %r26, %f26;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.bfly.b32 %r30|%p7, %r26, %r28, %r27, %r29;
mov.b32 %f14, %r30;
add.f32 %f15, %f26, %f14;
mov.b32 %r31, %f15;
mov.u32 %r32, 8;
shfl.sync.bfly.b32 %r33|%p8, %r31, %r32, %r27, %r29;
mov.b32 %f16, %r33;
add.f32 %f17, %f15, %f16;
mov.b32 %r34, %f17;
mov.u32 %r35, 4;
shfl.sync.bfly.b32 %r36|%p9, %r34, %r35, %r27, %r29;
mov.b32 %f18, %r36;
add.f32 %f19, %f17, %f18;
mov.b32 %r37, %f19;
mov.u32 %r38, 2;
shfl.sync.bfly.b32 %r39|%p10, %r37, %r38, %r27, %r29;
mov.b32 %f20, %r39;
add.f32 %f21, %f19, %f20;
mov.b32 %r40, %f21;
mov.u32 %r41, 1;
shfl.sync.bfly.b32 %r42|%p11, %r40, %r41, %r27, %r29;
mov.b32 %f22, %r42;
add.f32 %f26, %f21, %f22;

$L__BB136_10:
setp.ne.s32 %p12, %r1, 0;
@%p12 bra $L__BB136_12;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r19, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

$L__BB136_12:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<30>;
.reg .f32 %f<68>;
.reg .b32 %r<143>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch[160];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB137_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB137_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f62, 0f00000000;
@%p2 bra $L__BB137_6;

shl.b32 %r47, %r6, 10;
add.s32 %r134, %r47, %r3;
setp.ge.u32 %p3, %r134, %r37;
@%p3 bra $L__BB137_11;

shl.b32 %r8, %r5, 10;

$L__BB137_5:
mul.wide.u32 %rd5, %r134, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f62, %f62, %f18;
add.s32 %r134, %r134, %r8;
setp.lt.u32 %p4, %r134, %r37;
@%p4 bra $L__BB137_5;
bra.uni $L__BB137_11;

$L__BB137_6:
shl.b32 %r48, %r6, 11;
add.s32 %r135, %r48, %r3;
setp.ge.u32 %p5, %r135, %r37;
@%p5 bra $L__BB137_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 11;

$L__BB137_8:
cvt.u64.u32 %rd7, %r135;
mul.wide.u32 %rd8, %r135, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f62, %f62, %f21;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB137_10;

add.s32 %r49, %r135, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f62, %f62, %f22;

$L__BB137_10:
add.s32 %r135, %r135, %r12;
setp.lt.u32 %p7, %r135, %r37;
@%p7 bra $L__BB137_8;

$L__BB137_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f62;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f62, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r69, %r51;
shr.u32 %r18, %r4, 9;
shl.b32 %r71, %r18, 4;
mov.u32 %r72, 65535;
shl.b32 %r19, %r72, %r71;
bar.warp.sync -1;
mov.u32 %r136, %r50;
@%p13 bra $L__BB137_13;

add.s32 %r74, %r54, 12;
atom.shared.or.b32 %r136, [%r74], %r17;

$L__BB137_13:
shfl.sync.idx.b32 %r78|%p14, %r136, %r50, %r56, %r58;
or.b32 %r79, %r78, %r17;
and.b32 %r80, %r79, %r19;
setp.eq.s32 %p15, %r80, %r19;
@%p15 bra $L__BB137_16;
bra.uni $L__BB137_15;

$L__BB137_16:
and.b32 %r83, %r4, 16;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra $L__BB137_18;

and.b32 %r88, %r4, 15;
and.b32 %r89, %r4, -512;
shr.u32 %r90, %r89, 5;
or.b32 %r91, %r90, %r88;
shl.b32 %r92, %r91, 2;
add.s32 %r95, %r54, %r92;
ld.shared.f32 %f33, [%r95+32];

	mov.u32 %r84, %laneid;

	and.b32 %r96, %r84, -16;
shl.b32 %r98, %r72, %r96;
mov.b32 %r99, %f33;
mov.u32 %r100, 4127;
shfl.sync.bfly.b32 %r102|%p18, %r99, %r61, %r100, %r98;
mov.b32 %f34, %r102;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r103, %r85, -16;
shl.b32 %r104, %r72, %r103;
mov.b32 %r105, %f35;
shfl.sync.bfly.b32 %r107|%p19, %r105, %r64, %r100, %r104;
mov.b32 %f36, %r107;
add.f32 %f37, %f35, %f36;

	mov.u32 %r86, %laneid;

	and.b32 %r108, %r86, -16;
shl.b32 %r109, %r72, %r108;
mov.b32 %r110, %f37;
shfl.sync.bfly.b32 %r111|%p20, %r110, %r53, %r100, %r109;
mov.b32 %f38, %r111;
add.f32 %f39, %f37, %f38;

	mov.u32 %r87, %laneid;

	and.b32 %r112, %r87, -16;
shl.b32 %r113, %r72, %r112;
mov.b32 %r114, %f39;
shfl.sync.bfly.b32 %r116|%p21, %r114, %r69, %r100, %r113;
mov.b32 %f40, %r116;
add.f32 %f41, %f39, %f40;
st.shared.f32 [%r95+32], %f41;

$L__BB137_18:
bar.warp.sync -1;
@%p13 bra $L__BB137_20;

not.b32 %r117, %r19;
add.s32 %r119, %r54, 12;
atom.shared.and.b32 %r120, [%r119], %r117;
bra.uni $L__BB137_20;

$L__BB137_15:
ld.volatile.shared.u32 %r81, [_ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch+12];
and.b32 %r82, %r81, %r17;
setp.eq.s32 %p16, %r82, 0;
@%p16 bra $L__BB137_20;
bra.uni $L__BB137_15;

$L__BB137_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r121, %r4, 511;
setp.ne.s32 %p23, %r121, 0;
@%p23 bra $L__BB137_22;

shl.b32 %r122, %r18, 2;
mov.u32 %r123, __smem;
add.s32 %r124, %r123, %r122;
st.shared.f32 [%r124], %f8;

$L__BB137_22:
barrier.sync 0;
setp.ne.s32 %p24, %r3, 0;
@%p24 bra $L__BB137_31;

mul.lo.s32 %r125, %r2, %r1;
mov.u32 %r126, %ntid.z;
mad.lo.s32 %r127, %r125, %r126, 511;
shr.u32 %r22, %r127, 9;
setp.eq.s32 %p25, %r22, 0;
mov.f32 %f67, 0f00000000;
@%p25 bra $L__BB137_30;

add.s32 %r129, %r22, -1;
and.b32 %r142, %r22, 3;
setp.lt.u32 %p26, %r129, 3;
mov.f32 %f67, 0f00000000;
mov.u32 %r140, 0;
@%p26 bra $L__BB137_27;

sub.s32 %r139, %r22, %r142;
mov.u32 %r137, __smem;

$L__BB137_26:
ld.shared.v4.f32 {%f46, %f47, %f48, %f49}, [%r137];
add.f32 %f54, %f67, %f46;
add.f32 %f55, %f54, %f47;
add.f32 %f56, %f55, %f48;
add.f32 %f67, %f56, %f49;
add.s32 %r140, %r140, 4;
add.s32 %r137, %r137, 16;
add.s32 %r139, %r139, -4;
setp.ne.s32 %p27, %r139, 0;
@%p27 bra $L__BB137_26;

$L__BB137_27:
setp.eq.s32 %p28, %r142, 0;
@%p28 bra $L__BB137_30;

shl.b32 %r132, %r140, 2;
mov.u32 %r133, __smem;
add.s32 %r141, %r133, %r132;

$L__BB137_29:
.pragma "nounroll";
ld.shared.f32 %f57, [%r141];
add.f32 %f67, %f67, %f57;
add.s32 %r141, %r141, 4;
add.s32 %r142, %r142, -1;
setp.ne.s32 %p29, %r142, 0;
@%p29 bra $L__BB137_29;

$L__BB137_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f67;

$L__BB137_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<29>;
.reg .f32 %f<66>;
.reg .b32 %r<137>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch[96];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB138_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB138_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f60, 0f00000000;
@%p2 bra $L__BB138_6;

shl.b32 %r47, %r6, 9;
add.s32 %r128, %r47, %r3;
setp.ge.u32 %p3, %r128, %r37;
@%p3 bra $L__BB138_11;

shl.b32 %r8, %r5, 9;

$L__BB138_5:
mul.wide.u32 %rd5, %r128, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f60, %f60, %f18;
add.s32 %r128, %r128, %r8;
setp.lt.u32 %p4, %r128, %r37;
@%p4 bra $L__BB138_5;
bra.uni $L__BB138_11;

$L__BB138_6:
shl.b32 %r48, %r6, 10;
add.s32 %r129, %r48, %r3;
setp.ge.u32 %p5, %r129, %r37;
@%p5 bra $L__BB138_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 10;

$L__BB138_8:
cvt.u64.u32 %rd7, %r129;
mul.wide.u32 %rd8, %r129, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f60, %f60, %f21;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB138_10;

add.s32 %r49, %r129, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f60, %f60, %f22;

$L__BB138_10:
add.s32 %r129, %r129, %r12;
setp.lt.u32 %p7, %r129, %r37;
@%p7 bra $L__BB138_8;

$L__BB138_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f60;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f60, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r69, %r51;
shr.u32 %r18, %r4, 8;
shl.b32 %r71, %r18, 3;
mov.u32 %r72, 255;
shl.b32 %r19, %r72, %r71;
bar.warp.sync -1;
mov.u32 %r130, %r50;
@%p13 bra $L__BB138_13;

add.s32 %r74, %r54, 8;
atom.shared.or.b32 %r130, [%r74], %r17;

$L__BB138_13:
shfl.sync.idx.b32 %r78|%p14, %r130, %r50, %r56, %r58;
or.b32 %r79, %r78, %r17;
and.b32 %r80, %r79, %r19;
setp.eq.s32 %p15, %r80, %r19;
@%p15 bra $L__BB138_16;
bra.uni $L__BB138_15;

$L__BB138_16:
and.b32 %r83, %r4, 24;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra $L__BB138_18;

and.b32 %r87, %r4, 7;
and.b32 %r88, %r4, -256;
shr.u32 %r89, %r88, 5;
or.b32 %r90, %r89, %r87;
shl.b32 %r91, %r90, 2;
add.s32 %r94, %r54, %r91;
ld.shared.f32 %f33, [%r94+32];

	mov.u32 %r84, %laneid;

	and.b32 %r95, %r84, -8;
shl.b32 %r97, %r72, %r95;
mov.b32 %r98, %f33;
mov.u32 %r99, 6175;
shfl.sync.bfly.b32 %r101|%p18, %r98, %r64, %r99, %r97;
mov.b32 %f34, %r101;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r102, %r85, -8;
shl.b32 %r103, %r72, %r102;
mov.b32 %r104, %f35;
shfl.sync.bfly.b32 %r105|%p19, %r104, %r53, %r99, %r103;
mov.b32 %f36, %r105;
add.f32 %f37, %f35, %f36;

	mov.u32 %r86, %laneid;

	and.b32 %r106, %r86, -8;
shl.b32 %r107, %r72, %r106;
mov.b32 %r108, %f37;
shfl.sync.bfly.b32 %r110|%p20, %r108, %r69, %r99, %r107;
mov.b32 %f38, %r110;
add.f32 %f39, %f37, %f38;
st.shared.f32 [%r94+32], %f39;

$L__BB138_18:
bar.warp.sync -1;
@%p13 bra $L__BB138_20;

not.b32 %r111, %r19;
add.s32 %r113, %r54, 8;
atom.shared.and.b32 %r114, [%r113], %r111;
bra.uni $L__BB138_20;

$L__BB138_15:
ld.volatile.shared.u32 %r81, [_ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch+8];
and.b32 %r82, %r81, %r17;
setp.eq.s32 %p16, %r82, 0;
@%p16 bra $L__BB138_20;
bra.uni $L__BB138_15;

$L__BB138_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r115, %r4, 255;
setp.ne.s32 %p22, %r115, 0;
@%p22 bra $L__BB138_22;

shl.b32 %r116, %r18, 2;
mov.u32 %r117, __smem;
add.s32 %r118, %r117, %r116;
st.shared.f32 [%r118], %f8;

$L__BB138_22:
barrier.sync 0;
setp.ne.s32 %p23, %r3, 0;
@%p23 bra $L__BB138_31;

mul.lo.s32 %r119, %r2, %r1;
mov.u32 %r120, %ntid.z;
mad.lo.s32 %r121, %r119, %r120, 255;
shr.u32 %r22, %r121, 8;
setp.eq.s32 %p24, %r22, 0;
mov.f32 %f65, 0f00000000;
@%p24 bra $L__BB138_30;

add.s32 %r123, %r22, -1;
and.b32 %r136, %r22, 3;
setp.lt.u32 %p25, %r123, 3;
mov.f32 %f65, 0f00000000;
mov.u32 %r134, 0;
@%p25 bra $L__BB138_27;

sub.s32 %r133, %r22, %r136;
mov.u32 %r131, __smem;

$L__BB138_26:
ld.shared.v4.f32 {%f44, %f45, %f46, %f47}, [%r131];
add.f32 %f52, %f65, %f44;
add.f32 %f53, %f52, %f45;
add.f32 %f54, %f53, %f46;
add.f32 %f65, %f54, %f47;
add.s32 %r134, %r134, 4;
add.s32 %r131, %r131, 16;
add.s32 %r133, %r133, -4;
setp.ne.s32 %p26, %r133, 0;
@%p26 bra $L__BB138_26;

$L__BB138_27:
setp.eq.s32 %p27, %r136, 0;
@%p27 bra $L__BB138_30;

shl.b32 %r126, %r134, 2;
mov.u32 %r127, __smem;
add.s32 %r135, %r127, %r126;

$L__BB138_29:
.pragma "nounroll";
ld.shared.f32 %f55, [%r135];
add.f32 %f65, %f65, %f55;
add.s32 %r135, %r135, 4;
add.s32 %r136, %r136, -1;
setp.ne.s32 %p28, %r136, 0;
@%p28 bra $L__BB138_29;

$L__BB138_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f65;

$L__BB138_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<28>;
.reg .f32 %f<64>;
.reg .b32 %r<131>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB139_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB139_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f58, 0f00000000;
@%p2 bra $L__BB139_6;

shl.b32 %r47, %r6, 8;
add.s32 %r122, %r47, %r3;
setp.ge.u32 %p3, %r122, %r37;
@%p3 bra $L__BB139_11;

shl.b32 %r8, %r5, 8;

$L__BB139_5:
mul.wide.u32 %rd5, %r122, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f58, %f58, %f18;
add.s32 %r122, %r122, %r8;
setp.lt.u32 %p4, %r122, %r37;
@%p4 bra $L__BB139_5;
bra.uni $L__BB139_11;

$L__BB139_6:
shl.b32 %r48, %r6, 9;
add.s32 %r123, %r48, %r3;
setp.ge.u32 %p5, %r123, %r37;
@%p5 bra $L__BB139_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 9;

$L__BB139_8:
cvt.u64.u32 %rd7, %r123;
mul.wide.u32 %rd8, %r123, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f58, %f58, %f21;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB139_10;

add.s32 %r49, %r123, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f58, %f58, %f22;

$L__BB139_10:
add.s32 %r123, %r123, %r12;
setp.lt.u32 %p7, %r123, %r37;
@%p7 bra $L__BB139_8;

$L__BB139_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f58;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f58, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r69, %r51;
shr.u32 %r18, %r4, 7;
shl.b32 %r71, %r18, 2;
mov.u32 %r72, 15;
shl.b32 %r19, %r72, %r71;
bar.warp.sync -1;
mov.u32 %r124, %r50;
@%p13 bra $L__BB139_13;

add.s32 %r74, %r54, 4;
atom.shared.or.b32 %r124, [%r74], %r17;

$L__BB139_13:
shfl.sync.idx.b32 %r78|%p14, %r124, %r50, %r56, %r58;
or.b32 %r79, %r78, %r17;
and.b32 %r80, %r79, %r19;
setp.eq.s32 %p15, %r80, %r19;
@%p15 bra $L__BB139_16;
bra.uni $L__BB139_15;

$L__BB139_16:
and.b32 %r83, %r4, 28;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra $L__BB139_18;

and.b32 %r86, %r4, 3;
and.b32 %r87, %r4, -128;
shr.u32 %r88, %r87, 5;
or.b32 %r89, %r88, %r86;
shl.b32 %r90, %r89, 2;
add.s32 %r93, %r54, %r90;
ld.shared.f32 %f33, [%r93+32];

	mov.u32 %r84, %laneid;

	and.b32 %r94, %r84, -4;
shl.b32 %r96, %r72, %r94;
mov.b32 %r97, %f33;
mov.u32 %r98, 7199;
shfl.sync.bfly.b32 %r99|%p18, %r97, %r53, %r98, %r96;
mov.b32 %f34, %r99;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r100, %r85, -4;
shl.b32 %r101, %r72, %r100;
mov.b32 %r102, %f35;
shfl.sync.bfly.b32 %r104|%p19, %r102, %r69, %r98, %r101;
mov.b32 %f36, %r104;
add.f32 %f37, %f35, %f36;
st.shared.f32 [%r93+32], %f37;

$L__BB139_18:
bar.warp.sync -1;
@%p13 bra $L__BB139_20;

not.b32 %r105, %r19;
add.s32 %r107, %r54, 4;
atom.shared.and.b32 %r108, [%r107], %r105;
bra.uni $L__BB139_20;

$L__BB139_15:
ld.volatile.shared.u32 %r81, [_ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch+4];
and.b32 %r82, %r81, %r17;
setp.eq.s32 %p16, %r82, 0;
@%p16 bra $L__BB139_20;
bra.uni $L__BB139_15;

$L__BB139_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r109, %r4, 127;
setp.ne.s32 %p21, %r109, 0;
@%p21 bra $L__BB139_22;

mov.u32 %r111, __smem;
add.s32 %r112, %r111, %r71;
st.shared.f32 [%r112], %f8;

$L__BB139_22:
barrier.sync 0;
setp.ne.s32 %p22, %r3, 0;
@%p22 bra $L__BB139_31;

mul.lo.s32 %r113, %r2, %r1;
mov.u32 %r114, %ntid.z;
mad.lo.s32 %r115, %r113, %r114, 127;
shr.u32 %r22, %r115, 7;
setp.eq.s32 %p23, %r22, 0;
mov.f32 %f63, 0f00000000;
@%p23 bra $L__BB139_30;

add.s32 %r117, %r22, -1;
and.b32 %r130, %r22, 3;
setp.lt.u32 %p24, %r117, 3;
mov.f32 %f63, 0f00000000;
mov.u32 %r128, 0;
@%p24 bra $L__BB139_27;

sub.s32 %r127, %r22, %r130;
mov.u32 %r125, __smem;

$L__BB139_26:
ld.shared.v4.f32 {%f42, %f43, %f44, %f45}, [%r125];
add.f32 %f50, %f63, %f42;
add.f32 %f51, %f50, %f43;
add.f32 %f52, %f51, %f44;
add.f32 %f63, %f52, %f45;
add.s32 %r128, %r128, 4;
add.s32 %r125, %r125, 16;
add.s32 %r127, %r127, -4;
setp.ne.s32 %p25, %r127, 0;
@%p25 bra $L__BB139_26;

$L__BB139_27:
setp.eq.s32 %p26, %r130, 0;
@%p26 bra $L__BB139_30;

shl.b32 %r120, %r128, 2;
mov.u32 %r121, __smem;
add.s32 %r129, %r121, %r120;

$L__BB139_29:
.pragma "nounroll";
ld.shared.f32 %f53, [%r129];
add.f32 %f63, %f63, %f53;
add.s32 %r129, %r129, 4;
add.s32 %r130, %r130, -1;
setp.ne.s32 %p27, %r130, 0;
@%p27 bra $L__BB139_29;

$L__BB139_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f63;

$L__BB139_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<27>;
.reg .f32 %f<62>;
.reg .b32 %r<123>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch[48];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB140_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

$L__BB140_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
mov.f32 %f56, 0f00000000;
@%p2 bra $L__BB140_6;

shl.b32 %r47, %r6, 7;
add.s32 %r114, %r47, %r3;
setp.ge.u32 %p3, %r114, %r37;
@%p3 bra $L__BB140_11;

shl.b32 %r8, %r5, 7;

$L__BB140_5:
mul.wide.u32 %rd5, %r114, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f56, %f56, %f18;
add.s32 %r114, %r114, %r8;
setp.lt.u32 %p4, %r114, %r37;
@%p4 bra $L__BB140_5;
bra.uni $L__BB140_11;

$L__BB140_6:
shl.b32 %r48, %r6, 8;
add.s32 %r115, %r48, %r3;
setp.ge.u32 %p5, %r115, %r37;
@%p5 bra $L__BB140_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 8;

$L__BB140_8:
cvt.u64.u32 %rd7, %r115;
mul.wide.u32 %rd8, %r115, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f56, %f56, %f21;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB140_10;

add.s32 %r49, %r115, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f56, %f56, %f22;

$L__BB140_10:
add.s32 %r115, %r115, %r12;
setp.lt.u32 %p7, %r115, %r37;
@%p7 bra $L__BB140_8;

$L__BB140_11:
shr.u32 %r51, %r4, 5;
shl.b32 %r52, %r51, 2;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r15, %r54, %r52;
mov.b32 %r55, %f56;
mov.u32 %r56, 3;
mov.u32 %r57, 31;
mov.u32 %r58, 16;
mov.u32 %r59, -1;
shfl.sync.bfly.b32 %r60|%p8, %r55, %r58, %r57, %r59;
mov.b32 %f23, %r60;
add.f32 %f24, %f56, %f23;
mov.b32 %r61, %f24;
mov.u32 %r62, 8;
shfl.sync.bfly.b32 %r63|%p9, %r61, %r62, %r57, %r59;
mov.b32 %f25, %r63;
add.f32 %f26, %f24, %f25;
mov.b32 %r64, %f26;
mov.u32 %r65, 4;
shfl.sync.bfly.b32 %r66|%p10, %r64, %r65, %r57, %r59;
mov.b32 %f27, %r66;
add.f32 %f28, %f26, %f27;
mov.b32 %r67, %f28;
shfl.sync.bfly.b32 %r68|%p11, %r67, %r53, %r57, %r59;
mov.b32 %f29, %r68;
add.f32 %f30, %f28, %f29;
mov.b32 %r69, %f30;
mov.u32 %r70, 1;
shfl.sync.bfly.b32 %r71|%p12, %r69, %r70, %r57, %r59;
mov.b32 %f31, %r71;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r15+32], %f32;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p13, %r16, 0;
shl.b32 %r17, %r70, %r51;
shr.u32 %r18, %r4, 6;
shl.b32 %r72, %r18, 1;
shl.b32 %r19, %r56, %r72;
bar.warp.sync -1;
mov.u32 %r116, %r50;
@%p13 bra $L__BB140_13;

atom.shared.or.b32 %r116, [%r54], %r17;

$L__BB140_13:
shfl.sync.idx.b32 %r77|%p14, %r116, %r50, %r57, %r59;
or.b32 %r78, %r77, %r17;
and.b32 %r79, %r78, %r19;
setp.eq.s32 %p15, %r79, %r19;
@%p15 bra $L__BB140_16;
bra.uni $L__BB140_15;

$L__BB140_16:
and.b32 %r82, %r4, 30;
setp.ne.s32 %p17, %r82, 0;
@%p17 bra $L__BB140_18;

and.b32 %r84, %r4, 1;
and.b32 %r86, %r4, -64;
shr.u32 %r87, %r86, 5;
or.b32 %r88, %r87, %r84;
shl.b32 %r89, %r88, 2;
add.s32 %r91, %r54, %r89;
ld.shared.f32 %f33, [%r91+32];

	mov.u32 %r83, %laneid;

	and.b32 %r92, %r83, -2;
shl.b32 %r94, %r56, %r92;
mov.b32 %r95, %f33;
mov.u32 %r96, 7711;
shfl.sync.bfly.b32 %r97|%p18, %r95, %r70, %r96, %r94;
mov.b32 %f34, %r97;
add.f32 %f35, %f33, %f34;
st.shared.f32 [%r91+32], %f35;

$L__BB140_18:
bar.warp.sync -1;
@%p13 bra $L__BB140_20;

not.b32 %r98, %r19;
atom.shared.and.b32 %r100, [%r54], %r98;
bra.uni $L__BB140_20;

$L__BB140_15:
ld.volatile.shared.u32 %r80, [_ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch];
and.b32 %r81, %r80, %r17;
setp.eq.s32 %p16, %r81, 0;
@%p16 bra $L__BB140_20;
bra.uni $L__BB140_15;

$L__BB140_20:
ld.shared.f32 %f8, [%r15+32];
bar.warp.sync -1;
and.b32 %r101, %r4, 63;
setp.ne.s32 %p20, %r101, 0;
@%p20 bra $L__BB140_22;

shl.b32 %r102, %r18, 2;
mov.u32 %r103, __smem;
add.s32 %r104, %r103, %r102;
st.shared.f32 [%r104], %f8;

$L__BB140_22:
barrier.sync 0;
setp.ne.s32 %p21, %r3, 0;
@%p21 bra $L__BB140_31;

mul.lo.s32 %r105, %r2, %r1;
mov.u32 %r106, %ntid.z;
mad.lo.s32 %r107, %r105, %r106, 63;
shr.u32 %r22, %r107, 6;
setp.eq.s32 %p22, %r22, 0;
mov.f32 %f61, 0f00000000;
@%p22 bra $L__BB140_30;

add.s32 %r109, %r22, -1;
and.b32 %r122, %r22, 3;
setp.lt.u32 %p23, %r109, 3;
mov.f32 %f61, 0f00000000;
mov.u32 %r120, 0;
@%p23 bra $L__BB140_27;

sub.s32 %r119, %r22, %r122;
mov.u32 %r117, __smem;

$L__BB140_26:
ld.shared.v4.f32 {%f40, %f41, %f42, %f43}, [%r117];
add.f32 %f48, %f61, %f40;
add.f32 %f49, %f48, %f41;
add.f32 %f50, %f49, %f42;
add.f32 %f61, %f50, %f43;
add.s32 %r120, %r120, 4;
add.s32 %r117, %r117, 16;
add.s32 %r119, %r119, -4;
setp.ne.s32 %p24, %r119, 0;
@%p24 bra $L__BB140_26;

$L__BB140_27:
setp.eq.s32 %p25, %r122, 0;
@%p25 bra $L__BB140_30;

shl.b32 %r112, %r120, 2;
mov.u32 %r113, __smem;
add.s32 %r121, %r113, %r112;

$L__BB140_29:
.pragma "nounroll";
ld.shared.f32 %f51, [%r121];
add.f32 %f61, %f61, %f51;
add.s32 %r121, %r121, 4;
add.s32 %r122, %r122, -1;
setp.ne.s32 %p26, %r122, 0;
@%p26 bra $L__BB140_29;

$L__BB140_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f61;

$L__BB140_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<19>;
.reg .f32 %f<58>;
.reg .b32 %r<81>;
.reg .b64 %rd<16>;


ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r29, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r30, %ntid.y;
mov.u32 %r31, %tid.z;
mov.u32 %r32, %tid.y;
mad.lo.s32 %r33, %r30, %r31, %r32;
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %tid.x;
mad.lo.s32 %r3, %r33, %r1, %r2;
barrier.sync 0;
mov.u32 %r4, %nctaid.x;
add.s32 %r34, %r29, -1;
and.b32 %r35, %r34, %r29;
setp.eq.s32 %p1, %r35, 0;
mov.u32 %r5, %ctaid.x;
mov.f32 %f52, 0f00000000;
@%p1 bra $L__BB141_4;

shl.b32 %r36, %r5, 6;
add.s32 %r73, %r36, %r2;
setp.ge.u32 %p2, %r73, %r29;
@%p2 bra $L__BB141_9;

shl.b32 %r7, %r4, 6;

$L__BB141_3:
mul.wide.u32 %rd5, %r73, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f52, %f52, %f18;
add.s32 %r73, %r73, %r7;
setp.lt.u32 %p3, %r73, %r29;
@%p3 bra $L__BB141_3;
bra.uni $L__BB141_9;

$L__BB141_4:
shl.b32 %r37, %r5, 7;
add.s32 %r74, %r37, %r2;
setp.ge.u32 %p4, %r74, %r29;
@%p4 bra $L__BB141_9;

cvt.u64.u32 %rd2, %r29;
shl.b32 %r11, %r4, 7;

$L__BB141_6:
cvt.u64.u32 %rd7, %r74;
mul.wide.u32 %rd8, %r74, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f52, %f52, %f21;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p5, %rd10, %rd2;
@%p5 bra $L__BB141_8;

add.s32 %r38, %r74, %r1;
mul.wide.u32 %rd11, %r38, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f52, %f52, %f22;

$L__BB141_8:
add.s32 %r74, %r74, %r11;
setp.lt.u32 %p6, %r74, %r29;
@%p6 bra $L__BB141_6;

$L__BB141_9:
mov.b32 %r39, %f52;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.bfly.b32 %r43|%p7, %r39, %r41, %r40, %r42;
mov.b32 %f23, %r43;
add.f32 %f24, %f52, %f23;
mov.b32 %r44, %f24;
mov.u32 %r45, 8;
shfl.sync.bfly.b32 %r46|%p8, %r44, %r45, %r40, %r42;
mov.b32 %f25, %r46;
add.f32 %f26, %f24, %f25;
mov.b32 %r47, %f26;
mov.u32 %r48, 4;
shfl.sync.bfly.b32 %r49|%p9, %r47, %r48, %r40, %r42;
mov.b32 %f27, %r49;
add.f32 %f28, %f26, %f27;
mov.b32 %r50, %f28;
mov.u32 %r51, 2;
shfl.sync.bfly.b32 %r52|%p10, %r50, %r51, %r40, %r42;
mov.b32 %f29, %r52;
add.f32 %f30, %f28, %f29;
mov.b32 %r53, %f30;
mov.u32 %r54, 1;
shfl.sync.bfly.b32 %r55|%p11, %r53, %r54, %r40, %r42;
mov.b32 %f31, %r55;
add.f32 %f8, %f30, %f31;
and.b32 %r56, %r3, 31;
setp.ne.s32 %p12, %r56, 0;
@%p12 bra $L__BB141_11;

shr.u32 %r57, %r3, 3;
and.b32 %r58, %r57, 536870908;
mov.u32 %r59, __smem;
add.s32 %r60, %r59, %r58;
st.shared.f32 [%r60], %f8;

$L__BB141_11:
barrier.sync 0;
setp.ne.s32 %p13, %r2, 0;
@%p13 bra $L__BB141_20;

mul.lo.s32 %r63, %r1, %r30;
mov.u32 %r64, %ntid.z;
mad.lo.s32 %r65, %r63, %r64, 31;
shr.u32 %r14, %r65, 5;
setp.eq.s32 %p14, %r14, 0;
mov.f32 %f57, 0f00000000;
@%p14 bra $L__BB141_19;

add.s32 %r67, %r14, -1;
and.b32 %r80, %r14, 3;
setp.lt.u32 %p15, %r67, 3;
mov.f32 %f57, 0f00000000;
mov.u32 %r78, 0;
@%p15 bra $L__BB141_16;

sub.s32 %r77, %r14, %r80;
mov.u32 %r75, __smem;

$L__BB141_15:
ld.shared.v4.f32 {%f36, %f37, %f38, %f39}, [%r75];
add.f32 %f44, %f57, %f36;
add.f32 %f45, %f44, %f37;
add.f32 %f46, %f45, %f38;
add.f32 %f57, %f46, %f39;
add.s32 %r78, %r78, 4;
add.s32 %r75, %r75, 16;
add.s32 %r77, %r77, -4;
setp.ne.s32 %p16, %r77, 0;
@%p16 bra $L__BB141_15;

$L__BB141_16:
setp.eq.s32 %p17, %r80, 0;
@%p17 bra $L__BB141_19;

shl.b32 %r70, %r78, 2;
mov.u32 %r71, __smem;
add.s32 %r79, %r71, %r70;

$L__BB141_18:
.pragma "nounroll";
ld.shared.f32 %f47, [%r79];
add.f32 %f57, %f57, %f47;
add.s32 %r79, %r79, 4;
add.s32 %r80, %r80, -1;
setp.ne.s32 %p18, %r80, 0;
@%p18 bra $L__BB141_18;

$L__BB141_19:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r5, 4;
add.s64 %rd15, %rd13, %rd14;
st.global.f32 [%rd15], %f57;

$L__BB141_20:
ret;

}

.visible .entry _Z7reduce0IdEvPT_S1_j(
.param .u64 _Z7reduce0IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<16>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IdEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce0IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra $L__BB142_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

$L__BB142_2:
shl.b32 %r9, %r3, 3;
mov.u32 %r10, __smem_d;
add.s32 %r5, %r10, %r9;
st.shared.f64 [%r5], %fd8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB142_7;

mov.u32 %r15, 1;

$L__BB142_4:
shl.b32 %r7, %r15, 1;
rem.u32 %r12, %r3, %r7;
setp.ne.s32 %p3, %r12, 0;
@%p3 bra $L__BB142_6;

shl.b32 %r13, %r15, 3;
add.s32 %r14, %r5, %r13;
ld.shared.f64 %fd4, [%r5];
ld.shared.f64 %fd5, [%r14];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r5], %fd6;

$L__BB142_6:
barrier.sync 0;
setp.lt.u32 %p4, %r7, %r1;
mov.u32 %r15, %r7;
@%p4 bra $L__BB142_4;

$L__BB142_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB142_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

$L__BB142_9:
ret;

}

.visible .entry _Z7reduce1IdEvPT_S1_j(
.param .u64 _Z7reduce1IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<20>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IdEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce1IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra $L__BB143_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

$L__BB143_2:
shl.b32 %r9, %r3, 3;
mov.u32 %r10, __smem_d;
add.s32 %r11, %r10, %r9;
st.shared.f64 [%r11], %fd8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra $L__BB143_7;

mov.u32 %r19, 1;

$L__BB143_4:
shl.b32 %r6, %r19, 1;
mul.lo.s32 %r7, %r6, %r3;
setp.ge.u32 %p3, %r7, %r1;
@%p3 bra $L__BB143_6;

add.s32 %r13, %r7, %r19;
shl.b32 %r14, %r13, 3;
add.s32 %r16, %r10, %r14;
shl.b32 %r17, %r7, 3;
add.s32 %r18, %r10, %r17;
ld.shared.f64 %fd4, [%r18];
ld.shared.f64 %fd5, [%r16];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r18], %fd6;

$L__BB143_6:
barrier.sync 0;
setp.lt.u32 %p4, %r6, %r1;
mov.u32 %r19, %r6;
@%p4 bra $L__BB143_4;

$L__BB143_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB143_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

$L__BB143_9:
ret;

}

.visible .entry _Z7reduce2IdEvPT_S1_j(
.param .u64 _Z7reduce2IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce2IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce2IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<15>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce2IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce2IdEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce2IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r9;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra $L__BB144_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

$L__BB144_2:
shl.b32 %r10, %r3, 3;
mov.u32 %r11, __smem_d;
add.s32 %r5, %r11, %r10;
st.shared.f64 [%r5], %fd8;
barrier.sync 0;
shr.u32 %r14, %r1, 1;
setp.eq.s32 %p2, %r14, 0;
@%p2 bra $L__BB144_7;

$L__BB144_4:
setp.ge.u32 %p3, %r3, %r14;
@%p3 bra $L__BB144_6;

shl.b32 %r12, %r14, 3;
add.s32 %r13, %r5, %r12;
ld.shared.f64 %fd4, [%r5];
ld.shared.f64 %fd5, [%r13];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r5], %fd6;

$L__BB144_6:
barrier.sync 0;
shr.u32 %r14, %r14, 1;
setp.ne.s32 %p4, %r14, 0;
@%p4 bra $L__BB144_4;

$L__BB144_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra $L__BB144_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

$L__BB144_9:
ret;

}

.visible .entry _Z7reduce3IdEvPT_S1_j(
.param .u64 _Z7reduce3IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IdEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .b32 %r<17>;
.reg .f64 %fd<17>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IdEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce3IdEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
mov.f64 %fd15, 0d0000000000000000;
@%p1 bra $L__BB145_2;

mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd15, [%rd5];

$L__BB145_2:
add.s32 %r5, %r4, %r1;
setp.ge.u32 %p2, %r5, %r10;
@%p2 bra $L__BB145_4;

mul.wide.u32 %rd6, %r5, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd10, [%rd7];
add.f64 %fd15, %fd15, %fd10;

$L__BB145_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r6, %r13, %r12;
st.shared.f64 [%r6], %fd15;
barrier.sync 0;
shr.u32 %r16, %r1, 1;
setp.eq.s32 %p3, %r16, 0;
@%p3 bra $L__BB145_9;

$L__BB145_6:
setp.ge.u32 %p4, %r3, %r16;
@%p4 bra $L__BB145_8;

shl.b32 %r14, %r16, 3;
add.s32 %r15, %r6, %r14;
ld.shared.f64 %fd11, [%r15];
add.f64 %fd15, %fd15, %fd11;
st.shared.f64 [%r6], %fd15;

$L__BB145_8:
barrier.sync 0;
shr.u32 %r16, %r16, 1;
setp.ne.s32 %p5, %r16, 0;
@%p5 bra $L__BB145_6;

$L__BB145_9:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra $L__BB145_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd15;

$L__BB145_11:
ret;

}

.visible .entry _Z7reduce4IdLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj512EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB146_2;

ld.global.f64 %fd28, [%rd1];

$L__BB146_2:
add.s32 %r11, %r4, 512;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB146_4;

ld.global.f64 %fd12, [%rd1+4096];
add.f64 %fd28, %fd28, %fd12;

$L__BB146_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB146_9;

mov.u32 %r47, %r1;

$L__BB146_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB146_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB146_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB146_6;

$L__BB146_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB146_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB146_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB146_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB146_13:
ret;

}

.visible .entry _Z7reduce4IdLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj256EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB147_2;

ld.global.f64 %fd28, [%rd1];

$L__BB147_2:
add.s32 %r11, %r4, 256;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB147_4;

ld.global.f64 %fd12, [%rd1+2048];
add.f64 %fd28, %fd28, %fd12;

$L__BB147_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB147_9;

mov.u32 %r47, %r1;

$L__BB147_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB147_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB147_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB147_6;

$L__BB147_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB147_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB147_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB147_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB147_13:
ret;

}

.visible .entry _Z7reduce4IdLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj128EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB148_2;

ld.global.f64 %fd28, [%rd1];

$L__BB148_2:
add.s32 %r11, %r4, 128;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB148_4;

ld.global.f64 %fd12, [%rd1+1024];
add.f64 %fd28, %fd28, %fd12;

$L__BB148_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB148_9;

mov.u32 %r47, %r1;

$L__BB148_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB148_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB148_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB148_6;

$L__BB148_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB148_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB148_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB148_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB148_13:
ret;

}

.visible .entry _Z7reduce4IdLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj64EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra $L__BB149_2;

ld.global.f64 %fd28, [%rd1];

$L__BB149_2:
add.s32 %r11, %r4, 64;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB149_4;

ld.global.f64 %fd12, [%rd1+512];
add.f64 %fd28, %fd28, %fd12;

$L__BB149_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB149_9;

mov.u32 %r47, %r1;

$L__BB149_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB149_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

$L__BB149_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB149_6;

$L__BB149_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB149_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

$L__BB149_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB149_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

$L__BB149_13:
ret;

}

.visible .entry _Z7reduce4IdLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj32EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB150_2;

ld.global.f64 %fd27, [%rd1];

$L__BB150_2:
add.s32 %r11, %r4, 32;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB150_4;

ld.global.f64 %fd12, [%rd1+256];
add.f64 %fd27, %fd27, %fd12;

$L__BB150_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB150_9;

mov.u32 %r47, %r1;

$L__BB150_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB150_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB150_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB150_6;

$L__BB150_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB150_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB150_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB150_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB150_13:
ret;

}

.visible .entry _Z7reduce4IdLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj16EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB151_2;

ld.global.f64 %fd27, [%rd1];

$L__BB151_2:
add.s32 %r11, %r4, 16;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB151_4;

ld.global.f64 %fd12, [%rd1+128];
add.f64 %fd27, %fd27, %fd12;

$L__BB151_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB151_9;

mov.u32 %r47, %r1;

$L__BB151_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB151_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB151_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB151_6;

$L__BB151_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB151_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB151_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB151_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB151_13:
ret;

}

.visible .entry _Z7reduce4IdLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj8EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB152_2;

ld.global.f64 %fd27, [%rd1];

$L__BB152_2:
add.s32 %r11, %r4, 8;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB152_4;

ld.global.f64 %fd12, [%rd1+64];
add.f64 %fd27, %fd27, %fd12;

$L__BB152_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB152_9;

mov.u32 %r47, %r1;

$L__BB152_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB152_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB152_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB152_6;

$L__BB152_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB152_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB152_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB152_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB152_13:
ret;

}

.visible .entry _Z7reduce4IdLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj4EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB153_2;

ld.global.f64 %fd27, [%rd1];

$L__BB153_2:
add.s32 %r11, %r4, 4;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB153_4;

ld.global.f64 %fd12, [%rd1+32];
add.f64 %fd27, %fd27, %fd12;

$L__BB153_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB153_9;

mov.u32 %r47, %r1;

$L__BB153_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB153_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB153_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB153_6;

$L__BB153_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB153_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB153_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB153_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB153_13:
ret;

}

.visible .entry _Z7reduce4IdLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj2EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB154_2;

ld.global.f64 %fd27, [%rd1];

$L__BB154_2:
add.s32 %r11, %r4, 2;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB154_4;

ld.global.f64 %fd12, [%rd1+16];
add.f64 %fd27, %fd27, %fd12;

$L__BB154_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB154_9;

mov.u32 %r47, %r1;

$L__BB154_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB154_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB154_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB154_6;

$L__BB154_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB154_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB154_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB154_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB154_13:
ret;

}

.visible .entry _Z7reduce4IdLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB155_2;

ld.global.f64 %fd27, [%rd1];

$L__BB155_2:
add.s32 %r11, %r4, 1;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra $L__BB155_4;

ld.global.f64 %fd12, [%rd1+8];
add.f64 %fd27, %fd27, %fd12;

$L__BB155_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra $L__BB155_9;

mov.u32 %r47, %r1;

$L__BB155_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra $L__BB155_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

$L__BB155_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra $L__BB155_6;

$L__BB155_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB155_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

$L__BB155_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB155_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB155_13:
ret;

}

.visible .entry _Z7reduce5IdLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<43>;
.reg .f64 %fd<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj512EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd30, 0d0000000000000000;
@%p1 bra $L__BB156_2;

ld.global.f64 %fd30, [%rd1];

$L__BB156_2:
add.s32 %r8, %r3, 512;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB156_4;

ld.global.f64 %fd14, [%rd1+4096];
add.f64 %fd30, %fd30, %fd14;

$L__BB156_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB156_6;

ld.shared.f64 %fd15, [%r4+2048];
add.f64 %fd30, %fd30, %fd15;
st.shared.f64 [%r4], %fd30;

$L__BB156_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB156_8;

ld.shared.f64 %fd16, [%r4+1024];
add.f64 %fd30, %fd30, %fd16;
st.shared.f64 [%r4], %fd30;

$L__BB156_8:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB156_10;

ld.shared.f64 %fd17, [%r4+512];
add.f64 %fd30, %fd30, %fd17;
st.shared.f64 [%r4], %fd30;

$L__BB156_10:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p6, %r5, 31;
@%p6 bra $L__BB156_12;

ld.shared.f64 %fd28, [%r4+256];
add.f64 %fd18, %fd30, %fd28;

	mov.b64 {%r16,%r17}, %fd18;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p7, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p8, %r16, %r38, %r37, %r39;

	mov.b64 %fd19, {%r18,%r19};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r20,%r21}, %fd20;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p9, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p10, %r20, %r40, %r37, %r39;

	mov.b64 %fd21, {%r22,%r23};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r24,%r25}, %fd22;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p11, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p12, %r24, %r41, %r37, %r39;

	mov.b64 %fd23, {%r26,%r27};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r28,%r29}, %fd24;

	shfl.sync.down.b32 %r31|%p13, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p14, %r28, %r36, %r37, %r39;

	mov.b64 %fd25, {%r30,%r31};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r32,%r33}, %fd26;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p15, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p16, %r32, %r42, %r37, %r39;

	mov.b64 %fd27, {%r34,%r35};

	add.f64 %fd30, %fd26, %fd27;

$L__BB156_12:
setp.ne.s32 %p17, %r5, 0;
@%p17 bra $L__BB156_14;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd30;

$L__BB156_14:
ret;

}

.visible .entry _Z7reduce5IdLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<43>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj256EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB157_2;

ld.global.f64 %fd27, [%rd1];

$L__BB157_2:
add.s32 %r8, %r3, 256;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB157_4;

ld.global.f64 %fd12, [%rd1+2048];
add.f64 %fd27, %fd27, %fd12;

$L__BB157_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB157_6;

ld.shared.f64 %fd13, [%r4+1024];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r4], %fd27;

$L__BB157_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB157_8;

ld.shared.f64 %fd14, [%r4+512];
add.f64 %fd27, %fd27, %fd14;
st.shared.f64 [%r4], %fd27;

$L__BB157_8:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p5, %r5, 31;
@%p5 bra $L__BB157_10;

ld.shared.f64 %fd25, [%r4+256];
add.f64 %fd15, %fd27, %fd25;

	mov.b64 {%r16,%r17}, %fd15;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p6, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p7, %r16, %r38, %r37, %r39;

	mov.b64 %fd16, {%r18,%r19};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r20,%r21}, %fd17;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p8, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p9, %r20, %r40, %r37, %r39;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r24,%r25}, %fd19;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p10, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p11, %r24, %r41, %r37, %r39;

	mov.b64 %fd20, {%r26,%r27};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r28,%r29}, %fd21;

	shfl.sync.down.b32 %r31|%p12, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p13, %r28, %r36, %r37, %r39;

	mov.b64 %fd22, {%r30,%r31};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r32,%r33}, %fd23;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p14, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p15, %r32, %r42, %r37, %r39;

	mov.b64 %fd24, {%r34,%r35};

	add.f64 %fd27, %fd23, %fd24;

$L__BB157_10:
setp.ne.s32 %p16, %r5, 0;
@%p16 bra $L__BB157_12;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB157_12:
ret;

}

.visible .entry _Z7reduce5IdLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<43>;
.reg .f64 %fd<27>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj128EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd24, 0d0000000000000000;
@%p1 bra $L__BB158_2;

ld.global.f64 %fd24, [%rd1];

$L__BB158_2:
add.s32 %r8, %r3, 128;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB158_4;

ld.global.f64 %fd10, [%rd1+1024];
add.f64 %fd24, %fd24, %fd10;

$L__BB158_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB158_6;

ld.shared.f64 %fd11, [%r4+512];
add.f64 %fd24, %fd24, %fd11;
st.shared.f64 [%r4], %fd24;

$L__BB158_6:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p4, %r5, 31;
@%p4 bra $L__BB158_8;

ld.shared.f64 %fd22, [%r4+256];
add.f64 %fd12, %fd24, %fd22;

	mov.b64 {%r16,%r17}, %fd12;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p5, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p6, %r16, %r38, %r37, %r39;

	mov.b64 %fd13, {%r18,%r19};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p7, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p8, %r20, %r40, %r37, %r39;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p9, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p10, %r24, %r41, %r37, %r39;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	shfl.sync.down.b32 %r31|%p11, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p12, %r28, %r36, %r37, %r39;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p13, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p14, %r32, %r42, %r37, %r39;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd24, %fd20, %fd21;

$L__BB158_8:
setp.ne.s32 %p15, %r5, 0;
@%p15 bra $L__BB158_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd24;

$L__BB158_10:
ret;

}

.visible .entry _Z7reduce5IdLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj64EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB159_2;

ld.global.f64 %fd21, [%rd1];

$L__BB159_2:
add.s32 %r8, %r3, 64;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra $L__BB159_4;

ld.global.f64 %fd8, [%rd1+512];
add.f64 %fd21, %fd21, %fd8;

$L__BB159_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p3, %r5, 31;
@%p3 bra $L__BB159_6;

ld.shared.f64 %fd19, [%r4+256];
add.f64 %fd9, %fd21, %fd19;

	mov.b64 {%r16,%r17}, %fd9;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd9, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd21, %fd17, %fd18;

$L__BB159_6:
setp.ne.s32 %p14, %r5, 0;
@%p14 bra $L__BB159_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB159_8:
ret;

}

.visible .entry _Z7reduce5IdLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj32EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB160_2;

ld.global.f64 %fd20, [%rd1];

$L__BB160_2:
add.s32 %r7, %r3, 32;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB160_4;

ld.global.f64 %fd8, [%rd1+256];
add.f64 %fd20, %fd20, %fd8;

$L__BB160_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB160_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB160_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB160_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB160_8:
ret;

}

.visible .entry _Z7reduce5IdLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj16EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB161_2;

ld.global.f64 %fd20, [%rd1];

$L__BB161_2:
add.s32 %r7, %r3, 16;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB161_4;

ld.global.f64 %fd8, [%rd1+128];
add.f64 %fd20, %fd20, %fd8;

$L__BB161_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB161_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB161_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB161_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB161_8:
ret;

}

.visible .entry _Z7reduce5IdLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj8EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB162_2;

ld.global.f64 %fd20, [%rd1];

$L__BB162_2:
add.s32 %r7, %r3, 8;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB162_4;

ld.global.f64 %fd8, [%rd1+64];
add.f64 %fd20, %fd20, %fd8;

$L__BB162_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB162_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB162_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB162_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB162_8:
ret;

}

.visible .entry _Z7reduce5IdLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj4EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB163_2;

ld.global.f64 %fd20, [%rd1];

$L__BB163_2:
add.s32 %r7, %r3, 4;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB163_4;

ld.global.f64 %fd8, [%rd1+32];
add.f64 %fd20, %fd20, %fd8;

$L__BB163_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB163_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB163_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB163_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB163_8:
ret;

}

.visible .entry _Z7reduce5IdLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj2EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB164_2;

ld.global.f64 %fd20, [%rd1];

$L__BB164_2:
add.s32 %r7, %r3, 2;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB164_4;

ld.global.f64 %fd8, [%rd1+16];
add.f64 %fd20, %fd20, %fd8;

$L__BB164_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB164_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB164_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB164_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB164_8:
ret;

}

.visible .entry _Z7reduce5IdLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj1EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB165_2;

ld.global.f64 %fd20, [%rd1];

$L__BB165_2:
add.s32 %r7, %r3, 1;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra $L__BB165_4;

ld.global.f64 %fd8, [%rd1+8];
add.f64 %fd20, %fd20, %fd8;

$L__BB165_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra $L__BB165_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

$L__BB165_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra $L__BB165_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB165_8:
ret;

}

.visible .entry _Z7reduce6IdLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<19>;
.reg .b32 %r<48>;
.reg .f64 %fd<39>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd32, 0d0000000000000000;
@%p1 bra $L__BB166_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 10;

$L__BB166_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd16, [%rd5];
add.f64 %fd32, %fd32, %fd16;
add.s32 %r6, %r47, 512;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB166_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd17, [%rd7];
add.f64 %fd32, %fd32, %fd17;

$L__BB166_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB166_2;

$L__BB166_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd32;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 255;
@%p4 bra $L__BB166_7;

ld.shared.f64 %fd18, [%r8+2048];
add.f64 %fd32, %fd32, %fd18;
st.shared.f64 [%r8], %fd32;

$L__BB166_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 127;
@%p5 bra $L__BB166_9;

ld.shared.f64 %fd19, [%r8+1024];
add.f64 %fd32, %fd32, %fd19;
st.shared.f64 [%r8], %fd32;

$L__BB166_9:
barrier.sync 0;
setp.gt.u32 %p6, %r2, 63;
@%p6 bra $L__BB166_11;

ld.shared.f64 %fd20, [%r8+512];
add.f64 %fd32, %fd32, %fd20;
st.shared.f64 [%r8], %fd32;

$L__BB166_11:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p7, %r9, 31;
@%p7 bra $L__BB166_13;

ld.shared.f64 %fd31, [%r8+256];
add.f64 %fd21, %fd32, %fd31;

	mov.b64 {%r20,%r21}, %fd21;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p8, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p9, %r20, %r42, %r41, %r43;

	mov.b64 %fd22, {%r22,%r23};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r24,%r25}, %fd23;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p10, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p11, %r24, %r44, %r41, %r43;

	mov.b64 %fd24, {%r26,%r27};

	add.f64 %fd25, %fd23, %fd24;

	mov.b64 {%r28,%r29}, %fd25;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p12, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p13, %r28, %r45, %r41, %r43;

	mov.b64 %fd26, {%r30,%r31};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r32,%r33}, %fd27;

	shfl.sync.down.b32 %r35|%p14, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p15, %r32, %r40, %r41, %r43;

	mov.b64 %fd28, {%r34,%r35};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r36,%r37}, %fd29;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p16, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p17, %r36, %r46, %r41, %r43;

	mov.b64 %fd30, {%r38,%r39};

	add.f64 %fd32, %fd29, %fd30;

$L__BB166_13:
setp.ne.s32 %p18, %r9, 0;
@%p18 bra $L__BB166_15;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd32;

$L__BB166_15:
ret;

}

.visible .entry _Z7reduce6IdLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<35>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd29, 0d0000000000000000;
@%p1 bra $L__BB167_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 9;

$L__BB167_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd14, [%rd5];
add.f64 %fd29, %fd29, %fd14;
add.s32 %r6, %r47, 256;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB167_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd15, [%rd7];
add.f64 %fd29, %fd29, %fd15;

$L__BB167_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB167_2;

$L__BB167_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd29;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB167_7;

ld.shared.f64 %fd16, [%r8+1024];
add.f64 %fd29, %fd29, %fd16;
st.shared.f64 [%r8], %fd29;

$L__BB167_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB167_9;

ld.shared.f64 %fd17, [%r8+512];
add.f64 %fd29, %fd29, %fd17;
st.shared.f64 [%r8], %fd29;

$L__BB167_9:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra $L__BB167_11;

ld.shared.f64 %fd28, [%r8+256];
add.f64 %fd18, %fd29, %fd28;

	mov.b64 {%r20,%r21}, %fd18;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd19, {%r22,%r23};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r24,%r25}, %fd20;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd21, {%r26,%r27};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r28,%r29}, %fd22;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd23, {%r30,%r31};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r32,%r33}, %fd24;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd25, {%r34,%r35};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r36,%r37}, %fd26;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd27, {%r38,%r39};

	add.f64 %fd29, %fd26, %fd27;

$L__BB167_11:
setp.ne.s32 %p17, %r9, 0;
@%p17 bra $L__BB167_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd29;

$L__BB167_13:
ret;

}

.visible .entry _Z7reduce6IdLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd26, 0d0000000000000000;
@%p1 bra $L__BB168_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 8;

$L__BB168_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd26, %fd26, %fd12;
add.s32 %r6, %r47, 128;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB168_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd13, [%rd7];
add.f64 %fd26, %fd26, %fd13;

$L__BB168_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB168_2;

$L__BB168_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd26;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB168_7;

ld.shared.f64 %fd14, [%r8+512];
add.f64 %fd26, %fd26, %fd14;
st.shared.f64 [%r8], %fd26;

$L__BB168_7:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p5, %r9, 31;
@%p5 bra $L__BB168_9;

ld.shared.f64 %fd25, [%r8+256];
add.f64 %fd15, %fd26, %fd25;

	mov.b64 {%r20,%r21}, %fd15;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p6, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p7, %r20, %r42, %r41, %r43;

	mov.b64 %fd16, {%r22,%r23};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r24,%r25}, %fd17;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p8, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p9, %r24, %r44, %r41, %r43;

	mov.b64 %fd18, {%r26,%r27};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r28,%r29}, %fd19;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p10, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p11, %r28, %r45, %r41, %r43;

	mov.b64 %fd20, {%r30,%r31};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r32,%r33}, %fd21;

	shfl.sync.down.b32 %r35|%p12, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p13, %r32, %r40, %r41, %r43;

	mov.b64 %fd22, {%r34,%r35};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r36,%r37}, %fd23;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p14, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p15, %r36, %r46, %r41, %r43;

	mov.b64 %fd24, {%r38,%r39};

	add.f64 %fd26, %fd23, %fd24;

$L__BB168_9:
setp.ne.s32 %p16, %r9, 0;
@%p16 bra $L__BB168_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd26;

$L__BB168_11:
ret;

}

.visible .entry _Z7reduce6IdLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<27>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd23, 0d0000000000000000;
@%p1 bra $L__BB169_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 7;

$L__BB169_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd23, %fd23, %fd10;
add.s32 %r6, %r47, 64;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra $L__BB169_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd23, %fd23, %fd11;

$L__BB169_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra $L__BB169_2;

$L__BB169_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd23;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p4, %r9, 31;
@%p4 bra $L__BB169_7;

ld.shared.f64 %fd22, [%r8+256];
add.f64 %fd12, %fd23, %fd22;

	mov.b64 {%r20,%r21}, %fd12;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd23, %fd20, %fd21;

$L__BB169_7:
setp.ne.s32 %p15, %r9, 0;
@%p15 bra $L__BB169_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd23;

$L__BB169_9:
ret;

}

.visible .entry _Z7reduce6IdLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB170_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;

$L__BB170_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 32;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB170_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB170_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB170_2;

$L__BB170_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB170_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB170_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB170_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB170_9:
ret;

}

.visible .entry _Z7reduce6IdLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB171_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 5;

$L__BB171_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 16;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB171_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB171_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB171_2;

$L__BB171_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB171_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB171_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB171_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB171_9:
ret;

}

.visible .entry _Z7reduce6IdLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB172_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 4;

$L__BB172_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 8;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB172_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB172_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB172_2;

$L__BB172_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB172_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB172_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB172_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB172_9:
ret;

}

.visible .entry _Z7reduce6IdLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB173_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 3;

$L__BB173_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 4;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB173_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB173_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB173_2;

$L__BB173_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB173_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB173_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB173_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB173_9:
ret;

}

.visible .entry _Z7reduce6IdLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB174_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 2;

$L__BB174_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 2;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB174_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB174_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB174_2;

$L__BB174_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB174_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB174_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB174_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB174_9:
ret;

}

.visible .entry _Z7reduce6IdLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra $L__BB175_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 1;

$L__BB175_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 1;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra $L__BB175_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

$L__BB175_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra $L__BB175_2;

$L__BB175_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB175_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

$L__BB175_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB175_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

$L__BB175_9:
ret;

}

.visible .entry _Z7reduce6IdLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<47>;
.reg .f64 %fd<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd30, 0d0000000000000000;
@%p1 bra $L__BB176_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB176_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd14, [%rd5];
add.f64 %fd30, %fd30, %fd14;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB176_2;

$L__BB176_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra $L__BB176_5;

ld.shared.f64 %fd15, [%r7+2048];
add.f64 %fd30, %fd30, %fd15;
st.shared.f64 [%r7], %fd30;

$L__BB176_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra $L__BB176_7;

ld.shared.f64 %fd16, [%r7+1024];
add.f64 %fd30, %fd30, %fd16;
st.shared.f64 [%r7], %fd30;

$L__BB176_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra $L__BB176_9;

ld.shared.f64 %fd17, [%r7+512];
add.f64 %fd30, %fd30, %fd17;
st.shared.f64 [%r7], %fd30;

$L__BB176_9:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra $L__BB176_11;

ld.shared.f64 %fd28, [%r7+256];
add.f64 %fd18, %fd30, %fd28;

	mov.b64 {%r19,%r20}, %fd18;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p7, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p8, %r19, %r41, %r40, %r42;

	mov.b64 %fd19, {%r21,%r22};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r23,%r24}, %fd20;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p9, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p10, %r23, %r43, %r40, %r42;

	mov.b64 %fd21, {%r25,%r26};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r27,%r28}, %fd22;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p11, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p12, %r27, %r44, %r40, %r42;

	mov.b64 %fd23, {%r29,%r30};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r31,%r32}, %fd24;

	shfl.sync.down.b32 %r34|%p13, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p14, %r31, %r39, %r40, %r42;

	mov.b64 %fd25, {%r33,%r34};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r35,%r36}, %fd26;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p15, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p16, %r35, %r45, %r40, %r42;

	mov.b64 %fd27, {%r37,%r38};

	add.f64 %fd30, %fd26, %fd27;

$L__BB176_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra $L__BB176_13;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd30;

$L__BB176_13:
ret;

}

.visible .entry _Z7reduce6IdLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<47>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB177_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB177_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd27, %fd27, %fd12;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB177_2;

$L__BB177_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra $L__BB177_5;

ld.shared.f64 %fd13, [%r7+1024];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r7], %fd27;

$L__BB177_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra $L__BB177_7;

ld.shared.f64 %fd14, [%r7+512];
add.f64 %fd27, %fd27, %fd14;
st.shared.f64 [%r7], %fd27;

$L__BB177_7:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p5, %r8, 31;
@%p5 bra $L__BB177_9;

ld.shared.f64 %fd25, [%r7+256];
add.f64 %fd15, %fd27, %fd25;

	mov.b64 {%r19,%r20}, %fd15;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p6, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p7, %r19, %r41, %r40, %r42;

	mov.b64 %fd16, {%r21,%r22};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r23,%r24}, %fd17;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p8, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p9, %r23, %r43, %r40, %r42;

	mov.b64 %fd18, {%r25,%r26};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r27,%r28}, %fd19;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p10, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p11, %r27, %r44, %r40, %r42;

	mov.b64 %fd20, {%r29,%r30};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r31,%r32}, %fd21;

	shfl.sync.down.b32 %r34|%p12, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p13, %r31, %r39, %r40, %r42;

	mov.b64 %fd22, {%r33,%r34};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r35,%r36}, %fd23;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p14, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p15, %r35, %r45, %r40, %r42;

	mov.b64 %fd24, {%r37,%r38};

	add.f64 %fd27, %fd23, %fd24;

$L__BB177_9:
setp.ne.s32 %p16, %r8, 0;
@%p16 bra $L__BB177_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB177_11:
ret;

}

.visible .entry _Z7reduce6IdLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<47>;
.reg .f64 %fd<27>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd24, 0d0000000000000000;
@%p1 bra $L__BB178_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB178_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd24, %fd24, %fd10;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB178_2;

$L__BB178_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra $L__BB178_5;

ld.shared.f64 %fd11, [%r7+512];
add.f64 %fd24, %fd24, %fd11;
st.shared.f64 [%r7], %fd24;

$L__BB178_5:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra $L__BB178_7;

ld.shared.f64 %fd22, [%r7+256];
add.f64 %fd12, %fd24, %fd22;

	mov.b64 {%r19,%r20}, %fd12;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p5, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p6, %r19, %r41, %r40, %r42;

	mov.b64 %fd13, {%r21,%r22};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r23,%r24}, %fd14;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p7, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p8, %r23, %r43, %r40, %r42;

	mov.b64 %fd15, {%r25,%r26};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r27,%r28}, %fd16;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p9, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p10, %r27, %r44, %r40, %r42;

	mov.b64 %fd17, {%r29,%r30};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r31,%r32}, %fd18;

	shfl.sync.down.b32 %r34|%p11, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p12, %r31, %r39, %r40, %r42;

	mov.b64 %fd19, {%r33,%r34};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r35,%r36}, %fd20;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p13, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p14, %r35, %r45, %r40, %r42;

	mov.b64 %fd21, {%r37,%r38};

	add.f64 %fd24, %fd20, %fd21;

$L__BB178_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra $L__BB178_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd24;

$L__BB178_9:
ret;

}

.visible .entry _Z7reduce6IdLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB179_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB179_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd21, %fd21, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra $L__BB179_2;

$L__BB179_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra $L__BB179_5;

ld.shared.f64 %fd19, [%r7+256];
add.f64 %fd9, %fd21, %fd19;

	mov.b64 {%r19,%r20}, %fd9;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd9, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd21, %fd17, %fd18;

$L__BB179_5:
setp.ne.s32 %p14, %r8, 0;
@%p14 bra $L__BB179_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB179_7:
ret;

}

.visible .entry _Z7reduce6IdLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB180_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB180_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB180_2;

$L__BB180_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB180_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB180_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB180_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB180_7:
ret;

}

.visible .entry _Z7reduce6IdLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB181_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB181_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB181_2;

$L__BB181_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB181_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB181_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB181_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB181_7:
ret;

}

.visible .entry _Z7reduce6IdLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB182_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB182_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB182_2;

$L__BB182_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB182_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB182_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB182_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB182_7:
ret;

}

.visible .entry _Z7reduce6IdLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB183_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB183_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB183_2;

$L__BB183_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB183_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB183_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB183_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB183_7:
ret;

}

.visible .entry _Z7reduce6IdLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB184_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB184_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra $L__BB184_2;

$L__BB184_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB184_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

$L__BB184_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB184_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB184_7:
ret;

}

.visible .entry _Z7reduce6IdLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<45>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r1, %r2;
setp.ge.u32 %p1, %r44, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra $L__BB185_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB185_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r8;
@%p2 bra $L__BB185_2;

$L__BB185_3:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r11, %r10, %r9;
st.shared.f64 [%r11], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r7, %r15, %r16, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra $L__BB185_5;


	mov.b64 {%r17,%r18}, %fd20;

	mov.u32 %r37, 2;
mov.u32 %r38, 31;
mov.u32 %r39, 16;
mov.u32 %r40, -1;
shfl.sync.down.b32 %r20|%p4, %r18, %r39, %r38, %r40;
shfl.sync.down.b32 %r19|%p5, %r17, %r39, %r38, %r40;

	mov.b64 %fd10, {%r19,%r20};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r21,%r22}, %fd11;

	mov.u32 %r41, 8;
shfl.sync.down.b32 %r24|%p6, %r22, %r41, %r38, %r40;
shfl.sync.down.b32 %r23|%p7, %r21, %r41, %r38, %r40;

	mov.b64 %fd12, {%r23,%r24};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r25,%r26}, %fd13;

	mov.u32 %r42, 4;
shfl.sync.down.b32 %r28|%p8, %r26, %r42, %r38, %r40;
shfl.sync.down.b32 %r27|%p9, %r25, %r42, %r38, %r40;

	mov.b64 %fd14, {%r27,%r28};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r29,%r30}, %fd15;

	shfl.sync.down.b32 %r32|%p10, %r30, %r37, %r38, %r40;
shfl.sync.down.b32 %r31|%p11, %r29, %r37, %r38, %r40;

	mov.b64 %fd16, {%r31,%r32};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r33,%r34}, %fd17;

	mov.u32 %r43, 1;
shfl.sync.down.b32 %r36|%p12, %r34, %r43, %r38, %r40;
shfl.sync.down.b32 %r35|%p13, %r33, %r43, %r38, %r40;

	mov.b64 %fd18, {%r35,%r36};

	add.f64 %fd20, %fd17, %fd18;

$L__BB185_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra $L__BB185_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

$L__BB185_7:
ret;

}

.visible .entry _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB186_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 11;

$L__BB186_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 1024;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB186_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB186_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB186_2;

$L__BB186_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB186_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB186_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB186_7;

$L__BB186_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB186_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB186_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 1024;
mov.u32 %r47, 1;
@%p9 bra $L__BB186_12;

mov.u32 %r33, 1024;
div.u32 %r47, %r33, %r48;

$L__BB186_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB186_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB186_16;

mov.u32 %r44, 31;

$L__BB186_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB186_15;

$L__BB186_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB186_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB186_18:
ret;

}

.visible .entry _Z7reduce7IdLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB187_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 10;

$L__BB187_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 512;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB187_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB187_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB187_2;

$L__BB187_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB187_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB187_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB187_7;

$L__BB187_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB187_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB187_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 512;
mov.u32 %r47, 1;
@%p9 bra $L__BB187_12;

mov.u32 %r33, 512;
div.u32 %r47, %r33, %r48;

$L__BB187_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB187_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB187_16;

mov.u32 %r44, 31;

$L__BB187_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB187_15;

$L__BB187_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB187_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB187_18:
ret;

}

.visible .entry _Z7reduce7IdLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB188_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 9;

$L__BB188_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 256;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB188_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB188_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB188_2;

$L__BB188_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB188_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB188_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB188_7;

$L__BB188_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB188_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB188_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 256;
mov.u32 %r47, 1;
@%p9 bra $L__BB188_12;

mov.u32 %r33, 256;
div.u32 %r47, %r33, %r48;

$L__BB188_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB188_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB188_16;

mov.u32 %r44, 31;

$L__BB188_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB188_15;

$L__BB188_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB188_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB188_18:
ret;

}

.visible .entry _Z7reduce7IdLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB189_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 8;

$L__BB189_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 128;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB189_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB189_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB189_2;

$L__BB189_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB189_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB189_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB189_7;

$L__BB189_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB189_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB189_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 128;
mov.u32 %r47, 1;
@%p9 bra $L__BB189_12;

mov.u32 %r33, 128;
div.u32 %r47, %r33, %r48;

$L__BB189_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB189_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB189_16;

mov.u32 %r44, 31;

$L__BB189_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB189_15;

$L__BB189_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB189_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB189_18:
ret;

}

.visible .entry _Z7reduce7IdLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB190_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 7;

$L__BB190_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 64;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB190_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB190_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB190_2;

$L__BB190_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB190_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB190_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB190_7;

$L__BB190_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB190_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB190_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 64;
mov.u32 %r47, 1;
@%p9 bra $L__BB190_12;

mov.u32 %r33, 64;
div.u32 %r47, %r33, %r48;

$L__BB190_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB190_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB190_16;

mov.u32 %r44, 31;

$L__BB190_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB190_15;

$L__BB190_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB190_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB190_18:
ret;

}

.visible .entry _Z7reduce7IdLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB191_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;

$L__BB191_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 32;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB191_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB191_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB191_2;

$L__BB191_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB191_8;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

$L__BB191_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB191_7;

$L__BB191_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB191_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB191_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 32;
mov.u32 %r47, 1;
@%p9 bra $L__BB191_12;

mov.u32 %r33, 32;
div.u32 %r47, %r33, %r48;

$L__BB191_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB191_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB191_16;

mov.u32 %r44, 31;

$L__BB191_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB191_15;

$L__BB191_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB191_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB191_18:
ret;

}

.visible .entry _Z7reduce7IdLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB192_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 5;

$L__BB192_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 16;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB192_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB192_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB192_2;

$L__BB192_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB192_8;

mov.u32 %r25, 31;
mov.u32 %r26, 65535;
mov.u32 %r46, %r48;

$L__BB192_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB192_7;

$L__BB192_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB192_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB192_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 16;
mov.u32 %r47, 1;
@%p9 bra $L__BB192_12;

mov.u32 %r33, 16;
div.u32 %r47, %r33, %r48;

$L__BB192_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 65535;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB192_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB192_16;

mov.u32 %r44, 31;

$L__BB192_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB192_15;

$L__BB192_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB192_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB192_18:
ret;

}

.visible .entry _Z7reduce7IdLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB193_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 4;

$L__BB193_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 8;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB193_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB193_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB193_2;

$L__BB193_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB193_8;

mov.u32 %r25, 31;
mov.u32 %r26, 255;
mov.u32 %r46, %r48;

$L__BB193_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB193_7;

$L__BB193_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB193_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB193_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 8;
mov.u32 %r47, 1;
@%p9 bra $L__BB193_12;

mov.u32 %r33, 8;
div.u32 %r47, %r33, %r48;

$L__BB193_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 255;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB193_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB193_16;

mov.u32 %r44, 31;

$L__BB193_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB193_15;

$L__BB193_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB193_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB193_18:
ret;

}

.visible .entry _Z7reduce7IdLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB194_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 3;

$L__BB194_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 4;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB194_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB194_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB194_2;

$L__BB194_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB194_8;

mov.u32 %r25, 31;
mov.u32 %r26, 15;
mov.u32 %r46, %r48;

$L__BB194_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB194_7;

$L__BB194_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB194_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB194_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 4;
mov.u32 %r47, 1;
@%p9 bra $L__BB194_12;

mov.u32 %r33, 4;
div.u32 %r47, %r33, %r48;

$L__BB194_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 15;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB194_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB194_16;

mov.u32 %r44, 31;

$L__BB194_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB194_15;

$L__BB194_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB194_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB194_18:
ret;

}

.visible .entry _Z7reduce7IdLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p1, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB195_5;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 2;

$L__BB195_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r45, 2;
setp.ge.u32 %p2, %r6, %r16;
@%p2 bra $L__BB195_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB195_4:
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra $L__BB195_2;

$L__BB195_5:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra $L__BB195_8;

mov.u32 %r25, 31;
mov.u32 %r26, 3;
mov.u32 %r46, %r48;

$L__BB195_7:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r10, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r10, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r25, %r26;

	mov.b64 %fd18, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r10;
@%p7 bra $L__BB195_7;

$L__BB195_8:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra $L__BB195_10;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

$L__BB195_10:
bar.sync 0;
setp.gt.u32 %p9, %r48, 2;
mov.u32 %r47, 1;
@%p9 bra $L__BB195_12;

mov.u32 %r33, 2;
div.u32 %r47, %r33, %r48;

$L__BB195_12:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 3;
vote.sync.ballot.b32 %r13, %p11, %r34;
@%p10 bra $L__BB195_16;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra $L__BB195_16;

mov.u32 %r44, 31;

$L__BB195_15:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p14, %r39, %r15, %r44, %r13;
shfl.sync.down.b32 %r40|%p15, %r38, %r15, %r44, %r13;

	mov.b64 %fd20, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r48, 3;
mov.u32 %r48, %r15;
@%p16 bra $L__BB195_15;

$L__BB195_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra $L__BB195_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB195_18:
ret;

}

.visible .entry _Z7reduce7IdLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<41>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r14, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r15, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r38, %r15, %r2;
setp.ge.u32 %p1, %r38, %r14;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB196_5;

mov.u32 %r16, %nctaid.x;
shl.b32 %r4, %r16, 1;

$L__BB196_2:
mul.wide.u32 %rd4, %r38, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r38, 1;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra $L__BB196_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

$L__BB196_4:
add.s32 %r38, %r38, %r4;
setp.lt.u32 %p3, %r38, %r14;
@%p3 bra $L__BB196_2;

$L__BB196_5:
mov.u32 %r40, WARP_SZ;
setp.lt.s32 %p4, %r40, 2;
@%p4 bra $L__BB196_8;

mov.u32 %r23, 31;
mov.u32 %r24, 1;
mov.u32 %r39, %r40;

$L__BB196_7:

	mov.b64 {%r17,%r18}, %fd21;

	shr.u32 %r21, %r39, 31;
add.s32 %r22, %r39, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r20|%p5, %r18, %r10, %r23, %r24;
shfl.sync.down.b32 %r19|%p6, %r17, %r10, %r23, %r24;

	mov.b64 %fd18, {%r19,%r20};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p7, %r39, 3;
mov.u32 %r39, %r10;
@%p7 bra $L__BB196_7;

$L__BB196_8:
rem.u32 %r25, %r2, %r40;
setp.ne.s32 %p8, %r25, 0;
@%p8 bra $L__BB196_10;

div.u32 %r26, %r2, %r40;
shl.b32 %r27, %r26, 3;
mov.u32 %r28, __smem_d;
add.s32 %r29, %r28, %r27;
st.shared.f64 [%r29], %fd21;

$L__BB196_10:
bar.sync 0;
setp.ne.s32 %p9, %r2, 0;
setp.eq.s32 %p10, %r2, 0;
mov.u32 %r30, 1;
vote.sync.ballot.b32 %r11, %p10, %r30;
@%p9 bra $L__BB196_14;

ld.shared.f64 %fd21, [__smem_d];
@%p4 bra $L__BB196_14;

mov.u32 %r37, 31;

$L__BB196_13:

	mov.b64 {%r31,%r32}, %fd21;

	shr.u32 %r35, %r40, 31;
add.s32 %r36, %r40, %r35;
shr.s32 %r13, %r36, 1;
shfl.sync.down.b32 %r34|%p13, %r32, %r13, %r37, %r11;
shfl.sync.down.b32 %r33|%p14, %r31, %r13, %r37, %r11;

	mov.b64 %fd20, {%r33,%r34};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p15, %r40, 3;
mov.u32 %r40, %r13;
@%p15 bra $L__BB196_13;

$L__BB196_14:
@%p9 bra $L__BB196_16;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

$L__BB196_16:
ret;

}

.visible .entry _Z7reduce7IdLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB197_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 9;
cvta.to.global.u64 %rd1, %rd2;

$L__BB197_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB197_2;

$L__BB197_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB197_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB197_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB197_5;

$L__BB197_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB197_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB197_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 512;
mov.u32 %r46, 1;
@%p8 bra $L__BB197_10;

mov.u32 %r32, 512;
div.u32 %r46, %r32, %r47;

$L__BB197_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB197_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB197_14;

mov.u32 %r43, 31;

$L__BB197_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB197_13;

$L__BB197_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB197_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB197_16:
ret;

}

.visible .entry _Z7reduce7IdLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB198_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 8;
cvta.to.global.u64 %rd1, %rd2;

$L__BB198_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB198_2;

$L__BB198_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB198_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB198_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB198_5;

$L__BB198_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB198_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB198_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 256;
mov.u32 %r46, 1;
@%p8 bra $L__BB198_10;

mov.u32 %r32, 256;
div.u32 %r46, %r32, %r47;

$L__BB198_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB198_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB198_14;

mov.u32 %r43, 31;

$L__BB198_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB198_13;

$L__BB198_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB198_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB198_16:
ret;

}

.visible .entry _Z7reduce7IdLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB199_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 7;
cvta.to.global.u64 %rd1, %rd2;

$L__BB199_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB199_2;

$L__BB199_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB199_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB199_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB199_5;

$L__BB199_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB199_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB199_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 128;
mov.u32 %r46, 1;
@%p8 bra $L__BB199_10;

mov.u32 %r32, 128;
div.u32 %r46, %r32, %r47;

$L__BB199_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB199_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB199_14;

mov.u32 %r43, 31;

$L__BB199_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB199_13;

$L__BB199_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB199_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB199_16:
ret;

}

.visible .entry _Z7reduce7IdLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB200_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 6;
cvta.to.global.u64 %rd1, %rd2;

$L__BB200_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB200_2;

$L__BB200_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB200_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB200_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB200_5;

$L__BB200_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB200_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB200_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 64;
mov.u32 %r46, 1;
@%p8 bra $L__BB200_10;

mov.u32 %r32, 64;
div.u32 %r46, %r32, %r47;

$L__BB200_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB200_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB200_14;

mov.u32 %r43, 31;

$L__BB200_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB200_13;

$L__BB200_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB200_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB200_16:
ret;

}

.visible .entry _Z7reduce7IdLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB201_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 5;
cvta.to.global.u64 %rd1, %rd2;

$L__BB201_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB201_2;

$L__BB201_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB201_6;

mov.u32 %r24, 31;
mov.u32 %r25, -1;
mov.u32 %r45, %r47;

$L__BB201_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB201_5;

$L__BB201_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB201_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB201_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 32;
mov.u32 %r46, 1;
@%p8 bra $L__BB201_10;

mov.u32 %r32, 32;
div.u32 %r46, %r32, %r47;

$L__BB201_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB201_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB201_14;

mov.u32 %r43, 31;

$L__BB201_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB201_13;

$L__BB201_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB201_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB201_16:
ret;

}

.visible .entry _Z7reduce7IdLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB202_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 4;
cvta.to.global.u64 %rd1, %rd2;

$L__BB202_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB202_2;

$L__BB202_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB202_6;

mov.u32 %r24, 31;
mov.u32 %r25, 65535;
mov.u32 %r45, %r47;

$L__BB202_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB202_5;

$L__BB202_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB202_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB202_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 16;
mov.u32 %r46, 1;
@%p8 bra $L__BB202_10;

mov.u32 %r32, 16;
div.u32 %r46, %r32, %r47;

$L__BB202_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 65535;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB202_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB202_14;

mov.u32 %r43, 31;

$L__BB202_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB202_13;

$L__BB202_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB202_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB202_16:
ret;

}

.visible .entry _Z7reduce7IdLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB203_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 3;
cvta.to.global.u64 %rd1, %rd2;

$L__BB203_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB203_2;

$L__BB203_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB203_6;

mov.u32 %r24, 31;
mov.u32 %r25, 255;
mov.u32 %r45, %r47;

$L__BB203_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB203_5;

$L__BB203_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB203_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB203_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 8;
mov.u32 %r46, 1;
@%p8 bra $L__BB203_10;

mov.u32 %r32, 8;
div.u32 %r46, %r32, %r47;

$L__BB203_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 255;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB203_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB203_14;

mov.u32 %r43, 31;

$L__BB203_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB203_13;

$L__BB203_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB203_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB203_16:
ret;

}

.visible .entry _Z7reduce7IdLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB204_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 2;
cvta.to.global.u64 %rd1, %rd2;

$L__BB204_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB204_2;

$L__BB204_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB204_6;

mov.u32 %r24, 31;
mov.u32 %r25, 15;
mov.u32 %r45, %r47;

$L__BB204_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB204_5;

$L__BB204_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB204_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB204_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 4;
mov.u32 %r46, 1;
@%p8 bra $L__BB204_10;

mov.u32 %r32, 4;
div.u32 %r46, %r32, %r47;

$L__BB204_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 15;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB204_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB204_14;

mov.u32 %r43, 31;

$L__BB204_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB204_13;

$L__BB204_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB204_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB204_16:
ret;

}

.visible .entry _Z7reduce7IdLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r16, %r2;
setp.ge.u32 %p1, %r44, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB205_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
cvta.to.global.u64 %rd1, %rd2;

$L__BB205_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r15;
@%p2 bra $L__BB205_2;

$L__BB205_3:
mov.u32 %r47, WARP_SZ;
setp.lt.s32 %p3, %r47, 2;
@%p3 bra $L__BB205_6;

mov.u32 %r24, 31;
mov.u32 %r25, 3;
mov.u32 %r45, %r47;

$L__BB205_5:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r45, 31;
add.s32 %r23, %r45, %r22;
shr.s32 %r9, %r23, 1;
shfl.sync.down.b32 %r21|%p4, %r19, %r9, %r24, %r25;
shfl.sync.down.b32 %r20|%p5, %r18, %r9, %r24, %r25;

	mov.b64 %fd15, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r45, 3;
mov.u32 %r45, %r9;
@%p6 bra $L__BB205_5;

$L__BB205_6:
rem.u32 %r26, %r2, %r47;
setp.ne.s32 %p7, %r26, 0;
@%p7 bra $L__BB205_8;

div.u32 %r27, %r2, %r47;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

$L__BB205_8:
bar.sync 0;
setp.gt.u32 %p8, %r47, 2;
mov.u32 %r46, 1;
@%p8 bra $L__BB205_10;

mov.u32 %r32, 2;
div.u32 %r46, %r32, %r47;

$L__BB205_10:
setp.ge.u32 %p9, %r2, %r46;
setp.lt.u32 %p10, %r2, %r46;
mov.u32 %r33, 3;
vote.sync.ballot.b32 %r12, %p10, %r33;
@%p9 bra $L__BB205_14;

shl.b32 %r34, %r2, 3;
mov.u32 %r35, __smem_d;
add.s32 %r36, %r35, %r34;
ld.shared.f64 %fd21, [%r36];
@%p3 bra $L__BB205_14;

mov.u32 %r43, 31;

$L__BB205_13:

	mov.b64 {%r37,%r38}, %fd21;

	shr.u32 %r41, %r47, 31;
add.s32 %r42, %r47, %r41;
shr.s32 %r14, %r42, 1;
shfl.sync.down.b32 %r40|%p13, %r38, %r14, %r43, %r12;
shfl.sync.down.b32 %r39|%p14, %r37, %r14, %r43, %r12;

	mov.b64 %fd17, {%r39,%r40};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r47, 3;
mov.u32 %r47, %r14;
@%p15 bra $L__BB205_13;

$L__BB205_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra $L__BB205_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB205_16:
ret;

}

.visible .entry _Z7reduce7IdLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<38>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r13, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r35, %r1, %r2;
setp.ge.u32 %p1, %r35, %r13;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra $L__BB206_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;

$L__BB206_2:
mul.wide.u32 %rd4, %r35, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r35, %r35, %r4;
setp.lt.u32 %p2, %r35, %r13;
@%p2 bra $L__BB206_2;

$L__BB206_3:
mov.u32 %r37, WARP_SZ;
setp.lt.s32 %p3, %r37, 2;
@%p3 bra $L__BB206_6;

mov.u32 %r20, 31;
mov.u32 %r21, 1;
mov.u32 %r36, %r37;

$L__BB206_5:

	mov.b64 {%r14,%r15}, %fd21;

	shr.u32 %r18, %r36, 31;
add.s32 %r19, %r36, %r18;
shr.s32 %r9, %r19, 1;
shfl.sync.down.b32 %r17|%p4, %r15, %r9, %r20, %r21;
shfl.sync.down.b32 %r16|%p5, %r14, %r9, %r20, %r21;

	mov.b64 %fd15, {%r16,%r17};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p6, %r36, 3;
mov.u32 %r36, %r9;
@%p6 bra $L__BB206_5;

$L__BB206_6:
rem.u32 %r22, %r2, %r37;
setp.ne.s32 %p7, %r22, 0;
@%p7 bra $L__BB206_8;

div.u32 %r23, %r2, %r37;
shl.b32 %r24, %r23, 3;
mov.u32 %r25, __smem_d;
add.s32 %r26, %r25, %r24;
st.shared.f64 [%r26], %fd21;

$L__BB206_8:
bar.sync 0;
setp.ne.s32 %p8, %r2, 0;
setp.eq.s32 %p9, %r2, 0;
mov.u32 %r27, 1;
vote.sync.ballot.b32 %r10, %p9, %r27;
@%p8 bra $L__BB206_12;

ld.shared.f64 %fd21, [__smem_d];
@%p3 bra $L__BB206_12;

mov.u32 %r34, 31;

$L__BB206_11:

	mov.b64 {%r28,%r29}, %fd21;

	shr.u32 %r32, %r37, 31;
add.s32 %r33, %r37, %r32;
shr.s32 %r12, %r33, 1;
shfl.sync.down.b32 %r31|%p12, %r29, %r12, %r34, %r10;
shfl.sync.down.b32 %r30|%p13, %r28, %r12, %r34, %r10;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p14, %r37, 3;
mov.u32 %r37, %r12;
@%p14 bra $L__BB206_11;

$L__BB206_12:
@%p8 bra $L__BB206_14;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

$L__BB206_14:
ret;

}

.visible .entry _Z9cg_reduceIdEvPT_S1_j(
.param .u64 _Z9cg_reduceIdEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIdEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIdEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<55>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIdEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIdEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z9cg_reduceIdEvPT_S1_j_param_2];
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mov.u32 %r17, %tid.x;
mad.lo.s32 %r1, %r15, %r16, %r17;
mul.lo.s32 %r18, %r16, %r12;
mov.u32 %r19, %ntid.z;
mul.lo.s32 %r54, %r18, %r19;
mov.u32 %r3, %ctaid.x;
mad.lo.s32 %r53, %r54, %r3, %r1;
setp.ge.u32 %p1, %r53, %r11;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra $L__BB207_3;

mov.u32 %r20, %nctaid.x;
mul.lo.s32 %r5, %r54, %r20;
cvta.to.global.u64 %rd1, %rd2;

$L__BB207_2:
mul.wide.u32 %rd4, %r53, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd27, %fd27, %fd12;
add.s32 %r53, %r53, %r5;
setp.lt.u32 %p2, %r53, %r11;
@%p2 bra $L__BB207_2;

$L__BB207_3:
shl.b32 %r21, %r1, 3;
mov.u32 %r22, __smem_d;
add.s32 %r8, %r22, %r21;
st.shared.f64 [%r8], %fd27;
setp.lt.u32 %p3, %r54, 64;
@%p3 bra $L__BB207_8;

$L__BB207_5:
barrier.sync 0;
shr.u32 %r10, %r54, 1;
setp.ge.u32 %p4, %r1, %r10;
@%p4 bra $L__BB207_7;

shl.b32 %r23, %r10, 3;
add.s32 %r24, %r8, %r23;
ld.shared.f64 %fd13, [%r24];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r8], %fd27;

$L__BB207_7:
setp.gt.u32 %p5, %r54, 127;
mov.u32 %r54, %r10;
@%p5 bra $L__BB207_5;

$L__BB207_8:
barrier.sync 0;
and.b32 %r25, %r1, 2097120;
setp.ne.s32 %p6, %r25, 0;
@%p6 bra $L__BB207_10;


	mov.b64 {%r26,%r27}, %fd27;

	mov.u32 %r46, 31;
mov.u32 %r47, 16;
mov.u32 %r48, -1;
shfl.sync.bfly.b32 %r29|%p7, %r27, %r47, %r46, %r48;
shfl.sync.bfly.b32 %r28|%p8, %r26, %r47, %r46, %r48;

	mov.b64 %fd15, {%r28,%r29};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r30,%r31}, %fd16;

	mov.u32 %r49, 8;
shfl.sync.bfly.b32 %r33|%p9, %r31, %r49, %r46, %r48;
shfl.sync.bfly.b32 %r32|%p10, %r30, %r49, %r46, %r48;

	mov.b64 %fd17, {%r32,%r33};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r34,%r35}, %fd18;

	mov.u32 %r50, 4;
shfl.sync.bfly.b32 %r37|%p11, %r35, %r50, %r46, %r48;
shfl.sync.bfly.b32 %r36|%p12, %r34, %r50, %r46, %r48;

	mov.b64 %fd19, {%r36,%r37};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r38,%r39}, %fd20;

	mov.u32 %r51, 2;
shfl.sync.bfly.b32 %r41|%p13, %r39, %r51, %r46, %r48;
shfl.sync.bfly.b32 %r40|%p14, %r38, %r51, %r46, %r48;

	mov.b64 %fd21, {%r40,%r41};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r42,%r43}, %fd22;

	mov.u32 %r52, 1;
shfl.sync.bfly.b32 %r45|%p15, %r43, %r52, %r46, %r48;
shfl.sync.bfly.b32 %r44|%p16, %r42, %r52, %r46, %r48;

	mov.b64 %fd23, {%r44,%r45};

	add.f64 %fd27, %fd22, %fd23;

$L__BB207_10:
setp.ne.s32 %p17, %r1, 0;
@%p17 bra $L__BB207_12;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r3, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

$L__BB207_12:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<39>;
.reg .b32 %r<160>;
.reg .f64 %fd<69>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch[288];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB208_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB208_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd63, 0d0000000000000000;
@%p2 bra $L__BB208_6;

shl.b32 %r45, %r6, 10;
add.s32 %r152, %r45, %r3;
setp.ge.u32 %p3, %r152, %r35;
@%p3 bra $L__BB208_11;

shl.b32 %r8, %r5, 10;

$L__BB208_5:
mul.wide.u32 %rd5, %r152, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd63, %fd63, %fd18;
add.s32 %r152, %r152, %r8;
setp.lt.u32 %p4, %r152, %r35;
@%p4 bra $L__BB208_5;
bra.uni $L__BB208_11;

$L__BB208_6:
shl.b32 %r46, %r6, 11;
add.s32 %r153, %r46, %r3;
setp.ge.u32 %p5, %r153, %r35;
@%p5 bra $L__BB208_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 11;

$L__BB208_8:
cvt.u64.u32 %rd7, %r153;
mul.wide.u32 %rd8, %r153, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd63, %fd63, %fd21;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB208_10;

add.s32 %r47, %r153, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd63, %fd63, %fd22;

$L__BB208_10:
add.s32 %r153, %r153, %r12;
setp.lt.u32 %p7, %r153, %r35;
@%p7 bra $L__BB208_8;

$L__BB208_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r15, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd63;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd63, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r78, %r69;
shr.u32 %r18, %r4, 9;
shl.b32 %r79, %r18, 4;
mov.u32 %r80, 65535;
shl.b32 %r19, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r154, %r68;
@%p18 bra $L__BB208_13;

add.s32 %r82, %r71, 12;
atom.shared.or.b32 %r154, [%r82], %r17;

$L__BB208_13:
shfl.sync.idx.b32 %r86|%p19, %r154, %r68, %r72, %r74;
or.b32 %r87, %r86, %r17;
and.b32 %r88, %r87, %r19;
setp.eq.s32 %p20, %r88, %r19;
@%p20 bra $L__BB208_16;
bra.uni $L__BB208_15;

$L__BB208_16:
and.b32 %r91, %r4, 16;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra $L__BB208_18;

and.b32 %r112, %r4, 15;
and.b32 %r113, %r4, -512;
shr.u32 %r114, %r113, 5;
or.b32 %r115, %r114, %r112;
shl.b32 %r116, %r115, 3;
add.s32 %r118, %r71, %r116;
ld.shared.f64 %fd34, [%r118+32];

	mov.u32 %r92, %laneid;

	and.b32 %r119, %r92, -16;
shl.b32 %r121, %r80, %r119;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r122, 4127;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r75, %r122, %r121;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r75, %r122, %r121;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r124, %r97, -16;
shl.b32 %r125, %r80, %r124;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r76, %r122, %r125;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r76, %r122, %r125;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;

	mov.u32 %r102, %laneid;

	and.b32 %r127, %r102, -16;
shl.b32 %r128, %r80, %r127;

	mov.b64 {%r103,%r104}, %fd38;

	shfl.sync.bfly.b32 %r106|%p27, %r104, %r77, %r122, %r128;
shfl.sync.bfly.b32 %r105|%p28, %r103, %r77, %r122, %r128;

	mov.b64 %fd39, {%r105,%r106};

	add.f64 %fd40, %fd38, %fd39;

	mov.u32 %r107, %laneid;

	and.b32 %r130, %r107, -16;
shl.b32 %r131, %r80, %r130;

	mov.b64 {%r108,%r109}, %fd40;

	shfl.sync.bfly.b32 %r111|%p29, %r109, %r78, %r122, %r131;
shfl.sync.bfly.b32 %r110|%p30, %r108, %r78, %r122, %r131;

	mov.b64 %fd41, {%r110,%r111};

	add.f64 %fd42, %fd40, %fd41;
st.shared.f64 [%r118+32], %fd42;

$L__BB208_18:
bar.warp.sync -1;
@%p18 bra $L__BB208_20;

not.b32 %r133, %r19;
add.s32 %r135, %r71, 12;
atom.shared.and.b32 %r136, [%r135], %r133;
bra.uni $L__BB208_20;

$L__BB208_15:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch+12];
and.b32 %r90, %r89, %r17;
setp.eq.s32 %p21, %r90, 0;
@%p21 bra $L__BB208_20;
bra.uni $L__BB208_15;

$L__BB208_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r137, %r4, 511;
setp.ne.s32 %p32, %r137, 0;
@%p32 bra $L__BB208_22;

shl.b32 %r138, %r18, 3;
mov.u32 %r139, __smem_d;
add.s32 %r140, %r139, %r138;
st.shared.f64 [%r140], %fd8;

$L__BB208_22:
barrier.sync 0;
setp.ne.s32 %p33, %r3, 0;
@%p33 bra $L__BB208_31;

mul.lo.s32 %r141, %r2, %r1;
mov.u32 %r142, %ntid.z;
mad.lo.s32 %r143, %r141, %r142, 511;
shr.u32 %r22, %r143, 9;
setp.eq.s32 %p34, %r22, 0;
mov.f64 %fd68, 0d0000000000000000;
@%p34 bra $L__BB208_30;

add.s32 %r145, %r22, -1;
and.b32 %r159, %r22, 3;
setp.lt.u32 %p35, %r145, 3;
mov.f64 %fd68, 0d0000000000000000;
mov.u32 %r157, 0;
@%p35 bra $L__BB208_27;

sub.s32 %r156, %r22, %r159;

$L__BB208_26:
shl.b32 %r147, %r157, 3;
mov.u32 %r148, __smem_d;
add.s32 %r149, %r148, %r147;
ld.shared.v2.f64 {%fd47, %fd48}, [%r149];
add.f64 %fd51, %fd68, %fd47;
add.f64 %fd52, %fd51, %fd48;
ld.shared.v2.f64 {%fd53, %fd54}, [%r149+16];
add.f64 %fd57, %fd52, %fd53;
add.f64 %fd68, %fd57, %fd54;
add.s32 %r157, %r157, 4;
add.s32 %r156, %r156, -4;
setp.ne.s32 %p36, %r156, 0;
@%p36 bra $L__BB208_26;

$L__BB208_27:
setp.eq.s32 %p37, %r159, 0;
@%p37 bra $L__BB208_30;

shl.b32 %r150, %r157, 3;
mov.u32 %r151, __smem_d;
add.s32 %r158, %r151, %r150;

$L__BB208_29:
.pragma "nounroll";
ld.shared.f64 %fd58, [%r158];
add.f64 %fd68, %fd68, %fd58;
add.s32 %r158, %r158, 8;
add.s32 %r159, %r159, -1;
setp.ne.s32 %p38, %r159, 0;
@%p38 bra $L__BB208_29;

$L__BB208_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd68;

$L__BB208_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<37>;
.reg .b32 %r<152>;
.reg .f64 %fd<67>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch[160];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB209_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB209_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd61, 0d0000000000000000;
@%p2 bra $L__BB209_6;

shl.b32 %r45, %r6, 9;
add.s32 %r144, %r45, %r3;
setp.ge.u32 %p3, %r144, %r35;
@%p3 bra $L__BB209_11;

shl.b32 %r8, %r5, 9;

$L__BB209_5:
mul.wide.u32 %rd5, %r144, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd61, %fd61, %fd18;
add.s32 %r144, %r144, %r8;
setp.lt.u32 %p4, %r144, %r35;
@%p4 bra $L__BB209_5;
bra.uni $L__BB209_11;

$L__BB209_6:
shl.b32 %r46, %r6, 10;
add.s32 %r145, %r46, %r3;
setp.ge.u32 %p5, %r145, %r35;
@%p5 bra $L__BB209_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 10;

$L__BB209_8:
cvt.u64.u32 %rd7, %r145;
mul.wide.u32 %rd8, %r145, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd61, %fd61, %fd21;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB209_10;

add.s32 %r47, %r145, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd61, %fd61, %fd22;

$L__BB209_10:
add.s32 %r145, %r145, %r12;
setp.lt.u32 %p7, %r145, %r35;
@%p7 bra $L__BB209_8;

$L__BB209_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r15, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd61;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd61, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r78, %r69;
shr.u32 %r18, %r4, 8;
shl.b32 %r79, %r18, 3;
mov.u32 %r80, 255;
shl.b32 %r19, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r146, %r68;
@%p18 bra $L__BB209_13;

add.s32 %r82, %r71, 8;
atom.shared.or.b32 %r146, [%r82], %r17;

$L__BB209_13:
shfl.sync.idx.b32 %r86|%p19, %r146, %r68, %r72, %r74;
or.b32 %r87, %r86, %r17;
and.b32 %r88, %r87, %r19;
setp.eq.s32 %p20, %r88, %r19;
@%p20 bra $L__BB209_16;
bra.uni $L__BB209_15;

$L__BB209_16:
and.b32 %r91, %r4, 24;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra $L__BB209_18;

and.b32 %r107, %r4, 7;
and.b32 %r108, %r4, -256;
shr.u32 %r109, %r108, 5;
or.b32 %r110, %r109, %r107;
shl.b32 %r111, %r110, 3;
add.s32 %r113, %r71, %r111;
ld.shared.f64 %fd34, [%r113+32];

	mov.u32 %r92, %laneid;

	and.b32 %r114, %r92, -8;
shl.b32 %r116, %r80, %r114;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r117, 6175;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r76, %r117, %r116;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r76, %r117, %r116;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r119, %r97, -8;
shl.b32 %r120, %r80, %r119;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r77, %r117, %r120;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r77, %r117, %r120;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;

	mov.u32 %r102, %laneid;

	and.b32 %r122, %r102, -8;
shl.b32 %r123, %r80, %r122;

	mov.b64 {%r103,%r104}, %fd38;

	shfl.sync.bfly.b32 %r106|%p27, %r104, %r78, %r117, %r123;
shfl.sync.bfly.b32 %r105|%p28, %r103, %r78, %r117, %r123;

	mov.b64 %fd39, {%r105,%r106};

	add.f64 %fd40, %fd38, %fd39;
st.shared.f64 [%r113+32], %fd40;

$L__BB209_18:
bar.warp.sync -1;
@%p18 bra $L__BB209_20;

not.b32 %r125, %r19;
add.s32 %r127, %r71, 8;
atom.shared.and.b32 %r128, [%r127], %r125;
bra.uni $L__BB209_20;

$L__BB209_15:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch+8];
and.b32 %r90, %r89, %r17;
setp.eq.s32 %p21, %r90, 0;
@%p21 bra $L__BB209_20;
bra.uni $L__BB209_15;

$L__BB209_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r129, %r4, 255;
setp.ne.s32 %p30, %r129, 0;
@%p30 bra $L__BB209_22;

mov.u32 %r131, __smem_d;
add.s32 %r132, %r131, %r79;
st.shared.f64 [%r132], %fd8;

$L__BB209_22:
barrier.sync 0;
setp.ne.s32 %p31, %r3, 0;
@%p31 bra $L__BB209_31;

mul.lo.s32 %r133, %r2, %r1;
mov.u32 %r134, %ntid.z;
mad.lo.s32 %r135, %r133, %r134, 255;
shr.u32 %r22, %r135, 8;
setp.eq.s32 %p32, %r22, 0;
mov.f64 %fd66, 0d0000000000000000;
@%p32 bra $L__BB209_30;

add.s32 %r137, %r22, -1;
and.b32 %r151, %r22, 3;
setp.lt.u32 %p33, %r137, 3;
mov.f64 %fd66, 0d0000000000000000;
mov.u32 %r149, 0;
@%p33 bra $L__BB209_27;

sub.s32 %r148, %r22, %r151;

$L__BB209_26:
shl.b32 %r139, %r149, 3;
mov.u32 %r140, __smem_d;
add.s32 %r141, %r140, %r139;
ld.shared.v2.f64 {%fd45, %fd46}, [%r141];
add.f64 %fd49, %fd66, %fd45;
add.f64 %fd50, %fd49, %fd46;
ld.shared.v2.f64 {%fd51, %fd52}, [%r141+16];
add.f64 %fd55, %fd50, %fd51;
add.f64 %fd66, %fd55, %fd52;
add.s32 %r149, %r149, 4;
add.s32 %r148, %r148, -4;
setp.ne.s32 %p34, %r148, 0;
@%p34 bra $L__BB209_26;

$L__BB209_27:
setp.eq.s32 %p35, %r151, 0;
@%p35 bra $L__BB209_30;

shl.b32 %r142, %r149, 3;
mov.u32 %r143, __smem_d;
add.s32 %r150, %r143, %r142;

$L__BB209_29:
.pragma "nounroll";
ld.shared.f64 %fd56, [%r150];
add.f64 %fd66, %fd66, %fd56;
add.s32 %r150, %r150, 8;
add.s32 %r151, %r151, -1;
setp.ne.s32 %p36, %r151, 0;
@%p36 bra $L__BB209_29;

$L__BB209_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd66;

$L__BB209_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<35>;
.reg .b32 %r<144>;
.reg .f64 %fd<65>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch[96];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB210_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB210_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd59, 0d0000000000000000;
@%p2 bra $L__BB210_6;

shl.b32 %r45, %r6, 8;
add.s32 %r136, %r45, %r3;
setp.ge.u32 %p3, %r136, %r35;
@%p3 bra $L__BB210_11;

shl.b32 %r8, %r5, 8;

$L__BB210_5:
mul.wide.u32 %rd5, %r136, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd59, %fd59, %fd18;
add.s32 %r136, %r136, %r8;
setp.lt.u32 %p4, %r136, %r35;
@%p4 bra $L__BB210_5;
bra.uni $L__BB210_11;

$L__BB210_6:
shl.b32 %r46, %r6, 9;
add.s32 %r137, %r46, %r3;
setp.ge.u32 %p5, %r137, %r35;
@%p5 bra $L__BB210_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 9;

$L__BB210_8:
cvt.u64.u32 %rd7, %r137;
mul.wide.u32 %rd8, %r137, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd59, %fd59, %fd21;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB210_10;

add.s32 %r47, %r137, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd59, %fd59, %fd22;

$L__BB210_10:
add.s32 %r137, %r137, %r12;
setp.lt.u32 %p7, %r137, %r35;
@%p7 bra $L__BB210_8;

$L__BB210_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r15, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd59;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd59, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r78, %r69;
shr.u32 %r18, %r4, 7;
shl.b32 %r79, %r18, 2;
mov.u32 %r80, 15;
shl.b32 %r19, %r80, %r79;
bar.warp.sync -1;
mov.u32 %r138, %r68;
@%p18 bra $L__BB210_13;

add.s32 %r82, %r71, 4;
atom.shared.or.b32 %r138, [%r82], %r17;

$L__BB210_13:
shfl.sync.idx.b32 %r86|%p19, %r138, %r68, %r72, %r74;
or.b32 %r87, %r86, %r17;
and.b32 %r88, %r87, %r19;
setp.eq.s32 %p20, %r88, %r19;
@%p20 bra $L__BB210_16;
bra.uni $L__BB210_15;

$L__BB210_16:
and.b32 %r91, %r4, 28;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra $L__BB210_18;

and.b32 %r102, %r4, 3;
and.b32 %r103, %r4, -128;
shr.u32 %r104, %r103, 5;
or.b32 %r105, %r104, %r102;
shl.b32 %r106, %r105, 3;
add.s32 %r108, %r71, %r106;
ld.shared.f64 %fd34, [%r108+32];

	mov.u32 %r92, %laneid;

	and.b32 %r109, %r92, -4;
shl.b32 %r111, %r80, %r109;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r112, 7199;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r77, %r112, %r111;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r77, %r112, %r111;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r114, %r97, -4;
shl.b32 %r115, %r80, %r114;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r78, %r112, %r115;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r78, %r112, %r115;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;
st.shared.f64 [%r108+32], %fd38;

$L__BB210_18:
bar.warp.sync -1;
@%p18 bra $L__BB210_20;

not.b32 %r117, %r19;
add.s32 %r119, %r71, 4;
atom.shared.and.b32 %r120, [%r119], %r117;
bra.uni $L__BB210_20;

$L__BB210_15:
ld.volatile.shared.u32 %r89, [_ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch+4];
and.b32 %r90, %r89, %r17;
setp.eq.s32 %p21, %r90, 0;
@%p21 bra $L__BB210_20;
bra.uni $L__BB210_15;

$L__BB210_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r121, %r4, 127;
setp.ne.s32 %p28, %r121, 0;
@%p28 bra $L__BB210_22;

shl.b32 %r122, %r18, 3;
mov.u32 %r123, __smem_d;
add.s32 %r124, %r123, %r122;
st.shared.f64 [%r124], %fd8;

$L__BB210_22:
barrier.sync 0;
setp.ne.s32 %p29, %r3, 0;
@%p29 bra $L__BB210_31;

mul.lo.s32 %r125, %r2, %r1;
mov.u32 %r126, %ntid.z;
mad.lo.s32 %r127, %r125, %r126, 127;
shr.u32 %r22, %r127, 7;
setp.eq.s32 %p30, %r22, 0;
mov.f64 %fd64, 0d0000000000000000;
@%p30 bra $L__BB210_30;

add.s32 %r129, %r22, -1;
and.b32 %r143, %r22, 3;
setp.lt.u32 %p31, %r129, 3;
mov.f64 %fd64, 0d0000000000000000;
mov.u32 %r141, 0;
@%p31 bra $L__BB210_27;

sub.s32 %r140, %r22, %r143;

$L__BB210_26:
shl.b32 %r131, %r141, 3;
mov.u32 %r132, __smem_d;
add.s32 %r133, %r132, %r131;
ld.shared.v2.f64 {%fd43, %fd44}, [%r133];
add.f64 %fd47, %fd64, %fd43;
add.f64 %fd48, %fd47, %fd44;
ld.shared.v2.f64 {%fd49, %fd50}, [%r133+16];
add.f64 %fd53, %fd48, %fd49;
add.f64 %fd64, %fd53, %fd50;
add.s32 %r141, %r141, 4;
add.s32 %r140, %r140, -4;
setp.ne.s32 %p32, %r140, 0;
@%p32 bra $L__BB210_26;

$L__BB210_27:
setp.eq.s32 %p33, %r143, 0;
@%p33 bra $L__BB210_30;

shl.b32 %r134, %r141, 3;
mov.u32 %r135, __smem_d;
add.s32 %r142, %r135, %r134;

$L__BB210_29:
.pragma "nounroll";
ld.shared.f64 %fd54, [%r142];
add.f64 %fd64, %fd64, %fd54;
add.s32 %r142, %r142, 8;
add.s32 %r143, %r143, -1;
setp.ne.s32 %p34, %r143, 0;
@%p34 bra $L__BB210_29;

$L__BB210_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd64;

$L__BB210_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<33>;
.reg .b32 %r<134>;
.reg .f64 %fd<63>;
.reg .b64 %rd<16>;

	.shared .align 8 .b8 _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra $L__BB211_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

$L__BB211_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd57, 0d0000000000000000;
@%p2 bra $L__BB211_6;

shl.b32 %r45, %r6, 7;
add.s32 %r126, %r45, %r3;
setp.ge.u32 %p3, %r126, %r35;
@%p3 bra $L__BB211_11;

shl.b32 %r8, %r5, 7;

$L__BB211_5:
mul.wide.u32 %rd5, %r126, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd57, %fd57, %fd18;
add.s32 %r126, %r126, %r8;
setp.lt.u32 %p4, %r126, %r35;
@%p4 bra $L__BB211_5;
bra.uni $L__BB211_11;

$L__BB211_6:
shl.b32 %r46, %r6, 8;
add.s32 %r127, %r46, %r3;
setp.ge.u32 %p5, %r127, %r35;
@%p5 bra $L__BB211_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 8;

$L__BB211_8:
cvt.u64.u32 %rd7, %r127;
mul.wide.u32 %rd8, %r127, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd57, %fd57, %fd21;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra $L__BB211_10;

add.s32 %r47, %r127, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd57, %fd57, %fd22;

$L__BB211_10:
add.s32 %r127, %r127, %r12;
setp.lt.u32 %p7, %r127, %r35;
@%p7 bra $L__BB211_8;

$L__BB211_11:
shr.u32 %r69, %r4, 5;
shl.b32 %r70, %r69, 3;
mov.u32 %r71, 3;
mov.u32 %r72, _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r15, %r72, %r70;

	mov.b64 {%r48,%r49}, %fd57;

	mov.u32 %r73, 31;
mov.u32 %r74, 16;
mov.u32 %r75, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r74, %r73, %r75;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r74, %r73, %r75;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd57, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r76, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r76, %r73, %r75;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r76, %r73, %r75;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r77, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r77, %r73, %r75;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r77, %r73, %r75;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r78, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r78, %r73, %r75;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r78, %r73, %r75;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r79, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r79, %r73, %r75;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r79, %r73, %r75;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r15+32], %fd33;
and.b32 %r16, %r4, 31;
setp.ne.s32 %p18, %r16, 0;
shl.b32 %r17, %r79, %r69;
shr.u32 %r18, %r4, 6;
shl.b32 %r80, %r18, 1;
shl.b32 %r19, %r71, %r80;
bar.warp.sync -1;
mov.u32 %r128, %r68;
@%p18 bra $L__BB211_13;

atom.shared.or.b32 %r128, [%r72], %r17;

$L__BB211_13:
shfl.sync.idx.b32 %r85|%p19, %r128, %r68, %r73, %r75;
or.b32 %r86, %r85, %r17;
and.b32 %r87, %r86, %r19;
setp.eq.s32 %p20, %r87, %r19;
@%p20 bra $L__BB211_16;
bra.uni $L__BB211_15;

$L__BB211_16:
and.b32 %r90, %r4, 30;
setp.ne.s32 %p22, %r90, 0;
@%p22 bra $L__BB211_18;

and.b32 %r96, %r4, 1;
and.b32 %r98, %r4, -64;
shr.u32 %r99, %r98, 5;
or.b32 %r100, %r99, %r96;
shl.b32 %r101, %r100, 3;
add.s32 %r104, %r72, %r101;
ld.shared.f64 %fd34, [%r104+32];

	mov.u32 %r91, %laneid;

	and.b32 %r105, %r91, -2;
shl.b32 %r106, %r71, %r105;

	mov.b64 {%r92,%r93}, %fd34;

	mov.u32 %r107, 7711;
shfl.sync.bfly.b32 %r95|%p23, %r93, %r79, %r107, %r106;
shfl.sync.bfly.b32 %r94|%p24, %r92, %r79, %r107, %r106;

	mov.b64 %fd35, {%r94,%r95};

	add.f64 %fd36, %fd34, %fd35;
st.shared.f64 [%r104+32], %fd36;

$L__BB211_18:
bar.warp.sync -1;
@%p18 bra $L__BB211_20;

not.b32 %r108, %r19;
atom.shared.and.b32 %r110, [%r72], %r108;
bra.uni $L__BB211_20;

$L__BB211_15:
ld.volatile.shared.u32 %r88, [_ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch];
and.b32 %r89, %r88, %r17;
setp.eq.s32 %p21, %r89, 0;
@%p21 bra $L__BB211_20;
bra.uni $L__BB211_15;

$L__BB211_20:
ld.shared.f64 %fd8, [%r15+32];
bar.warp.sync -1;
and.b32 %r111, %r4, 63;
setp.ne.s32 %p26, %r111, 0;
@%p26 bra $L__BB211_22;

shl.b32 %r112, %r18, 3;
mov.u32 %r113, __smem_d;
add.s32 %r114, %r113, %r112;
st.shared.f64 [%r114], %fd8;

$L__BB211_22:
barrier.sync 0;
setp.ne.s32 %p27, %r3, 0;
@%p27 bra $L__BB211_31;

mul.lo.s32 %r115, %r2, %r1;
mov.u32 %r116, %ntid.z;
mad.lo.s32 %r117, %r115, %r116, 63;
shr.u32 %r22, %r117, 6;
setp.eq.s32 %p28, %r22, 0;
mov.f64 %fd62, 0d0000000000000000;
@%p28 bra $L__BB211_30;

add.s32 %r119, %r22, -1;
and.b32 %r133, %r22, 3;
setp.lt.u32 %p29, %r119, 3;
mov.f64 %fd62, 0d0000000000000000;
mov.u32 %r131, 0;
@%p29 bra $L__BB211_27;

sub.s32 %r130, %r22, %r133;

$L__BB211_26:
shl.b32 %r121, %r131, 3;
mov.u32 %r122, __smem_d;
add.s32 %r123, %r122, %r121;
ld.shared.v2.f64 {%fd41, %fd42}, [%r123];
add.f64 %fd45, %fd62, %fd41;
add.f64 %fd46, %fd45, %fd42;
ld.shared.v2.f64 {%fd47, %fd48}, [%r123+16];
add.f64 %fd51, %fd46, %fd47;
add.f64 %fd62, %fd51, %fd48;
add.s32 %r131, %r131, 4;
add.s32 %r130, %r130, -4;
setp.ne.s32 %p30, %r130, 0;
@%p30 bra $L__BB211_26;

$L__BB211_27:
setp.eq.s32 %p31, %r133, 0;
@%p31 bra $L__BB211_30;

shl.b32 %r124, %r131, 3;
mov.u32 %r125, __smem_d;
add.s32 %r132, %r125, %r124;

$L__BB211_29:
.pragma "nounroll";
ld.shared.f64 %fd52, [%r132];
add.f64 %fd62, %fd62, %fd52;
add.s32 %r132, %r132, 8;
add.s32 %r133, %r133, -1;
setp.ne.s32 %p32, %r133, 0;
@%p32 bra $L__BB211_29;

$L__BB211_30:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd62;

$L__BB211_31:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<24>;
.reg .b32 %r<88>;
.reg .f64 %fd<59>;
.reg .b64 %rd<16>;


ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r30, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r31, %tid.z;
mov.u32 %r32, %tid.y;
mad.lo.s32 %r33, %r1, %r31, %r32;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r33, %r2, %r3;
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r34, %r30, -1;
and.b32 %r35, %r34, %r30;
setp.eq.s32 %p1, %r35, 0;
mov.u32 %r6, %ctaid.x;
mov.f64 %fd53, 0d0000000000000000;
@%p1 bra $L__BB212_4;

shl.b32 %r36, %r6, 6;
add.s32 %r80, %r36, %r3;
setp.ge.u32 %p2, %r80, %r30;
@%p2 bra $L__BB212_9;

shl.b32 %r8, %r5, 6;

$L__BB212_3:
mul.wide.u32 %rd5, %r80, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd53, %fd53, %fd18;
add.s32 %r80, %r80, %r8;
setp.lt.u32 %p3, %r80, %r30;
@%p3 bra $L__BB212_3;
bra.uni $L__BB212_9;

$L__BB212_4:
shl.b32 %r37, %r6, 7;
add.s32 %r81, %r37, %r3;
setp.ge.u32 %p4, %r81, %r30;
@%p4 bra $L__BB212_9;

cvt.u64.u32 %rd2, %r30;
shl.b32 %r12, %r5, 7;

$L__BB212_6:
cvt.u64.u32 %rd7, %r81;
mul.wide.u32 %rd8, %r81, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd53, %fd53, %fd21;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p5, %rd10, %rd2;
@%p5 bra $L__BB212_8;

add.s32 %r38, %r81, %r2;
mul.wide.u32 %rd11, %r38, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd53, %fd53, %fd22;

$L__BB212_8:
add.s32 %r81, %r81, %r12;
setp.lt.u32 %p6, %r81, %r30;
@%p6 bra $L__BB212_6;

$L__BB212_9:

	mov.b64 {%r39,%r40}, %fd53;

	mov.u32 %r59, 31;
mov.u32 %r60, 16;
mov.u32 %r61, -1;
shfl.sync.bfly.b32 %r42|%p7, %r40, %r60, %r59, %r61;
shfl.sync.bfly.b32 %r41|%p8, %r39, %r60, %r59, %r61;

	mov.b64 %fd24, {%r41,%r42};

	add.f64 %fd25, %fd53, %fd24;

	mov.b64 {%r43,%r44}, %fd25;

	mov.u32 %r62, 8;
shfl.sync.bfly.b32 %r46|%p9, %r44, %r62, %r59, %r61;
shfl.sync.bfly.b32 %r45|%p10, %r43, %r62, %r59, %r61;

	mov.b64 %fd26, {%r45,%r46};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r47,%r48}, %fd27;

	mov.u32 %r63, 4;
shfl.sync.bfly.b32 %r50|%p11, %r48, %r63, %r59, %r61;
shfl.sync.bfly.b32 %r49|%p12, %r47, %r63, %r59, %r61;

	mov.b64 %fd28, {%r49,%r50};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r51,%r52}, %fd29;

	mov.u32 %r64, 2;
shfl.sync.bfly.b32 %r54|%p13, %r52, %r64, %r59, %r61;
shfl.sync.bfly.b32 %r53|%p14, %r51, %r64, %r59, %r61;

	mov.b64 %fd30, {%r53,%r54};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r55,%r56}, %fd31;

	mov.u32 %r65, 1;
shfl.sync.bfly.b32 %r58|%p15, %r56, %r65, %r59, %r61;
shfl.sync.bfly.b32 %r57|%p16, %r55, %r65, %r59, %r61;

	mov.b64 %fd32, {%r57,%r58};

	add.f64 %fd8, %fd31, %fd32;
and.b32 %r66, %r4, 31;
setp.ne.s32 %p17, %r66, 0;
@%p17 bra $L__BB212_11;

shr.u32 %r67, %r4, 2;
and.b32 %r68, %r67, 1073741816;
mov.u32 %r69, __smem_d;
add.s32 %r70, %r69, %r68;
st.shared.f64 [%r70], %fd8;

$L__BB212_11:
barrier.sync 0;
setp.ne.s32 %p18, %r3, 0;
@%p18 bra $L__BB212_20;

mul.lo.s32 %r71, %r2, %r1;
mov.u32 %r72, %ntid.z;
mad.lo.s32 %r73, %r71, %r72, 31;
shr.u32 %r15, %r73, 5;
setp.eq.s32 %p19, %r15, 0;
mov.f64 %fd58, 0d0000000000000000;
@%p19 bra $L__BB212_19;

add.s32 %r75, %r15, -1;
and.b32 %r87, %r15, 3;
setp.lt.u32 %p20, %r75, 3;
mov.f64 %fd58, 0d0000000000000000;
mov.u32 %r85, 0;
@%p20 bra $L__BB212_16;

sub.s32 %r84, %r15, %r87;
mov.u32 %r82, __smem_d;

$L__BB212_15:
ld.shared.v2.f64 {%fd37, %fd38}, [%r82];
add.f64 %fd41, %fd58, %fd37;
add.f64 %fd42, %fd41, %fd38;
ld.shared.v2.f64 {%fd43, %fd44}, [%r82+16];
add.f64 %fd47, %fd42, %fd43;
add.f64 %fd58, %fd47, %fd44;
add.s32 %r85, %r85, 4;
add.s32 %r82, %r82, 32;
add.s32 %r84, %r84, -4;
setp.ne.s32 %p21, %r84, 0;
@%p21 bra $L__BB212_15;

$L__BB212_16:
setp.eq.s32 %p22, %r87, 0;
@%p22 bra $L__BB212_19;

shl.b32 %r78, %r85, 3;
mov.u32 %r79, __smem_d;
add.s32 %r86, %r79, %r78;

$L__BB212_18:
.pragma "nounroll";
ld.shared.f64 %fd48, [%r86];
add.f64 %fd58, %fd58, %fd48;
add.s32 %r86, %r86, 8;
add.s32 %r87, %r87, -1;
setp.ne.s32 %p23, %r87, 0;
@%p23 bra $L__BB212_18;

$L__BB212_19:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd58;

$L__BB212_20:
ret;

}


Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit
