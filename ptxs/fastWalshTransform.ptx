
Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_80
code version = [7,5]
producer = <unknown>
host = linux
compile_size = 64bit
compressed








.version 7.5
.target sm_80
.address_size 64


.extern .shared .align 16 .b8 s_data[];

.visible .entry _Z15fwtBatch1KernelPfS_i(
.param .u64 _Z15fwtBatch1KernelPfS_i_param_0,
.param .u64 _Z15fwtBatch1KernelPfS_i_param_1,
.param .u32 _Z15fwtBatch1KernelPfS_i_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<21>;
.reg .b32 %r<49>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z15fwtBatch1KernelPfS_i_param_0];
ld.param.u64 %rd4, [_Z15fwtBatch1KernelPfS_i_param_1];
ld.param.u32 %r16, [_Z15fwtBatch1KernelPfS_i_param_2];
mov.u32 %r17, %ctaid.x;
shl.b32 %r1, %r17, %r16;
mov.u32 %r48, %tid.x;
mov.u32 %r18, 1;
shl.b32 %r3, %r18, %r16;
setp.ge.s32 %p1, %r48, %r3;
@%p1 bra $L__BB0_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r4, %ntid.x;
mov.u32 %r45, %r48;

$L__BB0_2:
add.s32 %r19, %r45, %r1;
mul.wide.s32 %rd5, %r19, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f1, [%rd6];
shl.b32 %r20, %r45, 2;
mov.u32 %r21, s_data;
add.s32 %r22, %r21, %r20;
st.shared.f32 [%r22], %f1;
add.s32 %r45, %r45, %r4;
setp.lt.s32 %p2, %r45, %r3;
@%p2 bra $L__BB0_2;

$L__BB0_3:
setp.lt.s32 %p3, %r3, 4;
@%p3 bra $L__BB0_6;

mov.u32 %r29, s_data;
mov.u32 %r46, %r3;

$L__BB0_5:
shr.s32 %r8, %r46, 2;
add.s32 %r23, %r8, -1;
and.b32 %r24, %r23, %r48;
sub.s32 %r25, %r48, %r24;
shl.b32 %r26, %r25, 2;
add.s32 %r27, %r26, %r24;
bar.sync 0;
shl.b32 %r28, %r27, 2;
add.s32 %r30, %r29, %r28;
and.b32 %r31, %r46, -4;
add.s32 %r32, %r30, %r31;
add.s32 %r33, %r32, %r31;
add.s32 %r34, %r33, %r31;
ld.shared.f32 %f2, [%r33];
ld.shared.f32 %f3, [%r30];
add.f32 %f4, %f3, %f2;
sub.f32 %f5, %f3, %f2;
ld.shared.f32 %f6, [%r34];
ld.shared.f32 %f7, [%r32];
add.f32 %f8, %f7, %f6;
sub.f32 %f9, %f7, %f6;
add.f32 %f10, %f4, %f8;
st.shared.f32 [%r30], %f10;
sub.f32 %f11, %f4, %f8;
st.shared.f32 [%r32], %f11;
add.f32 %f12, %f5, %f9;
st.shared.f32 [%r33], %f12;
sub.f32 %f13, %f5, %f9;
st.shared.f32 [%r34], %f13;
setp.gt.s32 %p4, %r46, 15;
mov.u32 %r46, %r8;
@%p4 bra $L__BB0_5;

$L__BB0_6:
and.b32 %r35, %r16, 1;
setp.eq.b32 %p5, %r35, 1;
mov.pred %p6, 0;
xor.pred %p7, %p5, %p6;
not.pred %p8, %p7;
@%p8 bra $L__BB0_10;

bar.sync 0;
shr.u32 %r36, %r3, 31;
add.s32 %r37, %r3, %r36;
shr.s32 %r9, %r37, 1;
setp.ge.s32 %p9, %r48, %r9;
@%p9 bra $L__BB0_10;

mov.u32 %r10, %ntid.x;
mov.u32 %r47, %r48;

$L__BB0_9:
shl.b32 %r38, %r47, 3;
mov.u32 %r39, s_data;
add.s32 %r40, %r39, %r38;
ld.shared.v2.f32 {%f14, %f15}, [%r40];
sub.f32 %f18, %f14, %f15;
add.f32 %f19, %f14, %f15;
st.shared.v2.f32 [%r40], {%f19, %f18};
add.s32 %r47, %r47, %r10;
setp.lt.s32 %p10, %r47, %r9;
@%p10 bra $L__BB0_9;

$L__BB0_10:
bar.sync 0;
@%p1 bra $L__BB0_13;

mov.u32 %r13, %ntid.x;
cvta.to.global.u64 %rd2, %rd3;
mov.u32 %r42, s_data;

$L__BB0_12:
shl.b32 %r41, %r48, 2;
add.s32 %r43, %r42, %r41;
ld.shared.f32 %f20, [%r43];
add.s32 %r44, %r48, %r1;
mul.wide.s32 %rd7, %r44, 4;
add.s64 %rd8, %rd2, %rd7;
st.global.f32 [%rd8], %f20;
add.s32 %r48, %r48, %r13;
setp.lt.s32 %p12, %r48, %r3;
@%p12 bra $L__BB0_12;

$L__BB0_13:
ret;

}

.visible .entry _Z15fwtBatch2KernelPfS_i(
.param .u64 _Z15fwtBatch2KernelPfS_i_param_0,
.param .u64 _Z15fwtBatch2KernelPfS_i_param_1,
.param .u32 _Z15fwtBatch2KernelPfS_i_param_2
)
{
.reg .f32 %f<13>;
.reg .b32 %r<16>;
.reg .b64 %rd<18>;


ld.param.u64 %rd1, [_Z15fwtBatch2KernelPfS_i_param_0];
ld.param.u64 %rd2, [_Z15fwtBatch2KernelPfS_i_param_1];
ld.param.u32 %r1, [_Z15fwtBatch2KernelPfS_i_param_2];
cvta.to.global.u64 %rd3, %rd1;
cvta.to.global.u64 %rd4, %rd2;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %ntid.x;
mov.u32 %r4, %tid.x;
mad.lo.s32 %r5, %r2, %r3, %r4;
mov.u32 %r6, %nctaid.x;
mov.u32 %r7, %ctaid.y;
mul.lo.s32 %r8, %r6, %r3;
mul.lo.s32 %r9, %r8, %r7;
shl.b32 %r10, %r9, 2;
cvt.u64.u32 %rd5, %r10;
add.s32 %r11, %r1, -1;
and.b32 %r12, %r11, %r5;
sub.s32 %r13, %r5, %r12;
shl.b32 %r14, %r13, 2;
add.s32 %r15, %r14, %r12;
cvt.s64.s32 %rd6, %r15;
add.s64 %rd7, %rd6, %rd5;
shl.b64 %rd8, %rd7, 2;
add.s64 %rd9, %rd4, %rd8;
ld.global.f32 %f1, [%rd9];
mul.wide.s32 %rd10, %r1, 4;
add.s64 %rd11, %rd9, %rd10;
ld.global.f32 %f2, [%rd11];
add.s64 %rd12, %rd11, %rd10;
ld.global.f32 %f3, [%rd12];
add.s64 %rd13, %rd12, %rd10;
ld.global.f32 %f4, [%rd13];
add.f32 %f5, %f1, %f3;
sub.f32 %f6, %f1, %f3;
add.f32 %f7, %f2, %f4;
sub.f32 %f8, %f2, %f4;
add.f32 %f9, %f5, %f7;
add.s64 %rd14, %rd3, %rd8;
st.global.f32 [%rd14], %f9;
sub.f32 %f10, %f5, %f7;
add.s64 %rd15, %rd14, %rd10;
st.global.f32 [%rd15], %f10;
add.f32 %f11, %f6, %f8;
add.s64 %rd16, %rd15, %rd10;
st.global.f32 [%rd16], %f11;
sub.f32 %f12, %f6, %f8;
add.s64 %rd17, %rd16, %rd10;
st.global.f32 [%rd17], %f12;
ret;

}

.visible .entry _Z14modulateKernelPfS_i(
.param .u64 _Z14modulateKernelPfS_i_param_0,
.param .u64 _Z14modulateKernelPfS_i_param_1,
.param .u32 _Z14modulateKernelPfS_i_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<23>;
.reg .b32 %r<30>;
.reg .b64 %rd<25>;


ld.param.u64 %rd10, [_Z14modulateKernelPfS_i_param_0];
ld.param.u64 %rd11, [_Z14modulateKernelPfS_i_param_1];
ld.param.u32 %r13, [_Z14modulateKernelPfS_i_param_2];
cvta.to.global.u64 %rd1, %rd10;
cvta.to.global.u64 %rd2, %rd11;
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r28, %r15, %r14, %r16;
mov.u32 %r17, %nctaid.x;
mul.lo.s32 %r2, %r14, %r17;
cvt.rn.f32.s32 %f2, %r13;
rcp.rn.f32 %f1, %f2;
setp.ge.s32 %p1, %r28, %r13;
@%p1 bra $L__BB2_7;

add.s32 %r18, %r2, %r13;
add.s32 %r19, %r28, %r2;
not.b32 %r20, %r19;
add.s32 %r21, %r18, %r20;
div.u32 %r3, %r21, %r2;
add.s32 %r22, %r3, 1;
and.b32 %r27, %r22, 3;
setp.eq.s32 %p2, %r27, 0;
@%p2 bra $L__BB2_4;

mul.wide.s32 %rd12, %r28, 4;
add.s64 %rd24, %rd1, %rd12;
mul.wide.s32 %rd4, %r2, 4;
add.s64 %rd23, %rd2, %rd12;

$L__BB2_3:
.pragma "nounroll";
ld.global.f32 %f3, [%rd23];
mul.f32 %f4, %f1, %f3;
ld.global.f32 %f5, [%rd24];
mul.f32 %f6, %f5, %f4;
st.global.f32 [%rd24], %f6;
add.s32 %r28, %r28, %r2;
add.s64 %rd24, %rd24, %rd4;
add.s64 %rd23, %rd23, %rd4;
add.s32 %r27, %r27, -1;
setp.ne.s32 %p3, %r27, 0;
@%p3 bra $L__BB2_3;

$L__BB2_4:
setp.lt.u32 %p4, %r3, 3;
@%p4 bra $L__BB2_7;

shl.b32 %r10, %r2, 2;
cvt.s64.s32 %rd16, %r10;

$L__BB2_6:
mul.wide.s32 %rd13, %r28, 4;
add.s64 %rd14, %rd2, %rd13;
ld.global.f32 %f7, [%rd14];
mul.f32 %f8, %f1, %f7;
add.s64 %rd15, %rd1, %rd13;
ld.global.f32 %f9, [%rd15];
mul.f32 %f10, %f9, %f8;
st.global.f32 [%rd15], %f10;
add.s64 %rd17, %rd14, %rd16;
ld.global.f32 %f11, [%rd17];
mul.f32 %f12, %f1, %f11;
add.s64 %rd18, %rd15, %rd16;
ld.global.f32 %f13, [%rd18];
mul.f32 %f14, %f13, %f12;
st.global.f32 [%rd18], %f14;
add.s32 %r23, %r28, %r2;
add.s32 %r24, %r23, %r2;
add.s64 %rd19, %rd17, %rd16;
ld.global.f32 %f15, [%rd19];
mul.f32 %f16, %f1, %f15;
add.s64 %rd20, %rd18, %rd16;
ld.global.f32 %f17, [%rd20];
mul.f32 %f18, %f17, %f16;
st.global.f32 [%rd20], %f18;
add.s32 %r25, %r24, %r2;
add.s64 %rd21, %rd19, %rd16;
ld.global.f32 %f19, [%rd21];
mul.f32 %f20, %f1, %f19;
add.s64 %rd22, %rd20, %rd16;
ld.global.f32 %f21, [%rd22];
mul.f32 %f22, %f21, %f20;
st.global.f32 [%rd22], %f22;
add.s32 %r28, %r25, %r2;
setp.lt.s32 %p5, %r28, %r13;
@%p5 bra $L__BB2_6;

$L__BB2_7:
ret;

}


Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit
